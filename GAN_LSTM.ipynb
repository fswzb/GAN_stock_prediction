{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Bidirectional, LSTM, Reshape, RepeatVector, TimeDistributed\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow_gan as tfgan\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution() \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Loading from preprocessed numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 4)\n",
      "input [[[4366.64 4411.01 4287.11 4356.45]\n",
      "  [4356.32 4417.35 4222.62 4410.13]\n",
      "  [4471.38 4494.52 4395.34 4397.94]\n",
      "  [4547.35 4602.11 4477.95 4482.73]\n",
      "  [4588.03 4611.55 4530.2  4532.76]]\n",
      "\n",
      " [[4356.32 4417.35 4222.62 4410.13]\n",
      "  [4471.38 4494.52 4395.34 4397.94]\n",
      "  [4547.35 4602.11 4477.95 4482.73]\n",
      "  [4588.03 4611.55 4530.2  4532.76]\n",
      "  [4632.24 4632.24 4568.7  4577.11]]\n",
      "\n",
      " [[4471.38 4494.52 4395.34 4397.94]\n",
      "  [4547.35 4602.11 4477.95 4482.73]\n",
      "  [4588.03 4611.55 4530.2  4532.76]\n",
      "  [4632.24 4632.24 4568.7  4577.11]\n",
      "  [4637.99 4665.13 4614.75 4662.85]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2457.77 2571.42 2407.53 2475.56]\n",
      "  [2344.44 2449.71 2344.44 2447.33]\n",
      "  [2290.71 2300.73 2191.86 2237.4 ]\n",
      "  [2431.94 2453.01 2295.56 2304.92]\n",
      "  [2393.48 2466.97 2319.78 2409.39]]\n",
      "\n",
      " [[2344.44 2449.71 2344.44 2447.33]\n",
      "  [2290.71 2300.73 2191.86 2237.4 ]\n",
      "  [2431.94 2453.01 2295.56 2304.92]\n",
      "  [2393.48 2466.97 2319.78 2409.39]\n",
      "  [2436.5  2453.57 2280.52 2398.1 ]]\n",
      "\n",
      " [[2290.71 2300.73 2191.86 2237.4 ]\n",
      "  [2431.94 2453.01 2295.56 2304.92]\n",
      "  [2393.48 2466.97 2319.78 2409.39]\n",
      "  [2436.5  2453.57 2280.52 2398.1 ]\n",
      "  [2425.66 2553.93 2367.04 2529.19]]]\n",
      "output [[4632.24 4632.24 4568.7  4577.11]\n",
      " [4637.99 4665.13 4614.75 4662.85]\n",
      " [4733.56 4744.13 4650.29 4659.03]\n",
      " ...\n",
      " [2436.5  2453.57 2280.52 2398.1 ]\n",
      " [2425.66 2553.93 2367.04 2529.19]\n",
      " [2508.59 2562.98 2380.94 2386.13]]\n",
      "merged tf.Tensor(\n",
      "[[[4366.64 4411.01 4287.11 4356.45]\n",
      "  [4356.32 4417.35 4222.62 4410.13]\n",
      "  [4471.38 4494.52 4395.34 4397.94]\n",
      "  [4547.35 4602.11 4477.95 4482.73]\n",
      "  [4588.03 4611.55 4530.2  4532.76]\n",
      "  [4632.24 4632.24 4568.7  4577.11]]\n",
      "\n",
      " [[4356.32 4417.35 4222.62 4410.13]\n",
      "  [4471.38 4494.52 4395.34 4397.94]\n",
      "  [4547.35 4602.11 4477.95 4482.73]\n",
      "  [4588.03 4611.55 4530.2  4532.76]\n",
      "  [4632.24 4632.24 4568.7  4577.11]\n",
      "  [4637.99 4665.13 4614.75 4662.85]]\n",
      "\n",
      " [[4471.38 4494.52 4395.34 4397.94]\n",
      "  [4547.35 4602.11 4477.95 4482.73]\n",
      "  [4588.03 4611.55 4530.2  4532.76]\n",
      "  [4632.24 4632.24 4568.7  4577.11]\n",
      "  [4637.99 4665.13 4614.75 4662.85]\n",
      "  [4733.56 4744.13 4650.29 4659.03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2457.77 2571.42 2407.53 2475.56]\n",
      "  [2344.44 2449.71 2344.44 2447.33]\n",
      "  [2290.71 2300.73 2191.86 2237.4 ]\n",
      "  [2431.94 2453.01 2295.56 2304.92]\n",
      "  [2393.48 2466.97 2319.78 2409.39]\n",
      "  [2436.5  2453.57 2280.52 2398.1 ]]\n",
      "\n",
      " [[2344.44 2449.71 2344.44 2447.33]\n",
      "  [2290.71 2300.73 2191.86 2237.4 ]\n",
      "  [2431.94 2453.01 2295.56 2304.92]\n",
      "  [2393.48 2466.97 2319.78 2409.39]\n",
      "  [2436.5  2453.57 2280.52 2398.1 ]\n",
      "  [2425.66 2553.93 2367.04 2529.19]]\n",
      "\n",
      " [[2290.71 2300.73 2191.86 2237.4 ]\n",
      "  [2431.94 2453.01 2295.56 2304.92]\n",
      "  [2393.48 2466.97 2319.78 2409.39]\n",
      "  [2436.5  2453.57 2280.52 2398.1 ]\n",
      "  [2425.66 2553.93 2367.04 2529.19]\n",
      "  [2508.59 2562.98 2380.94 2386.13]]], shape=(466, 6, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    # test, train split\n",
    "    x_train = np.array(pd.read_csv(\"./data_stock/SP500_average.csv\",).drop([0]).drop(columns=['Date']))\n",
    "    return x_train\n",
    "            \n",
    "\n",
    "def merge_time_series(arr1, arr2) -> tf.float64 :\n",
    "    t1 = tf.cast(arr1, 'float64') if tf.is_tensor(arr1) else tf.convert_to_tensor(arr1, dtype='float64')\n",
    "    t2 = tf.cast(arr2, 'float64') if tf.is_tensor(arr2) else tf.convert_to_tensor(arr2, dtype='float64')\n",
    "    if(len(t2.shape)==2):\n",
    "        t2 = tf.expand_dims(t2, 1);\n",
    "    return tf.concat([t1, t2 ], axis=1)\n",
    "\n",
    "def split_time_series(t, arr) -> (np.array, np.array):\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in range(len(arr)-t):\n",
    "        a.append(arr[i: i+t])\n",
    "        b.append(arr[i+t])\n",
    "    return (np.array(a), np.array(b))\n",
    "\n",
    "(input, output) = split_time_series(5, load_data())\n",
    "print(f'{output.shape}')\n",
    "merged = merge_time_series(input, output)\n",
    "print(\"input\",input)\n",
    "print(\"output\", output)\n",
    "print(\"merged\",merged)\n",
    "\n",
    "def batch_standardize(input):\n",
    "    def standardize_fn(i) : \n",
    "        scaler = StandardScaler();\n",
    "        scaler.fit(i)\n",
    "        return (scaler.transform(i), scaler)\n",
    "    return zip(*[ standardize_fn (i) for i in input])\n",
    "\n",
    "# scalers require 2D arrays, so add artifically add a dimension when the input is 1D\n",
    "def batch_scale(input, scalers):\n",
    "    scale = lambda x,s : s.transform(x) if(len(x.shape)==2) else s.transform([x])[0]\n",
    "    return list(map(scale, input, scalers))\n",
    "\n",
    "def batch_inverse_scale(input, scalers):\n",
    "    scale = lambda x,s : s.inverse_transform(x) if(len(x.shape)==2) else s.inverse_transform([x])[0]\n",
    "    return list(map(scale, input, scalers))\n",
    "\n",
    "    \n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGAN():\n",
    "    def __init__(self, t, f, data):\n",
    "        self.data = data\n",
    "        self.time_series_len = t\n",
    "        self.feature_len = f\n",
    "        self.gen_shape = (self.time_series_len, self.feature_len)\n",
    "        self.dis_shape = (self.time_series_len+1, self.feature_len)\n",
    "\n",
    "        optimizer = Adam(0.0001, 0.4)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # Trains the generator to imitate input data\n",
    "        self.generator.compile(loss='mean_squared_error',\n",
    "            optimizer=optimizer)\n",
    "        \n",
    "        # The generator takes noise as input and generates song\n",
    "        noise = Input(shape=self.gen_shape)\n",
    "        gen_output = self.generator(noise)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(merge_time_series(noise, gen_output))\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(noise, valid)\n",
    "        \n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        \n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=self.gen_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Bidirectional(LSTM(128)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(4))\n",
    "        # model.summary()\n",
    "\n",
    "        noise = Input(shape=self.gen_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Bidirectional(LSTM(128, activation = 'relu', return_sequences=True), input_shape=self.dis_shape))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(TimeDistributed(Dense(128, activation = 'relu')))\n",
    "        model.add(Dense(1, activation = 'linear'))\n",
    "        #model.summary()\n",
    "\n",
    "        img = Input(shape=self.dis_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "    \n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train_input, X_train_output) = split_time_series(self.time_series_len, self.data)\n",
    "\n",
    "        # normalize\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones(batch_size)\n",
    "        fake = np.zeros(batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of songs\n",
    "            idx = np.random.randint(0, X_train_input.shape[0], batch_size)\n",
    "            real_input= X_train_input[idx]\n",
    "            real_output= X_train_output[idx]\n",
    "            \n",
    "           \n",
    "            \n",
    "            (real_input, scalers) = batch_standardize(real_input)\n",
    "            real_output = batch_scale(real_output, scalers)\n",
    "            \n",
    "            # Sample noise and generate a batch of new prices\n",
    "            noise = np.random.normal(0, 1, (batch_size,self.time_series_len,self.feature_len))\n",
    "            gen_output = self.generator.predict(noise, batch_size = batch_size)\n",
    "            real_series = merge_time_series(real_input,real_output)\n",
    "            fake_series = merge_time_series(real_input,gen_output)\n",
    "            print(\"input:\\n\", scalers[0].inverse_transform( real_input[0]))\n",
    "            print(\"fake_output:\\n\", scalers[0].inverse_transform( [gen_output[0]])[0])\n",
    "            print(\"real_output:\\n\", scalers[0].inverse_transform( [real_output[0]])[0])\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_series, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(fake_series, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # First training (wants generator to imitate real data)\n",
    "            g_loss1 = self.generator.train_on_batch( np.array(real_input), np.array(real_output))\n",
    "            \n",
    "            # Second training (wants discriminator to mistake songs as real)\n",
    "            g_loss2 = self.combined.train_on_batch(noise, valid)\n",
    "            g_loss = 0.5 * np.add(g_loss1, g_loss2)\n",
    "\n",
    "\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save model\n",
    "            if epoch % save_interval == 0:\n",
    "                self.generator.save(\"LSTM_generator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary\n",
    "I couldn't train the model on this online notebook so I trained it locally for 1000 epochs and uploaded the h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " [[3111.56 3128.91 3090.41 3112.35]\n",
      " [3098.9  3130.94 3098.9  3122.87]\n",
      " [3064.78 3081.07 3051.64 3080.82]\n",
      " [3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]]\n",
      "fake_output:\n",
      " [[3068.69779241 3089.55789047 3054.4615908  3083.07518185]]\n",
      "real_output:\n",
      " [[3046.61 3068.67 3023.4  3029.73]]\n",
      "0 [D loss: 5.967822, acc.: 50.00%] [G loss: 7.291785]\n",
      "input:\n",
      " [[3543.76 3588.11 3535.23 3580.84]\n",
      " [3507.44 3528.03 3494.6  3526.65]\n",
      " [3509.73 3514.77 3493.25 3500.31]\n",
      " [3494.69 3509.23 3484.32 3508.01]\n",
      " [3485.14 3501.38 3468.35 3484.55]]\n",
      "fake_output:\n",
      " [[3508.62067368 3528.25810702 3495.31941574 3520.09242469]]\n",
      "real_output:\n",
      " [[3449.97 3481.07 3444.15 3478.73]]\n",
      "1 [D loss: 5.448864, acc.: 50.00%] [G loss: 7.407722]\n",
      "input:\n",
      " [[3638.55 3644.31 3629.33 3638.35]\n",
      " [3635.5  3635.5  3617.76 3629.65]\n",
      " [3594.52 3642.31 3594.52 3635.41]\n",
      " [3566.82 3589.81 3552.77 3577.59]\n",
      " [3579.31 3581.23 3556.85 3557.54]]\n",
      "fake_output:\n",
      " [[3603.66292942 3618.02532897 3590.36375495 3607.11820841]]\n",
      "real_output:\n",
      " [[3559.41 3585.22 3543.84 3581.87]]\n",
      "2 [D loss: 4.534419, acc.: 50.00%] [G loss: 6.445080]\n",
      "input:\n",
      " [[4348.84 4355.51 4278.94 4300.46]\n",
      " [4317.16 4375.19 4288.52 4357.04]\n",
      " [4370.67 4382.55 4306.24 4307.54]\n",
      " [4362.41 4385.57 4355.08 4359.46]\n",
      " [4419.54 4419.54 4346.33 4352.63]]\n",
      "fake_output:\n",
      " [[4364.4698622  4383.22464672 4315.55635939 4335.08686257]]\n",
      "real_output:\n",
      " [[4442.12 4457.3  4436.19 4443.11]]\n",
      "3 [D loss: 3.613786, acc.: 50.00%] [G loss: 6.313359]\n",
      "input:\n",
      " [[4317.16 4375.19 4288.52 4357.04]\n",
      " [4370.67 4382.55 4306.24 4307.54]\n",
      " [4362.41 4385.57 4355.08 4359.46]\n",
      " [4419.54 4419.54 4346.33 4352.63]\n",
      " [4442.12 4457.3  4436.19 4443.11]]\n",
      "fake_output:\n",
      " [[4385.03111882 4402.33748534 4344.17905307 4361.58140283]]\n",
      "real_output:\n",
      " [[4438.04 4463.12 4430.27 4455.48]]\n",
      "4 [D loss: 2.966187, acc.: 50.00%] [G loss: 5.211849]\n",
      "input:\n",
      " [[3141.11 3200.95 3127.66 3197.52]\n",
      " [3205.08 3235.32 3149.43 3155.22]\n",
      " [3152.47 3186.82 3136.22 3185.04]\n",
      " [3176.17 3179.78 3115.7  3152.05]\n",
      " [3153.07 3171.8  3136.53 3169.94]]\n",
      "fake_output:\n",
      " [[3166.14739762 3194.34603642 3133.1587635  3171.82984958]]\n",
      "real_output:\n",
      " [[3166.44 3184.15 3142.93 3145.32]]\n",
      "5 [D loss: 2.752744, acc.: 50.00%] [G loss: 4.241984]\n",
      "input:\n",
      " [[4632.24 4632.24 4568.7  4577.11]\n",
      " [4637.99 4665.13 4614.75 4662.85]\n",
      " [4733.56 4744.13 4650.29 4659.03]\n",
      " [4728.59 4748.83 4706.71 4726.35]\n",
      " [4669.14 4714.13 4638.27 4713.07]]\n",
      "fake_output:\n",
      " [[4682.94169536 4698.41212523 4634.47007464 4665.35134425]]\n",
      "real_output:\n",
      " [[4655.34 4673.02 4582.24 4670.29]]\n",
      "6 [D loss: 2.367017, acc.: 50.00%] [G loss: 5.541010]\n",
      "input:\n",
      " [[3439.38 3476.93 3435.65 3443.12]\n",
      " [3493.66 3502.42 3419.93 3426.92]\n",
      " [3493.5  3515.76 3480.45 3483.81]\n",
      " [3453.72 3489.08 3440.89 3483.34]\n",
      " [3515.47 3527.94 3480.55 3488.67]]\n",
      "fake_output:\n",
      " [[3480.4772045  3501.60615029 3452.74571126 3464.64521215]]\n",
      "real_output:\n",
      " [[3534.01 3534.01 3500.86 3511.93]]\n",
      "7 [D loss: 1.989128, acc.: 50.00%] [G loss: 4.838972]\n",
      "input:\n",
      " [[4248.31 4255.59 4234.07 4255.15]\n",
      " [4242.9  4248.38 4232.25 4247.44]\n",
      " [4228.56 4249.74 4220.34 4239.18]\n",
      " [4232.99 4237.09 4218.74 4219.55]\n",
      " [4233.81 4236.74 4208.41 4227.26]]\n",
      "fake_output:\n",
      " [[4237.56884525 4244.98731012 4222.71859868 4237.11635531]]\n",
      "real_output:\n",
      " [[4229.34 4232.34 4215.66 4226.52]]\n",
      "8 [D loss: 1.762924, acc.: 50.00%] [G loss: 3.579871]\n",
      "input:\n",
      " [[4664.63 4664.63 4585.43 4594.62]\n",
      " [4675.78 4702.87 4659.89 4701.46]\n",
      " [4678.48 4699.39 4652.66 4690.7 ]\n",
      " [4712.   4743.83 4682.17 4682.94]\n",
      " [4708.44 4717.75 4694.22 4697.96]]\n",
      "fake_output:\n",
      " [[4688.70889114 4704.17021209 4654.18901314 4671.40616828]]\n",
      "real_output:\n",
      " [[4700.72 4708.8  4672.78 4704.54]]\n",
      "9 [D loss: 1.567048, acc.: 50.00%] [G loss: 4.543530]\n",
      "input:\n",
      " [[4679.42 4714.95 4679.42 4700.9 ]\n",
      " [4689.3  4697.42 4672.86 4682.8 ]\n",
      " [4655.24 4688.47 4650.77 4682.85]\n",
      " [4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]]\n",
      "fake_output:\n",
      " [[4671.38378239 4689.39359131 4656.35607092 4671.57485236]]\n",
      "real_output:\n",
      " [[4707.25 4708.53 4670.87 4685.25]]\n",
      "10 [D loss: 1.443132, acc.: 50.00%] [G loss: 4.102243]\n",
      "input:\n",
      " [[3046.61 3068.67 3023.4  3029.73]\n",
      " [3015.65 3036.25 2969.75 3036.13]\n",
      " [3004.08 3021.72 2988.17 2991.77]\n",
      " [2948.05 2956.76 2933.59 2955.45]\n",
      " [2969.95 2978.5  2938.57 2948.51]]\n",
      "fake_output:\n",
      " [[2997.48986092 3010.23263162 2970.86587534 2991.05956487]]\n",
      "real_output:\n",
      " [[2953.63 2980.29 2953.63 2971.61]]\n",
      "11 [D loss: 1.519872, acc.: 50.00%] [G loss: 3.741272]\n",
      "input:\n",
      " [[4210.77 4218.36 4203.57 4204.11]\n",
      " [4201.94 4213.38 4197.78 4200.88]\n",
      " [4191.59 4202.61 4184.11 4195.99]\n",
      " [4205.94 4213.42 4182.52 4188.13]\n",
      " [4170.16 4209.52 4170.16 4197.05]]\n",
      "fake_output:\n",
      " [[4196.5743167  4211.19629552 4187.67055927 4196.99253289]]\n",
      "real_output:\n",
      " [[4168.61 4188.72 4151.72 4155.86]]\n",
      "12 [D loss: 1.370327, acc.: 50.00%] [G loss: 4.320023]\n",
      "input:\n",
      " [[4170.46 4179.57 4123.69 4134.98]\n",
      " [4128.42 4175.02 4126.35 4173.42]\n",
      " [4159.18 4159.18 4118.38 4134.94]\n",
      " [4179.8  4180.81 4150.47 4163.26]\n",
      " [4174.14 4191.31 4170.75 4185.47]]\n",
      "fake_output:\n",
      " [[4162.58981385 4176.48745135 4138.14868373 4157.64382357]]\n",
      "real_output:\n",
      " [[4139.76 4173.49 4139.76 4170.42]]\n",
      "13 [D loss: 1.283077, acc.: 50.00%] [G loss: 4.752792]\n",
      "input:\n",
      " [[4130.1  4148.   4124.43 4141.59]\n",
      " [4124.71 4131.76 4114.82 4127.99]\n",
      " [4096.11 4129.48 4095.51 4128.8 ]\n",
      " [4089.95 4098.19 4082.54 4097.17]\n",
      " [4074.29 4083.13 4068.31 4079.95]]\n",
      "fake_output:\n",
      " [[4103.92824913 4117.10520923 4097.31343007 4114.35486455]]\n",
      "real_output:\n",
      " [[4075.57 4086.23 4068.14 4073.94]]\n",
      "14 [D loss: 1.278242, acc.: 50.17%] [G loss: 3.762130]\n",
      "input:\n",
      " [[4406.51 4412.02 4386.22 4391.34]\n",
      " [4383.73 4429.97 4383.73 4399.76]\n",
      " [4319.57 4365.57 4290.49 4363.55]\n",
      " [4309.87 4369.23 4309.87 4345.72]\n",
      " [4348.84 4355.51 4278.94 4300.46]]\n",
      "fake_output:\n",
      " [[4355.30410857 4384.93637507 4330.98791332 4358.84209757]]\n",
      "real_output:\n",
      " [[4317.16 4375.19 4288.52 4357.04]]\n",
      "15 [D loss: 1.176769, acc.: 50.00%] [G loss: 3.703121]\n",
      "input:\n",
      " [[4408.86 4429.76 4408.86 4429.1 ]\n",
      " [4415.95 4416.17 4400.23 4402.66]\n",
      " [4392.74 4423.79 4373.   4423.15]\n",
      " [4406.86 4422.18 4384.81 4387.16]\n",
      " [4395.12 4412.25 4389.65 4395.26]]\n",
      "fake_output:\n",
      " [[4404.26095692 4420.37627049 4391.01049126 4406.54398578]]\n",
      "real_output:\n",
      " [[4403.59 4429.97 4403.59 4419.15]]\n",
      "16 [D loss: 1.166148, acc.: 50.17%] [G loss: 4.438538]\n",
      "input:\n",
      " [[3288.26 3302.73 3284.53 3294.61]\n",
      " [3270.45 3272.17 3220.26 3271.12]\n",
      " [3231.76 3250.92 3204.13 3246.22]\n",
      " [3227.22 3264.74 3227.22 3258.44]\n",
      " [3234.27 3243.72 3216.17 3218.44]]\n",
      "fake_output:\n",
      " [[3252.45121241 3264.67291121 3228.99970974 3254.97801702]]\n",
      "real_output:\n",
      " [[3219.84 3241.43 3214.25 3239.41]]\n",
      "17 [D loss: 1.177596, acc.: 50.00%] [G loss: 3.484707]\n",
      "input:\n",
      " [[4572.87 4608.08 4567.59 4605.38]\n",
      " [4562.84 4597.55 4562.84 4596.42]\n",
      " [4580.22 4584.57 4551.66 4551.68]\n",
      " [4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]]\n",
      "fake_output:\n",
      " [[4569.99782279 4591.39257648 4557.99620725 4577.98465274]]\n",
      "real_output:\n",
      " [[4546.12 4559.67 4524.   4544.9 ]]\n",
      "18 [D loss: 1.106905, acc.: 50.00%] [G loss: 4.117891]\n",
      "input:\n",
      " [[3731.17 3784.32 3725.62 3773.86]\n",
      " [3778.05 3778.05 3694.12 3714.24]\n",
      " [3755.75 3830.5  3755.75 3787.38]\n",
      " [3836.83 3836.83 3732.48 3750.77]\n",
      " [3862.96 3870.9  3847.78 3849.62]]\n",
      "fake_output:\n",
      " [[3793.6437841  3816.8167446  3748.37847896 3772.05656569]]\n",
      "real_output:\n",
      " [[3851.68 3859.23 3797.16 3855.36]]\n",
      "19 [D loss: 1.097388, acc.: 50.00%] [G loss: 4.841926]\n",
      "input:\n",
      " [[3064.78 3081.07 3051.64 3080.82]\n",
      " [3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]\n",
      " [3015.65 3036.25 2969.75 3036.13]]\n",
      "fake_output:\n",
      " [[3039.10114553 3058.28244629 3014.53948461 3047.80989801]]\n",
      "real_output:\n",
      " [[3004.08 3021.72 2988.17 2991.77]]\n",
      "20 [D loss: 1.094305, acc.: 50.17%] [G loss: 3.441336]\n",
      "input:\n",
      " [[4513.02 4529.9  4492.07 4493.28]\n",
      " [4518.09 4521.79 4493.95 4514.07]\n",
      " [4535.38 4535.38 4513.   4520.03]\n",
      " [4532.42 4541.45 4521.3  4535.43]\n",
      " [4534.48 4545.85 4524.66 4536.95]]\n",
      "fake_output:\n",
      " [[4526.67730199 4534.29513853 4508.81920007 4519.3914527 ]]\n",
      "real_output:\n",
      " [[4528.8  4537.11 4522.02 4524.09]]\n",
      "21 [D loss: 1.069155, acc.: 50.00%] [G loss: 3.131075]\n",
      "input:\n",
      " [[3600.16 3628.51 3600.16 3626.91]\n",
      " [3552.57 3593.66 3552.57 3585.15]\n",
      " [3562.67 3569.02 3518.58 3537.01]\n",
      " [3563.22 3581.16 3557.   3572.66]\n",
      " [3543.26 3557.22 3511.91 3545.53]]\n",
      "fake_output:\n",
      " [[3565.67574208 3584.34278234 3547.69674211 3571.62790727]]\n",
      "real_output:\n",
      " [[3583.04 3645.99 3547.48 3550.5 ]]\n",
      "22 [D loss: 1.033009, acc.: 50.00%] [G loss: 3.065421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " [[3494.69 3509.23 3484.32 3508.01]\n",
      " [3485.14 3501.38 3468.35 3484.55]\n",
      " [3449.97 3481.07 3444.15 3478.73]\n",
      " [3435.95 3444.21 3425.84 3443.62]\n",
      " [3418.09 3432.09 3413.13 3431.28]]\n",
      "fake_output:\n",
      " [[3458.2676378  3472.16863536 3448.30733845 3468.17007476]]\n",
      "real_output:\n",
      " [[3386.01 3399.96 3379.31 3397.16]]\n",
      "23 [D loss: 1.034322, acc.: 50.00%] [G loss: 3.739196]\n",
      "input:\n",
      " [[3224.29 3258.61 3215.16 3251.84]\n",
      " [3224.21 3233.52 3205.65 3224.73]\n",
      " [3208.36 3220.39 3198.59 3215.57]\n",
      " [3225.98 3238.28 3200.76 3226.56]\n",
      " [3141.11 3200.95 3127.66 3197.52]]\n",
      "fake_output:\n",
      " [[3205.92996121 3229.05621316 3189.45732615 3222.19413211]]\n",
      "real_output:\n",
      " [[3205.08 3235.32 3149.43 3155.22]]\n",
      "24 [D loss: 1.031813, acc.: 50.00%] [G loss: 2.945321]\n",
      "input:\n",
      " [[4469.74 4471.52 4427.76 4432.99]\n",
      " [4477.09 4485.87 4443.8  4473.75]\n",
      " [4447.49 4486.87 4438.37 4480.7 ]\n",
      " [4479.33 4485.68 4435.46 4443.05]\n",
      " [4474.81 4492.99 4445.7  4468.73]]\n",
      "fake_output:\n",
      " [[4469.99197775 4484.24102018 4438.54155424 4459.41175273]]\n",
      "real_output:\n",
      " [[4506.92 4520.47 4457.66 4458.58]]\n",
      "25 [D loss: 1.017124, acc.: 50.00%] [G loss: 2.356962]\n",
      "input:\n",
      " [[3392.51 3399.54 3369.66 3374.85]\n",
      " [3387.04 3395.06 3370.15 3389.78]\n",
      " [3380.86 3387.59 3379.22 3381.99]\n",
      " [3368.66 3378.51 3361.64 3372.85]\n",
      " [3372.95 3387.24 3363.35 3373.43]]\n",
      "fake_output:\n",
      " [[3380.62484989 3389.09233033 3368.70826656 3378.27897283]]\n",
      "real_output:\n",
      " [[3355.46 3387.89 3355.46 3380.35]]\n",
      "26 [D loss: 0.980360, acc.: 50.00%] [G loss: 3.770726]\n",
      "input:\n",
      " [[4580.22 4584.57 4551.66 4551.68]\n",
      " [4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]\n",
      " [4546.12 4559.67 4524.   4544.9 ]\n",
      " [4532.24 4551.44 4526.89 4549.78]]\n",
      "fake_output:\n",
      " [[4558.1955541  4572.18194578 4541.37753048 4556.85371965]]\n",
      "real_output:\n",
      " [[4524.42 4540.87 4524.4  4536.19]]\n",
      "27 [D loss: 0.981020, acc.: 50.17%] [G loss: 3.736107]\n",
      "input:\n",
      " [[4534.48 4545.85 4524.66 4536.95]\n",
      " [4528.8  4537.11 4522.02 4524.09]\n",
      " [4529.75 4531.39 4515.8  4522.68]\n",
      " [4513.76 4537.36 4513.76 4528.79]\n",
      " [4474.1  4513.33 4474.1  4509.37]]\n",
      "fake_output:\n",
      " [[4516.64414925 4532.13137895 4509.94641448 4523.72903419]]\n",
      "real_output:\n",
      " [[4493.75 4495.9  4468.99 4470.  ]]\n",
      "28 [D loss: 0.992620, acc.: 50.00%] [G loss: 2.534684]\n",
      "input:\n",
      " [[4232.99 4237.09 4218.74 4219.55]\n",
      " [4233.81 4236.74 4208.41 4227.26]\n",
      " [4229.34 4232.34 4215.66 4226.52]\n",
      " [4206.05 4233.45 4206.05 4229.89]\n",
      " [4191.43 4204.39 4167.93 4192.85]]\n",
      "fake_output:\n",
      " [[4219.57178125 4227.77907482 4203.44245998 4218.30132287]]\n",
      "real_output:\n",
      " [[4206.82 4217.37 4198.27 4208.12]]\n",
      "29 [D loss: 0.964394, acc.: 50.00%] [G loss: 2.731145]\n",
      "input:\n",
      " [[4141.58 4151.69 4120.87 4124.66]\n",
      " [4130.1  4148.   4124.43 4141.59]\n",
      " [4124.71 4131.76 4114.82 4127.99]\n",
      " [4096.11 4129.48 4095.51 4128.8 ]\n",
      " [4089.95 4098.19 4082.54 4097.17]]\n",
      "fake_output:\n",
      " [[4116.59993343 4129.354725   4106.71201155 4122.73917508]]\n",
      "real_output:\n",
      " [[4074.29 4083.13 4068.31 4079.95]]\n",
      "30 [D loss: 0.961953, acc.: 50.00%] [G loss: 2.796411]\n",
      "input:\n",
      " [[4395.12 4412.25 4389.65 4395.26]\n",
      " [4403.59 4429.97 4403.59 4419.15]\n",
      " [4402.95 4415.47 4387.01 4400.64]\n",
      " [4416.38 4416.38 4372.51 4401.46]\n",
      " [4409.58 4422.73 4405.45 4422.3 ]]\n",
      "fake_output:\n",
      " [[4405.65269757 4418.78180835 4391.70222935 4406.9741955 ]]\n",
      "real_output:\n",
      " [[4381.2  4415.18 4381.2  4411.79]]\n",
      "31 [D loss: 0.957791, acc.: 50.33%] [G loss: 3.101385]\n",
      "input:\n",
      " [[3793.58 3851.69 3730.19 3841.94]\n",
      " [3818.53 3843.67 3723.34 3768.47]\n",
      " [3863.99 3874.47 3818.86 3819.72]\n",
      " [3903.64 3906.41 3868.57 3870.29]\n",
      " [3842.51 3914.5  3842.51 3901.82]]\n",
      "fake_output:\n",
      " [[3845.33637061 3876.42234077 3797.39424599 3838.50652736]]\n",
      "real_output:\n",
      " [[3839.66 3861.08 3789.54 3811.15]]\n",
      "32 [D loss: 0.938999, acc.: 50.00%] [G loss: 3.367622]\n",
      "input:\n",
      " [[2794.54 2852.8  2766.64 2852.5 ]\n",
      " [2865.86 2874.14 2793.15 2820.  ]\n",
      " [2939.5  2945.82 2869.59 2870.12]\n",
      " [2915.46 2944.25 2903.44 2930.32]\n",
      " [2908.83 2932.16 2902.88 2929.8 ]]\n",
      "fake_output:\n",
      " [[2886.46948335 2906.84758658 2848.06195103 2878.22241907]]\n",
      "real_output:\n",
      " [[2878.26 2901.92 2876.48 2881.19]]\n",
      "33 [D loss: 0.940257, acc.: 50.17%] [G loss: 3.570046]\n",
      "input:\n",
      " [[3919.93 3942.08 3889.07 3889.14]\n",
      " [3937.6  3949.13 3901.57 3910.52]\n",
      " [3916.48 3955.31 3914.16 3940.59]\n",
      " [3913.14 3930.12 3886.75 3913.1 ]\n",
      " [3953.5  3969.62 3910.86 3915.46]]\n",
      "fake_output:\n",
      " [[3928.64594077 3948.1665905  3900.54565979 3912.14759454]]\n",
      "real_output:\n",
      " [[3949.57 3983.87 3935.74 3974.12]]\n",
      "34 [D loss: 0.940190, acc.: 50.17%] [G loss: 3.107611]\n",
      "input:\n",
      " [[4406.75 4465.4  4406.75 4448.98]\n",
      " [4367.43 4416.75 4367.43 4395.64]\n",
      " [4374.45 4394.87 4347.96 4354.19]\n",
      " [4402.95 4402.95 4305.91 4357.73]\n",
      " [4469.74 4471.52 4427.76 4432.99]]\n",
      "fake_output:\n",
      " [[4405.10757279 4424.14613314 4364.9947799  4390.92200879]]\n",
      "real_output:\n",
      " [[4477.09 4485.87 4443.8  4473.75]]\n",
      "35 [D loss: 0.948391, acc.: 50.00%] [G loss: 2.554926]\n",
      "input:\n",
      " [[3367.27 3409.57 3367.27 3408.63]\n",
      " [3338.94 3369.1  3323.69 3348.44]\n",
      " [3385.87 3397.18 3361.39 3380.8 ]\n",
      " [3341.21 3393.56 3340.47 3363.  ]\n",
      " [3350.92 3357.92 3327.54 3335.47]]\n",
      "fake_output:\n",
      " [[3357.3556647  3384.03551919 3344.23169625 3366.0185283 ]]\n",
      "real_output:\n",
      " [[3333.9  3360.74 3332.91 3351.6 ]]\n",
      "36 [D loss: 0.883889, acc.: 50.17%] [G loss: 2.910222]\n",
      "input:\n",
      " [[3236.66 3306.88 3228.44 3298.46]\n",
      " [3226.14 3278.7  3209.45 3246.59]\n",
      " [3320.11 3323.35 3232.57 3236.92]\n",
      " [3295.75 3320.31 3270.95 3315.57]\n",
      " [3285.57 3285.57 3229.1  3281.06]]\n",
      "fake_output:\n",
      " [[3275.04632903 3302.15433528 3235.60643128 3274.93787705]]\n",
      "real_output:\n",
      " [[3357.38 3362.27 3292.4  3319.47]]\n",
      "37 [D loss: 0.905284, acc.: 50.00%] [G loss: 3.367673]\n",
      "input:\n",
      " [[3384.56 3426.26 3384.56 3419.45]\n",
      " [3408.74 3431.56 3354.54 3360.95]\n",
      " [3367.27 3409.57 3367.27 3408.63]\n",
      " [3338.94 3369.1  3323.69 3348.44]\n",
      " [3385.87 3397.18 3361.39 3380.8 ]]\n",
      "fake_output:\n",
      " [[3377.56698859 3402.61718097 3356.24776767 3379.62689899]]\n",
      "real_output:\n",
      " [[3341.21 3393.56 3340.47 3363.  ]]\n",
      "38 [D loss: 0.879095, acc.: 50.50%] [G loss: 3.877084]\n",
      "input:\n",
      " [[4374.45 4394.87 4347.96 4354.19]\n",
      " [4402.95 4402.95 4305.91 4357.73]\n",
      " [4469.74 4471.52 4427.76 4432.99]\n",
      " [4477.09 4485.87 4443.8  4473.75]\n",
      " [4447.49 4486.87 4438.37 4480.7 ]]\n",
      "fake_output:\n",
      " [[4434.76957489 4442.70754618 4387.31105686 4411.86273301]]\n",
      "real_output:\n",
      " [[4479.33 4485.68 4435.46 4443.05]]\n",
      "39 [D loss: 0.879899, acc.: 50.50%] [G loss: 2.726261]\n",
      "input:\n",
      " [[2913.86 2968.09 2913.86 2953.91]\n",
      " [2829.95 2865.01 2816.78 2863.7 ]\n",
      " [2794.54 2852.8  2766.64 2852.5 ]\n",
      " [2865.86 2874.14 2793.15 2820.  ]\n",
      " [2939.5  2945.82 2869.59 2870.12]]\n",
      "fake_output:\n",
      " [[2865.81135575 2891.80894413 2825.39302681 2864.27526242]]\n",
      "real_output:\n",
      " [[2915.46 2944.25 2903.44 2930.32]]\n",
      "40 [D loss: 0.871934, acc.: 50.00%] [G loss: 2.690248]\n",
      "input:\n",
      " [[3386.01 3399.96 3379.31 3397.16]\n",
      " [3360.48 3390.8  3354.69 3385.51]\n",
      " [3392.51 3399.54 3369.66 3374.85]\n",
      " [3387.04 3395.06 3370.15 3389.78]\n",
      " [3380.86 3387.59 3379.22 3381.99]]\n",
      "fake_output:\n",
      " [[3380.74257823 3393.61563794 3369.3594408  3384.64637619]]\n",
      "real_output:\n",
      " [[3368.66 3378.51 3361.64 3372.85]]\n",
      "41 [D loss: 0.882677, acc.: 50.50%] [G loss: 3.567841]\n",
      "input:\n",
      " [[3098.9  3130.94 3098.9  3122.87]\n",
      " [3064.78 3081.07 3051.64 3080.82]\n",
      " [3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]]\n",
      "fake_output:\n",
      " [[3054.20602292 3073.41297349 3037.43644765 3062.54261063]]\n",
      "real_output:\n",
      " [[3015.65 3036.25 2969.75 3036.13]]\n",
      "42 [D loss: 0.855219, acc.: 50.67%] [G loss: 3.195510]\n",
      "input:\n",
      " [[3583.04 3645.99 3547.48 3550.5 ]\n",
      " [3508.34 3521.58 3484.34 3509.44]\n",
      " [3485.74 3529.05 3485.74 3510.45]\n",
      " [3406.46 3486.25 3405.17 3443.44]\n",
      " [3336.25 3389.49 3336.25 3369.16]]\n",
      "fake_output:\n",
      " [[3473.41054517 3515.2636783  3461.17586168 3477.68965356]]\n",
      "real_output:\n",
      " [[3296.2  3330.14 3279.74 3310.24]]\n",
      "43 [D loss: 0.873970, acc.: 50.67%] [G loss: 2.781297]\n",
      "input:\n",
      " [[3949.57 3983.87 3935.74 3974.12]\n",
      " [3973.59 3981.04 3953.44 3962.71]\n",
      " [3942.96 3970.08 3923.54 3968.94]\n",
      " [3924.52 3944.99 3915.21 3943.34]\n",
      " [3915.54 3960.27 3915.54 3939.34]]\n",
      "fake_output:\n",
      " [[3940.78389603 3964.68798817 3926.12732565 3954.43320786]]\n",
      "real_output:\n",
      " [[3891.99 3917.35 3885.73 3898.81]]\n",
      "44 [D loss: 0.821323, acc.: 51.33%] [G loss: 3.683621]\n",
      "input:\n",
      " [[4710.3  4710.3  4667.6  4668.97]\n",
      " [4687.64 4713.57 4670.24 4712.02]\n",
      " [4691.   4695.26 4665.98 4667.45]\n",
      " [4690.86 4705.06 4674.52 4701.21]\n",
      " [4631.97 4694.04 4631.97 4686.75]]\n",
      "fake_output:\n",
      " [[4684.64614261 4703.56689991 4663.06191181 4687.40998141]]\n",
      "real_output:\n",
      " [[4548.37 4612.6  4540.51 4591.67]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 [D loss: 0.844635, acc.: 50.83%] [G loss: 2.652634]\n",
      "input:\n",
      " [[3270.45 3272.17 3220.26 3271.12]\n",
      " [3231.76 3250.92 3204.13 3246.22]\n",
      " [3227.22 3264.74 3227.22 3258.44]\n",
      " [3234.27 3243.72 3216.17 3218.44]\n",
      " [3219.84 3241.43 3214.25 3239.41]]\n",
      "fake_output:\n",
      " [[3232.98274187 3246.95406325 3212.26600347 3236.26112197]]\n",
      "real_output:\n",
      " [[3218.58 3227.26 3200.05 3215.63]]\n",
      "46 [D loss: 0.820982, acc.: 51.50%] [G loss: 2.822596]\n",
      "input:\n",
      " [[4356.32 4417.35 4222.62 4410.13]\n",
      " [4471.38 4494.52 4395.34 4397.94]\n",
      " [4547.35 4602.11 4477.95 4482.73]\n",
      " [4588.03 4611.55 4530.2  4532.76]\n",
      " [4632.24 4632.24 4568.7  4577.11]]\n",
      "fake_output:\n",
      " [[4515.94577628 4537.55948424 4425.89126047 4470.76213098]]\n",
      "real_output:\n",
      " [[4637.99 4665.13 4614.75 4662.85]]\n",
      "47 [D loss: 0.829555, acc.: 50.50%] [G loss: 2.681247]\n",
      "input:\n",
      " [[3234.27 3243.72 3216.17 3218.44]\n",
      " [3219.84 3241.43 3214.25 3239.41]\n",
      " [3218.58 3227.26 3200.05 3215.63]\n",
      " [3271.64 3279.99 3222.66 3235.66]\n",
      " [3254.86 3279.32 3253.1  3276.02]]\n",
      "fake_output:\n",
      " [[3239.077245   3251.12667105 3220.20781164 3234.22977234]]\n",
      "real_output:\n",
      " [[3268.52 3277.29 3247.77 3257.3 ]]\n",
      "48 [D loss: 0.862763, acc.: 50.50%] [G loss: 2.170844]\n",
      "input:\n",
      " [[4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]\n",
      " [4546.12 4559.67 4524.   4544.9 ]\n",
      " [4532.24 4551.44 4526.89 4549.78]\n",
      " [4524.42 4540.87 4524.4  4536.19]]\n",
      "fake_output:\n",
      " [[4547.20671126 4563.13837256 4536.34091826 4553.80975864]]\n",
      "real_output:\n",
      " [[4497.34 4520.4  4496.41 4519.63]]\n",
      "49 [D loss: 0.842779, acc.: 50.17%] [G loss: 1.875752]\n",
      "input:\n",
      " [[4804.51 4818.62 4774.27 4793.54]\n",
      " [4778.14 4796.64 4758.17 4796.56]\n",
      " [4775.21 4786.83 4765.75 4766.18]\n",
      " [4794.23 4808.93 4775.33 4778.73]\n",
      " [4788.64 4804.06 4778.08 4793.06]]\n",
      "fake_output:\n",
      " [[4787.84513297 4801.24671071 4769.6386617  4783.69499099]]\n",
      "real_output:\n",
      " [[4795.49 4807.02 4780.04 4786.35]]\n",
      "50 [D loss: 0.828257, acc.: 50.67%] [G loss: 1.891883]\n",
      "input:\n",
      " [[4664.63 4664.63 4585.43 4594.62]\n",
      " [4675.78 4702.87 4659.89 4701.46]\n",
      " [4678.48 4699.39 4652.66 4690.7 ]\n",
      " [4712.   4743.83 4682.17 4682.94]\n",
      " [4708.44 4717.75 4694.22 4697.96]]\n",
      "fake_output:\n",
      " [[4688.87401995 4703.40446802 4654.50709375 4671.26950406]]\n",
      "real_output:\n",
      " [[4700.72 4708.8  4672.78 4704.54]]\n",
      "51 [D loss: 0.820414, acc.: 50.67%] [G loss: 2.063672]\n",
      "input:\n",
      " [[2812.64 2842.71 2791.76 2836.74]\n",
      " [2810.42 2844.9  2794.26 2797.8 ]\n",
      " [2787.89 2815.1  2775.95 2799.31]\n",
      " [2784.81 2785.54 2727.1  2736.56]\n",
      " [2845.62 2868.98 2820.43 2823.16]]\n",
      "fake_output:\n",
      " [[2807.74374473 2825.0119902  2778.62398998 2790.2097922 ]]\n",
      "real_output:\n",
      " [[2842.43 2879.22 2830.88 2874.56]]\n",
      "52 [D loss: 0.803162, acc.: 50.67%] [G loss: 2.575820]\n",
      "input:\n",
      " [[4034.44 4083.42 4034.44 4077.91]\n",
      " [3992.78 4020.63 3992.78 4019.87]\n",
      " [3967.25 3994.41 3966.98 3972.89]\n",
      " [3963.34 3968.01 3944.35 3958.55]\n",
      " [3969.31 3981.83 3943.25 3971.09]]\n",
      "fake_output:\n",
      " [[3982.4404483  3998.27778168 3968.15880359 3987.39563823]]\n",
      "real_output:\n",
      " [[3917.12 3978.19 3917.12 3974.54]]\n",
      "53 [D loss: 0.804551, acc.: 50.83%] [G loss: 3.881144]\n",
      "input:\n",
      " [[3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]\n",
      " [3015.65 3036.25 2969.75 3036.13]\n",
      " [3004.08 3021.72 2988.17 2991.77]\n",
      " [2948.05 2956.76 2933.59 2955.45]]\n",
      "fake_output:\n",
      " [[3001.75997017 3011.51024476 2971.87641964 2998.75050173]]\n",
      "real_output:\n",
      " [[2969.95 2978.5  2938.57 2948.51]]\n",
      "54 [D loss: 0.811559, acc.: 51.17%] [G loss: 2.496070]\n",
      "input:\n",
      " [[4265.11 4336.84 4262.05 4323.06]\n",
      " [4296.4  4296.4  4233.13 4258.49]\n",
      " [4367.43 4375.09 4322.53 4327.16]\n",
      " [4369.02 4369.02 4340.7  4360.03]\n",
      " [4380.11 4393.68 4362.36 4374.3 ]]\n",
      "fake_output:\n",
      " [[4325.79582122 4336.37815061 4280.69908946 4306.70889988]]\n",
      "real_output:\n",
      " [[4381.07 4392.37 4366.92 4369.21]]\n",
      "55 [D loss: 0.784540, acc.: 51.33%] [G loss: 2.254619]\n",
      "input:\n",
      " [[3105.92 3128.44 3101.17 3115.86]\n",
      " [3050.2  3111.51 3047.83 3100.29]\n",
      " [3018.59 3053.89 2999.74 3053.24]\n",
      " [3073.2  3073.73 3004.63 3009.05]\n",
      " [3046.6  3086.25 3024.01 3083.76]]\n",
      "fake_output:\n",
      " [[3053.16592298 3080.00559561 3022.81577226 3057.19954255]]\n",
      "real_output:\n",
      " [[3114.4  3115.01 3032.13 3050.33]]\n",
      "56 [D loss: 0.804206, acc.: 50.83%] [G loss: 2.772483]\n",
      "input:\n",
      " [[4699.26 4718.5  4681.32 4697.53]\n",
      " [4662.93 4683.   4662.59 4680.06]\n",
      " [4630.65 4663.46 4621.19 4660.57]\n",
      " [4613.34 4635.15 4613.34 4630.65]\n",
      " [4610.62 4620.34 4595.06 4613.67]]\n",
      "fake_output:\n",
      " [[4639.0300673  4652.77982392 4626.69199562 4647.18333531]]\n",
      "real_output:\n",
      " [[4572.87 4608.08 4567.59 4605.38]]\n",
      "57 [D loss: 0.812247, acc.: 51.17%] [G loss: 1.978997]\n",
      "input:\n",
      " [[3213.42 3223.27 3181.49 3190.14]\n",
      " [3213.32 3222.71 3193.11 3207.18]\n",
      " [3199.92 3233.13 3196.   3232.39]\n",
      " [3163.84 3211.72 3163.84 3193.93]\n",
      " [3111.56 3128.91 3090.41 3112.35]]\n",
      "fake_output:\n",
      " [[3179.85655039 3199.38544875 3163.4262561  3181.82383498]]\n",
      "real_output:\n",
      " [[3098.9  3130.94 3098.9  3122.87]]\n",
      "58 [D loss: 0.778276, acc.: 51.33%] [G loss: 2.299825]\n",
      "input:\n",
      " [[3153.07 3171.8  3136.53 3169.94]\n",
      " [3166.44 3184.15 3142.93 3145.32]\n",
      " [3155.29 3182.59 3155.29 3179.72]\n",
      " [3143.64 3165.81 3124.52 3130.01]\n",
      " [3105.92 3128.44 3101.17 3115.86]]\n",
      "fake_output:\n",
      " [[3134.74014152 3148.45379066 3116.73358227 3126.03818359]]\n",
      "real_output:\n",
      " [[3050.2  3111.51 3047.83 3100.29]]\n",
      "59 [D loss: 0.787370, acc.: 51.50%] [G loss: 2.855013]\n",
      "input:\n",
      " [[4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]\n",
      " [4707.25 4708.53 4670.87 4685.25]\n",
      " [4701.48 4714.92 4694.39 4701.7 ]\n",
      " [4699.26 4718.5  4681.32 4697.53]]\n",
      "fake_output:\n",
      " [[4678.24684543 4677.27293376 4644.00818048 4652.01525023]]\n",
      "real_output:\n",
      " [[4662.93 4683.   4662.59 4680.06]]\n",
      "60 [D loss: 0.776363, acc.: 52.17%] [G loss: 2.833976]\n",
      "input:\n",
      " [[3350.92 3357.92 3327.54 3335.47]\n",
      " [3333.9  3360.74 3332.91 3351.6 ]\n",
      " [3236.66 3306.88 3228.44 3298.46]\n",
      " [3226.14 3278.7  3209.45 3246.59]\n",
      " [3320.11 3323.35 3232.57 3236.92]]\n",
      "fake_output:\n",
      " [[3280.53179421 3309.71433138 3244.16245729 3270.71656156]]\n",
      "real_output:\n",
      " [[3295.75 3320.31 3270.95 3315.57]]\n",
      "61 [D loss: 0.775063, acc.: 52.00%] [G loss: 2.067968]\n",
      "input:\n",
      " [[4293.21 4300.52 4287.04 4291.8 ]\n",
      " [4284.9  4292.14 4274.67 4290.61]\n",
      " [4274.45 4286.12 4271.16 4280.7 ]\n",
      " [4256.97 4271.28 4256.97 4266.49]\n",
      " [4249.27 4256.6  4241.43 4241.84]]\n",
      "fake_output:\n",
      " [[4270.2202303  4277.90939261 4264.16987234 4270.35591296]]\n",
      "real_output:\n",
      " [[4224.61 4255.84 4217.27 4246.44]]\n",
      "62 [D loss: 0.770952, acc.: 52.00%] [G loss: 3.053813]\n",
      "input:\n",
      " [[4321.07 4330.88 4289.37 4320.82]\n",
      " [4351.01 4361.88 4329.79 4358.13]\n",
      " [4356.46 4356.46 4314.37 4343.54]\n",
      " [4326.6  4355.43 4326.6  4352.34]\n",
      " [4300.73 4320.66 4300.73 4319.94]]\n",
      "fake_output:\n",
      " [[4327.33727147 4337.49311686 4307.4433513  4332.89964047]]\n",
      "real_output:\n",
      " [[4290.65 4302.43 4287.96 4297.5 ]]\n",
      "63 [D loss: 0.761670, acc.: 51.67%] [G loss: 2.805107]\n",
      "input:\n",
      " [[3612.09 3619.09 3567.33 3567.79]\n",
      " [3610.31 3623.11 3588.68 3609.53]\n",
      " [3600.16 3628.51 3600.16 3626.91]\n",
      " [3552.57 3593.66 3552.57 3585.15]\n",
      " [3562.67 3569.02 3518.58 3537.01]]\n",
      "fake_output:\n",
      " [[3584.87610878 3601.20322185 3560.87347849 3578.24213183]]\n",
      "real_output:\n",
      " [[3563.22 3581.16 3557.   3572.66]]\n",
      "64 [D loss: 0.765987, acc.: 51.67%] [G loss: 1.936154]\n",
      "input:\n",
      " [[3862.96 3870.9  3847.78 3849.62]\n",
      " [3851.68 3859.23 3797.16 3855.36]\n",
      " [3844.24 3852.31 3830.41 3841.47]\n",
      " [3857.46 3861.45 3845.05 3853.07]\n",
      " [3816.22 3859.75 3816.22 3851.85]]\n",
      "fake_output:\n",
      " [[3843.16301544 3858.47631889 3821.53139448 3848.53841953]]\n",
      "real_output:\n",
      " [[3781.88 3804.53 3780.37 3798.91]]\n",
      "65 [D loss: 0.749208, acc.: 52.33%] [G loss: 2.821765]\n",
      "input:\n",
      " [[4504.73 4595.46 4504.73 4577.1 ]\n",
      " [4602.82 4652.94 4510.27 4513.04]\n",
      " [4640.25 4646.02 4560.   4567.  ]\n",
      " [4628.75 4672.95 4625.26 4655.27]\n",
      " [4664.63 4664.63 4585.43 4594.62]]\n",
      "fake_output:\n",
      " [[4604.33519405 4641.43985227 4552.80188099 4573.37978053]]\n",
      "real_output:\n",
      " [[4675.78 4702.87 4659.89 4701.46]]\n",
      "66 [D loss: 0.756204, acc.: 52.17%] [G loss: 2.612549]\n",
      "input:\n",
      " [[3371.88 3379.97 3329.27 3331.84]\n",
      " [3453.6  3479.15 3349.63 3426.96]\n",
      " [3564.74 3564.85 3427.41 3455.06]\n",
      " [3543.76 3588.11 3535.23 3580.84]\n",
      " [3507.44 3528.03 3494.6  3526.65]]\n",
      "fake_output:\n",
      " [[3475.47464092 3483.82164479 3407.3444207  3437.5581343 ]]\n",
      "real_output:\n",
      " [[3509.73 3514.77 3493.25 3500.31]]\n",
      "67 [D loss: 0.752701, acc.: 51.50%] [G loss: 2.877906]\n",
      "input:\n",
      " [[4367.43 4375.09 4322.53 4327.16]\n",
      " [4369.02 4369.02 4340.7  4360.03]\n",
      " [4380.11 4393.68 4362.36 4374.3 ]\n",
      " [4381.07 4392.37 4366.92 4369.21]\n",
      " [4372.41 4386.68 4364.03 4384.63]]\n",
      "fake_output:\n",
      " [[4374.01165569 4382.22361627 4351.44145943 4361.02760221]]\n",
      "real_output:\n",
      " [[4329.38 4371.6  4329.38 4369.55]]\n",
      "68 [D loss: 0.733120, acc.: 52.17%] [G loss: 2.666223]\n",
      "input:\n",
      " [[4096.11 4129.48 4095.51 4128.8 ]\n",
      " [4089.95 4098.19 4082.54 4097.17]\n",
      " [4074.29 4083.13 4068.31 4079.95]\n",
      " [4075.57 4086.23 4068.14 4073.94]\n",
      " [4034.44 4083.42 4034.44 4077.91]]\n",
      "fake_output:\n",
      " [[4055.7907363  4072.65653635 4043.80605358 4062.49123844]]\n",
      "real_output:\n",
      " [[3992.78 4020.63 3992.78 4019.87]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 [D loss: 0.755309, acc.: 51.50%] [G loss: 1.791663]\n",
      "input:\n",
      " [[3915.54 3960.27 3915.54 3939.34]\n",
      " [3891.99 3917.35 3885.73 3898.81]\n",
      " [3851.93 3903.76 3851.93 3875.44]\n",
      " [3844.39 3881.06 3819.25 3821.35]\n",
      " [3793.58 3851.69 3730.19 3841.94]]\n",
      "fake_output:\n",
      " [[3864.17339164 3902.96122898 3850.81468122 3875.30419968]]\n",
      "real_output:\n",
      " [[3818.53 3843.67 3723.34 3768.47]]\n",
      "70 [D loss: 0.736378, acc.: 53.17%] [G loss: 3.139472]\n",
      "input:\n",
      " [[3552.57 3593.66 3552.57 3585.15]\n",
      " [3562.67 3569.02 3518.58 3537.01]\n",
      " [3563.22 3581.16 3557.   3572.66]\n",
      " [3543.26 3557.22 3511.91 3545.53]\n",
      " [3583.04 3645.99 3547.48 3550.5 ]]\n",
      "fake_output:\n",
      " [[3561.49307153 3588.08737614 3538.20750609 3557.85793736]]\n",
      "real_output:\n",
      " [[3508.34 3521.58 3484.34 3509.44]]\n",
      "71 [D loss: 0.725789, acc.: 53.00%] [G loss: 3.518611]\n",
      "input:\n",
      " [[3152.47 3186.82 3136.22 3185.04]\n",
      " [3176.17 3179.78 3115.7  3152.05]\n",
      " [3153.07 3171.8  3136.53 3169.94]\n",
      " [3166.44 3184.15 3142.93 3145.32]\n",
      " [3155.29 3182.59 3155.29 3179.72]]\n",
      "fake_output:\n",
      " [[3158.56412256 3178.7961683  3132.99213626 3159.91649447]]\n",
      "real_output:\n",
      " [[3143.64 3165.81 3124.52 3130.01]]\n",
      "72 [D loss: 0.728670, acc.: 51.67%] [G loss: 2.110028]\n",
      "input:\n",
      " [[3915.86 3921.98 3885.03 3913.97]\n",
      " [3918.5  3933.61 3900.43 3931.33]\n",
      " [3939.61 3950.43 3923.85 3932.59]\n",
      " [3911.65 3937.23 3905.78 3934.83]\n",
      " [3916.4  3925.99 3890.39 3916.38]]\n",
      "fake_output:\n",
      " [[3918.27668333 3929.98043298 3896.58046006 3922.42227829]]\n",
      "real_output:\n",
      " [[3920.78 3931.5  3884.94 3909.88]]\n",
      "73 [D loss: 0.726950, acc.: 52.83%] [G loss: 2.423861]\n",
      "input:\n",
      " [[2993.76 3079.76 2965.66 3066.59]\n",
      " [3071.04 3088.42 2984.47 3041.31]\n",
      " [3123.53 3123.53 2999.49 3002.1 ]\n",
      " [3213.42 3223.27 3181.49 3190.14]\n",
      " [3213.32 3222.71 3193.11 3207.18]]\n",
      "fake_output:\n",
      " [[3092.81202683 3113.11774993 3015.72356071 3054.45554791]]\n",
      "real_output:\n",
      " [[3199.92 3233.13 3196.   3232.39]]\n",
      "74 [D loss: 0.747459, acc.: 51.00%] [G loss: 1.884801]\n",
      "input:\n",
      " [[4655.24 4688.47 4650.77 4682.85]\n",
      " [4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]\n",
      " [4707.25 4708.53 4670.87 4685.25]\n",
      " [4701.48 4714.92 4694.39 4701.7 ]]\n",
      "fake_output:\n",
      " [[4661.65650057 4673.90473867 4637.15419677 4650.36389732]]\n",
      "real_output:\n",
      " [[4699.26 4718.5  4681.32 4697.53]]\n",
      "75 [D loss: 0.726995, acc.: 52.83%] [G loss: 2.341174]\n",
      "input:\n",
      " [[3227.22 3264.74 3227.22 3258.44]\n",
      " [3234.27 3243.72 3216.17 3218.44]\n",
      " [3219.84 3241.43 3214.25 3239.41]\n",
      " [3218.58 3227.26 3200.05 3215.63]\n",
      " [3271.64 3279.99 3222.66 3235.66]]\n",
      "fake_output:\n",
      " [[3233.00856354 3247.24921224 3215.44415392 3230.54712492]]\n",
      "real_output:\n",
      " [[3254.86 3279.32 3253.1  3276.02]]\n",
      "76 [D loss: 0.733772, acc.: 53.17%] [G loss: 2.351578]\n",
      "input:\n",
      " [[3764.61 3769.99 3662.71 3700.65]\n",
      " [3733.27 3760.2  3726.88 3756.07]\n",
      " [3736.19 3744.63 3730.21 3732.04]\n",
      " [3750.01 3756.12 3723.31 3727.04]\n",
      " [3723.03 3740.51 3723.03 3735.36]]\n",
      "fake_output:\n",
      " [[3736.59925281 3748.70421848 3701.83357429 3720.41484001]]\n",
      "real_output:\n",
      " [[3694.03 3703.82 3689.32 3703.06]]\n",
      "77 [D loss: 0.709331, acc.: 53.83%] [G loss: 2.185347]\n",
      "input:\n",
      " [[3320.11 3323.35 3232.57 3236.92]\n",
      " [3295.75 3320.31 3270.95 3315.57]\n",
      " [3285.57 3285.57 3229.1  3281.06]\n",
      " [3357.38 3362.27 3292.4  3319.47]\n",
      " [3346.86 3375.17 3328.82 3357.01]]\n",
      "fake_output:\n",
      " [[3305.33793176 3307.61639397 3241.78165968 3267.10571606]]\n",
      "real_output:\n",
      " [[3411.23 3428.92 3384.45 3385.49]]\n",
      "78 [D loss: 0.727317, acc.: 53.17%] [G loss: 2.200490]\n",
      "input:\n",
      " [[4532.42 4541.45 4521.3  4535.43]\n",
      " [4534.48 4545.85 4524.66 4536.95]\n",
      " [4528.8  4537.11 4522.02 4524.09]\n",
      " [4529.75 4531.39 4515.8  4522.68]\n",
      " [4513.76 4537.36 4513.76 4528.79]]\n",
      "fake_output:\n",
      " [[4527.5027967  4537.66937766 4519.31315086 4528.67360634]]\n",
      "real_output:\n",
      " [[4474.1  4513.33 4474.1  4509.37]]\n",
      "79 [D loss: 0.702807, acc.: 54.50%] [G loss: 2.205492]\n",
      "input:\n",
      " [[4408.86 4429.76 4408.86 4429.1 ]\n",
      " [4415.95 4416.17 4400.23 4402.66]\n",
      " [4392.74 4423.79 4373.   4423.15]\n",
      " [4406.86 4422.18 4384.81 4387.16]\n",
      " [4395.12 4412.25 4389.65 4395.26]]\n",
      "fake_output:\n",
      " [[4402.76871271 4419.33328299 4388.91713298 4403.43538749]]\n",
      "real_output:\n",
      " [[4403.59 4429.97 4403.59 4419.15]]\n",
      "80 [D loss: 0.709441, acc.: 54.00%] [G loss: 1.711574]\n",
      "input:\n",
      " [[4471.38 4494.52 4395.34 4397.94]\n",
      " [4547.35 4602.11 4477.95 4482.73]\n",
      " [4588.03 4611.55 4530.2  4532.76]\n",
      " [4632.24 4632.24 4568.7  4577.11]\n",
      " [4637.99 4665.13 4614.75 4662.85]]\n",
      "fake_output:\n",
      " [[4551.66534467 4568.57210716 4478.98251299 4481.69540722]]\n",
      "real_output:\n",
      " [[4733.56 4744.13 4650.29 4659.03]]\n",
      "81 [D loss: 0.715959, acc.: 53.33%] [G loss: 1.981059]\n",
      "input:\n",
      " [[4406.51 4412.02 4386.22 4391.34]\n",
      " [4383.73 4429.97 4383.73 4399.76]\n",
      " [4319.57 4365.57 4290.49 4363.55]\n",
      " [4309.87 4369.23 4309.87 4345.72]\n",
      " [4348.84 4355.51 4278.94 4300.46]]\n",
      "fake_output:\n",
      " [[4350.67576007 4380.26848921 4324.28070874 4352.7506538 ]]\n",
      "real_output:\n",
      " [[4317.16 4375.19 4288.52 4357.04]]\n",
      "82 [D loss: 0.704237, acc.: 54.67%] [G loss: 2.065359]\n",
      "input:\n",
      " [[3357.38 3362.27 3292.4  3319.47]\n",
      " [3346.86 3375.17 3328.82 3357.01]\n",
      " [3411.23 3428.92 3384.45 3385.49]\n",
      " [3407.73 3419.48 3389.25 3401.2 ]\n",
      " [3363.56 3402.93 3363.56 3383.54]]\n",
      "fake_output:\n",
      " [[3379.90036497 3397.9549698  3356.23361934 3370.63000416]]\n",
      "real_output:\n",
      " [[3352.7  3368.95 3310.47 3340.97]]\n",
      "83 [D loss: 0.698974, acc.: 54.17%] [G loss: 2.412958]\n",
      "input:\n",
      " [[4513.02 4529.9  4492.07 4493.28]\n",
      " [4518.09 4521.79 4493.95 4514.07]\n",
      " [4535.38 4535.38 4513.   4520.03]\n",
      " [4532.42 4541.45 4521.3  4535.43]\n",
      " [4534.48 4545.85 4524.66 4536.95]]\n",
      "fake_output:\n",
      " [[4524.63440922 4530.93887932 4505.18554732 4513.33726692]]\n",
      "real_output:\n",
      " [[4528.8  4537.11 4522.02 4524.09]]\n",
      "84 [D loss: 0.702018, acc.: 54.00%] [G loss: 1.985367]\n",
      "input:\n",
      " [[2845.62 2868.98 2820.43 2823.16]\n",
      " [2842.43 2879.22 2830.88 2874.56]\n",
      " [2799.34 2806.51 2764.32 2799.55]\n",
      " [2795.64 2801.88 2761.54 2783.36]\n",
      " [2805.1  2851.85 2805.1  2846.06]]\n",
      "fake_output:\n",
      " [[2808.00505577 2821.03697031 2779.59388573 2802.8564311 ]]\n",
      "real_output:\n",
      " [[2782.46 2782.46 2721.17 2761.63]]\n",
      "85 [D loss: 0.692036, acc.: 55.50%] [G loss: 1.716103]\n",
      "input:\n",
      " [[3803.14 3817.86 3789.02 3799.61]\n",
      " [3815.05 3826.69 3783.6  3824.68]\n",
      " [3764.71 3811.55 3764.71 3803.79]\n",
      " [3712.2  3783.04 3705.34 3748.14]\n",
      " [3698.02 3737.83 3695.07 3726.86]]\n",
      "fake_output:\n",
      " [[3753.15812261 3786.82316974 3744.21593526 3772.57127234]]\n",
      "real_output:\n",
      " [[3764.61 3769.99 3662.71 3700.65]]\n",
      "86 [D loss: 0.704177, acc.: 54.17%] [G loss: 2.263560]\n",
      "input:\n",
      " [[4406.51 4412.02 4386.22 4391.34]\n",
      " [4383.73 4429.97 4383.73 4399.76]\n",
      " [4319.57 4365.57 4290.49 4363.55]\n",
      " [4309.87 4369.23 4309.87 4345.72]\n",
      " [4348.84 4355.51 4278.94 4300.46]]\n",
      "fake_output:\n",
      " [[4349.41885414 4378.34055259 4322.19750852 4351.34909123]]\n",
      "real_output:\n",
      " [[4317.16 4375.19 4288.52 4357.04]]\n",
      "87 [D loss: 0.678876, acc.: 55.17%] [G loss: 2.173226]\n",
      "input:\n",
      " [[3755.75 3830.5  3755.75 3787.38]\n",
      " [3836.83 3836.83 3732.48 3750.77]\n",
      " [3862.96 3870.9  3847.78 3849.62]\n",
      " [3851.68 3859.23 3797.16 3855.36]\n",
      " [3844.24 3852.31 3830.41 3841.47]]\n",
      "fake_output:\n",
      " [[3820.57780728 3844.14369766 3777.37959238 3798.95050596]]\n",
      "real_output:\n",
      " [[3857.46 3861.45 3845.05 3853.07]]\n",
      "88 [D loss: 0.694039, acc.: 53.67%] [G loss: 2.009823]\n",
      "input:\n",
      " [[4374.45 4394.87 4347.96 4354.19]\n",
      " [4402.95 4402.95 4305.91 4357.73]\n",
      " [4469.74 4471.52 4427.76 4432.99]\n",
      " [4477.09 4485.87 4443.8  4473.75]\n",
      " [4447.49 4486.87 4438.37 4480.7 ]]\n",
      "fake_output:\n",
      " [[4424.68469237 4431.21840762 4378.15003504 4399.0557629 ]]\n",
      "real_output:\n",
      " [[4479.33 4485.68 4435.46 4443.05]]\n",
      "89 [D loss: 0.700797, acc.: 54.33%] [G loss: 1.828927]\n",
      "input:\n",
      " [[3967.25 3994.41 3966.98 3972.89]\n",
      " [3963.34 3968.01 3944.35 3958.55]\n",
      " [3969.31 3981.83 3943.25 3971.09]\n",
      " [3917.12 3978.19 3917.12 3974.54]\n",
      " [3879.34 3919.54 3853.5  3909.52]]\n",
      "fake_output:\n",
      " [[3923.02129198 3951.3821427  3902.0444731  3941.18775332]]\n",
      "real_output:\n",
      " [[3919.93 3942.08 3889.07 3889.14]]\n",
      "90 [D loss: 0.688921, acc.: 55.50%] [G loss: 1.885940]\n",
      "input:\n",
      " [[3236.66 3306.88 3228.44 3298.46]\n",
      " [3226.14 3278.7  3209.45 3246.59]\n",
      " [3320.11 3323.35 3232.57 3236.92]\n",
      " [3295.75 3320.31 3270.95 3315.57]\n",
      " [3285.57 3285.57 3229.1  3281.06]]\n",
      "fake_output:\n",
      " [[3249.7417667  3287.43299166 3217.01731717 3247.97897298]]\n",
      "real_output:\n",
      " [[3357.38 3362.27 3292.4  3319.47]]\n",
      "91 [D loss: 0.696959, acc.: 55.00%] [G loss: 1.928557]\n",
      "input:\n",
      " [[3407.73 3419.48 3389.25 3401.2 ]\n",
      " [3363.56 3402.93 3363.56 3383.54]\n",
      " [3352.7  3368.95 3310.47 3340.97]\n",
      " [3412.56 3425.55 3329.25 3339.19]\n",
      " [3369.82 3424.77 3366.84 3398.96]]\n",
      "fake_output:\n",
      " [[3377.09096131 3401.28034551 3347.45108016 3363.68650631]]\n",
      "real_output:\n",
      " [[3371.88 3379.97 3329.27 3331.84]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 [D loss: 0.694430, acc.: 55.50%] [G loss: 1.685175]\n",
      "input:\n",
      " [[3818.53 3843.67 3723.34 3768.47]\n",
      " [3863.99 3874.47 3818.86 3819.72]\n",
      " [3903.64 3906.41 3868.57 3870.29]\n",
      " [3842.51 3914.5  3842.51 3901.82]\n",
      " [3839.66 3861.08 3789.54 3811.15]]\n",
      "fake_output:\n",
      " [[3856.78760884 3880.63673414 3815.90316063 3837.32107949]]\n",
      "real_output:\n",
      " [[3915.8  3925.02 3814.04 3829.34]]\n",
      "93 [D loss: 0.677530, acc.: 56.00%] [G loss: 2.001355]\n",
      "input:\n",
      " [[3441.42 3441.42 3364.86 3400.97]\n",
      " [3464.9  3466.46 3440.45 3465.39]\n",
      " [3438.5  3460.53 3415.34 3453.49]\n",
      " [3439.91 3464.86 3433.06 3435.56]\n",
      " [3439.38 3476.93 3435.65 3443.12]]\n",
      "fake_output:\n",
      " [[3447.46826858 3463.83191086 3427.25304899 3443.94652323]]\n",
      "real_output:\n",
      " [[3493.66 3502.42 3419.93 3426.92]]\n",
      "94 [D loss: 0.674112, acc.: 57.33%] [G loss: 2.279752]\n",
      "input:\n",
      " [[3371.88 3379.97 3329.27 3331.84]\n",
      " [3453.6  3479.15 3349.63 3426.96]\n",
      " [3564.74 3564.85 3427.41 3455.06]\n",
      " [3543.76 3588.11 3535.23 3580.84]\n",
      " [3507.44 3528.03 3494.6  3526.65]]\n",
      "fake_output:\n",
      " [[3506.95967294 3519.10310576 3453.48759172 3483.76025322]]\n",
      "real_output:\n",
      " [[3509.73 3514.77 3493.25 3500.31]]\n",
      "95 [D loss: 0.691187, acc.: 56.00%] [G loss: 1.999436]\n",
      "input:\n",
      " [[4572.87 4608.08 4567.59 4605.38]\n",
      " [4562.84 4597.55 4562.84 4596.42]\n",
      " [4580.22 4584.57 4551.66 4551.68]\n",
      " [4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]]\n",
      "fake_output:\n",
      " [[4560.31603696 4577.78363708 4543.85120782 4554.09446258]]\n",
      "real_output:\n",
      " [[4546.12 4559.67 4524.   4544.9 ]]\n",
      "96 [D loss: 0.676611, acc.: 56.83%] [G loss: 2.454857]\n",
      "input:\n",
      " [[3778.05 3778.05 3694.12 3714.24]\n",
      " [3755.75 3830.5  3755.75 3787.38]\n",
      " [3836.83 3836.83 3732.48 3750.77]\n",
      " [3862.96 3870.9  3847.78 3849.62]\n",
      " [3851.68 3859.23 3797.16 3855.36]]\n",
      "fake_output:\n",
      " [[3802.17750377 3815.79529257 3740.72655718 3761.72614066]]\n",
      "real_output:\n",
      " [[3844.24 3852.31 3830.41 3841.47]]\n",
      "97 [D loss: 0.648283, acc.: 59.33%] [G loss: 3.784855]\n",
      "input:\n",
      " [[4248.87 4251.89 4202.45 4223.7 ]\n",
      " [4255.28 4257.16 4238.35 4246.59]\n",
      " [4248.31 4255.59 4234.07 4255.15]\n",
      " [4242.9  4248.38 4232.25 4247.44]\n",
      " [4228.56 4249.74 4220.34 4239.18]]\n",
      "fake_output:\n",
      " [[4241.1826562  4250.54771721 4218.7903335  4236.30657002]]\n",
      "real_output:\n",
      " [[4232.99 4237.09 4218.74 4219.55]]\n",
      "98 [D loss: 0.652770, acc.: 59.83%] [G loss: 2.898754]\n",
      "input:\n",
      " [[4121.97 4172.8  4121.97 4159.12]\n",
      " [4098.45 4116.93 4061.41 4115.68]\n",
      " [4165.94 4169.15 4125.99 4127.83]\n",
      " [4169.92 4171.92 4142.69 4163.29]\n",
      " [4129.58 4183.13 4129.58 4173.85]]\n",
      "fake_output:\n",
      " [[4132.83084936 4155.1836409  4110.13386203 4141.96959686]]\n",
      "real_output:\n",
      " [[4074.99 4131.58 4074.99 4112.5 ]]\n",
      "99 [D loss: 0.670093, acc.: 57.83%] [G loss: 2.237691]\n",
      "input:\n",
      " [[4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]\n",
      " [4546.12 4559.67 4524.   4544.9 ]\n",
      " [4532.24 4551.44 4526.89 4549.78]\n",
      " [4524.42 4540.87 4524.4  4536.19]]\n",
      "fake_output:\n",
      " [[4547.11311138 4562.58346611 4536.94210477 4553.88002761]]\n",
      "real_output:\n",
      " [[4497.34 4520.4  4496.41 4519.63]]\n",
      "100 [D loss: 0.665510, acc.: 57.67%] [G loss: 2.403398]\n",
      "input:\n",
      " [[3296.2  3330.14 3279.74 3310.24]\n",
      " [3293.59 3304.93 3233.94 3269.96]\n",
      " [3277.17 3341.05 3259.82 3310.11]\n",
      " [3342.48 3342.48 3268.89 3271.03]\n",
      " [3403.15 3409.51 3388.71 3390.68]]\n",
      "fake_output:\n",
      " [[3298.27390299 3319.44937518 3249.22203421 3278.27473988]]\n",
      "real_output:\n",
      " [[3441.42 3441.42 3364.86 3400.97]]\n",
      "101 [D loss: 0.653576, acc.: 58.17%] [G loss: 1.953603]\n",
      "input:\n",
      " [[3653.78 3670.96 3644.84 3669.01]\n",
      " [3645.87 3678.45 3645.87 3662.45]\n",
      " [3634.18 3634.18 3594.39 3621.63]\n",
      " [3638.55 3644.31 3629.33 3638.35]\n",
      " [3635.5  3635.5  3617.76 3629.65]]\n",
      "fake_output:\n",
      " [[3640.34508731 3647.44563064 3622.83717164 3639.63483785]]\n",
      "real_output:\n",
      " [[3594.52 3642.31 3594.52 3635.41]]\n",
      "102 [D loss: 0.675194, acc.: 58.00%] [G loss: 1.829966]\n",
      "input:\n",
      " [[4703.96 4740.74 4703.96 4725.79]\n",
      " [4650.36 4697.67 4645.53 4696.56]\n",
      " [4594.96 4651.14 4583.16 4649.23]\n",
      " [4587.9  4587.9  4531.1  4568.02]\n",
      " [4652.5  4666.7  4600.22 4620.64]]\n",
      "fake_output:\n",
      " [[4631.35011579 4653.44308723 4601.46360793 4637.87068812]]\n",
      "real_output:\n",
      " [[4719.13 4731.99 4651.89 4668.67]]\n",
      "103 [D loss: 0.653818, acc.: 59.67%] [G loss: 1.889904]\n",
      "input:\n",
      " [[3949.57 3983.87 3935.74 3974.12]\n",
      " [3973.59 3981.04 3953.44 3962.71]\n",
      " [3942.96 3970.08 3923.54 3968.94]\n",
      " [3924.52 3944.99 3915.21 3943.34]\n",
      " [3915.54 3960.27 3915.54 3939.34]]\n",
      "fake_output:\n",
      " [[3935.2115264  3962.019612   3923.62399435 3952.20775567]]\n",
      "real_output:\n",
      " [[3891.99 3917.35 3885.73 3898.81]]\n",
      "104 [D loss: 0.654080, acc.: 59.50%] [G loss: 2.335528]\n",
      "input:\n",
      " [[4437.77 4439.39 4424.74 4432.35]\n",
      " [4429.07 4440.82 4429.07 4436.52]\n",
      " [4408.86 4429.76 4408.86 4429.1 ]\n",
      " [4415.95 4416.17 4400.23 4402.66]\n",
      " [4392.74 4423.79 4373.   4423.15]]\n",
      "fake_output:\n",
      " [[4426.2051173  4434.64715448 4423.23608322 4432.62998548]]\n",
      "real_output:\n",
      " [[4406.86 4422.18 4384.81 4387.16]]\n",
      "105 [D loss: 0.652023, acc.: 59.83%] [G loss: 2.065715]\n",
      "input:\n",
      " [[3338.94 3369.1  3323.69 3348.44]\n",
      " [3385.87 3397.18 3361.39 3380.8 ]\n",
      " [3341.21 3393.56 3340.47 3363.  ]\n",
      " [3350.92 3357.92 3327.54 3335.47]\n",
      " [3333.9  3360.74 3332.91 3351.6 ]]\n",
      "fake_output:\n",
      " [[3338.8252458  3362.65248466 3327.85029023 3343.56872756]]\n",
      "real_output:\n",
      " [[3236.66 3306.88 3228.44 3298.46]]\n",
      "106 [D loss: 0.657860, acc.: 59.67%] [G loss: 2.130738]\n",
      "input:\n",
      " [[4185.14 4201.53 4181.78 4183.18]\n",
      " [4188.25 4193.35 4176.22 4186.72]\n",
      " [4185.03 4194.19 4182.36 4187.62]\n",
      " [4138.78 4194.17 4138.78 4180.17]\n",
      " [4170.46 4179.57 4123.69 4134.98]]\n",
      "fake_output:\n",
      " [[4175.77233751 4192.75207615 4166.09181569 4176.0296266 ]]\n",
      "real_output:\n",
      " [[4128.42 4175.02 4126.35 4173.42]]\n",
      "107 [D loss: 0.674004, acc.: 56.67%] [G loss: 1.722385]\n",
      "input:\n",
      " [[3583.04 3645.99 3547.48 3550.5 ]\n",
      " [3508.34 3521.58 3484.34 3509.44]\n",
      " [3485.74 3529.05 3485.74 3510.45]\n",
      " [3406.46 3486.25 3405.17 3443.44]\n",
      " [3336.25 3389.49 3336.25 3369.16]]\n",
      "fake_output:\n",
      " [[3473.39453525 3513.57084706 3460.05412441 3476.15355845]]\n",
      "real_output:\n",
      " [[3296.2  3330.14 3279.74 3310.24]]\n",
      "108 [D loss: 0.632138, acc.: 63.00%] [G loss: 1.989653]\n",
      "input:\n",
      " [[4150.34 4162.04 4111.53 4152.1 ]\n",
      " [4228.29 4236.39 4188.13 4188.43]\n",
      " [4210.34 4238.04 4201.64 4232.6 ]\n",
      " [4169.14 4202.7  4147.33 4201.62]\n",
      " [4177.06 4187.72 4160.94 4167.59]]\n",
      "fake_output:\n",
      " [[4179.60044412 4190.93495907 4149.83477613 4175.60564624]]\n",
      "real_output:\n",
      " [[4179.04 4179.04 4128.59 4164.66]]\n",
      "109 [D loss: 0.650669, acc.: 61.33%] [G loss: 2.569323]\n",
      "input:\n",
      " [[4447.69 4475.82 4447.69 4471.37]\n",
      " [4386.75 4439.73 4386.75 4438.26]\n",
      " [4358.01 4372.87 4329.92 4363.8 ]\n",
      " [4368.31 4374.89 4342.09 4350.65]\n",
      " [4385.44 4415.88 4360.59 4361.19]]\n",
      "fake_output:\n",
      " [[4362.76092745 4371.38699601 4326.65151789 4340.17101757]]\n",
      "real_output:\n",
      " [[4406.51 4412.02 4386.22 4391.34]]\n",
      "110 [D loss: 0.668048, acc.: 57.00%] [G loss: 1.890331]\n",
      "input:\n",
      " [[3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]\n",
      " [3015.65 3036.25 2969.75 3036.13]\n",
      " [3004.08 3021.72 2988.17 2991.77]]\n",
      "fake_output:\n",
      " [[3031.48054078 3052.18906123 3014.08001675 3039.69084683]]\n",
      "real_output:\n",
      " [[2948.05 2956.76 2933.59 2955.45]]\n",
      "111 [D loss: 0.643391, acc.: 61.67%] [G loss: 2.395301]\n",
      "input:\n",
      " [[3453.6  3479.15 3349.63 3426.96]\n",
      " [3564.74 3564.85 3427.41 3455.06]\n",
      " [3543.76 3588.11 3535.23 3580.84]\n",
      " [3507.44 3528.03 3494.6  3526.65]\n",
      " [3509.73 3514.77 3493.25 3500.31]]\n",
      "fake_output:\n",
      " [[3521.5963322  3534.96688682 3472.36872195 3502.5882546 ]]\n",
      "real_output:\n",
      " [[3494.69 3509.23 3484.32 3508.01]]\n",
      "112 [D loss: 0.631326, acc.: 63.33%] [G loss: 2.385249]\n",
      "input:\n",
      " [[4691.   4695.26 4665.98 4667.45]\n",
      " [4690.86 4705.06 4674.52 4701.21]\n",
      " [4631.97 4694.04 4631.97 4686.75]\n",
      " [4548.37 4612.6  4540.51 4591.67]\n",
      " [4589.49 4608.03 4495.12 4538.43]]\n",
      "fake_output:\n",
      " [[4635.94501912 4663.39849001 4614.676443   4640.70246394]]\n",
      "real_output:\n",
      " [[4504.73 4595.46 4504.73 4577.1 ]]\n",
      "113 [D loss: 0.649152, acc.: 60.33%] [G loss: 2.049727]\n",
      "input:\n",
      " [[4356.46 4356.46 4314.37 4343.54]\n",
      " [4326.6  4355.43 4326.6  4352.34]\n",
      " [4300.73 4320.66 4300.73 4319.94]\n",
      " [4290.65 4302.43 4287.96 4297.5 ]\n",
      " [4293.21 4300.52 4287.04 4291.8 ]]\n",
      "fake_output:\n",
      " [[4304.1979481  4312.06839525 4296.39490895 4306.68298636]]\n",
      "real_output:\n",
      " [[4284.9  4292.14 4274.67 4290.61]]\n",
      "114 [D loss: 0.647386, acc.: 61.17%] [G loss: 1.445284]\n",
      "input:\n",
      " [[2883.14 2891.11 2847.65 2848.42]\n",
      " [2868.88 2898.23 2863.55 2868.44]\n",
      " [2815.01 2844.24 2797.85 2842.74]\n",
      " [2869.09 2869.09 2821.61 2830.71]\n",
      " [2930.91 2930.91 2892.47 2912.43]]\n",
      "fake_output:\n",
      " [[2861.52440041 2873.05495173 2831.37067255 2847.64112475]]\n",
      "real_output:\n",
      " [[2918.46 2954.86 2912.16 2939.51]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 [D loss: 0.644120, acc.: 62.17%] [G loss: 2.014653]\n",
      "input:\n",
      " [[3464.9  3466.46 3440.45 3465.39]\n",
      " [3438.5  3460.53 3415.34 3453.49]\n",
      " [3439.91 3464.86 3433.06 3435.56]\n",
      " [3439.38 3476.93 3435.65 3443.12]\n",
      " [3493.66 3502.42 3419.93 3426.92]]\n",
      "fake_output:\n",
      " [[3430.01421899 3451.71460735 3414.13597821 3424.74797368]]\n",
      "real_output:\n",
      " [[3493.5  3515.76 3480.45 3483.81]]\n",
      "116 [D loss: 0.660880, acc.: 60.00%] [G loss: 1.666551]\n",
      "input:\n",
      " [[3910.49 3918.35 3902.64 3911.23]\n",
      " [3892.59 3915.77 3892.59 3915.59]\n",
      " [3878.3  3894.56 3874.93 3886.83]\n",
      " [3836.66 3872.42 3836.66 3871.74]\n",
      " [3840.27 3847.51 3816.68 3830.17]]\n",
      "fake_output:\n",
      " [[3854.49604516 3868.49182471 3838.63288757 3857.73031609]]\n",
      "real_output:\n",
      " [[3791.84 3843.09 3791.84 3826.31]]\n",
      "117 [D loss: 0.652029, acc.: 61.50%] [G loss: 1.864479]\n",
      "input:\n",
      " [[3840.27 3847.51 3816.68 3830.17]\n",
      " [3791.84 3843.09 3791.84 3826.31]\n",
      " [3731.17 3784.32 3725.62 3773.86]\n",
      " [3778.05 3778.05 3694.12 3714.24]\n",
      " [3755.75 3830.5  3755.75 3787.38]]\n",
      "fake_output:\n",
      " [[3772.86008308 3806.37569352 3747.59302141 3772.15160227]]\n",
      "real_output:\n",
      " [[3836.83 3836.83 3732.48 3750.77]]\n",
      "118 [D loss: 0.654722, acc.: 60.00%] [G loss: 2.122059]\n",
      "input:\n",
      " [[3453.6  3479.15 3349.63 3426.96]\n",
      " [3564.74 3564.85 3427.41 3455.06]\n",
      " [3543.76 3588.11 3535.23 3580.84]\n",
      " [3507.44 3528.03 3494.6  3526.65]\n",
      " [3509.73 3514.77 3493.25 3500.31]]\n",
      "fake_output:\n",
      " [[3534.99398167 3552.78171601 3505.56694995 3530.07030196]]\n",
      "real_output:\n",
      " [[3494.69 3509.23 3484.32 3508.01]]\n",
      "119 [D loss: 0.658162, acc.: 59.17%] [G loss: 1.200529]\n",
      "input:\n",
      " [[3764.61 3769.99 3662.71 3700.65]\n",
      " [3733.27 3760.2  3726.88 3756.07]\n",
      " [3736.19 3744.63 3730.21 3732.04]\n",
      " [3750.01 3756.12 3723.31 3727.04]\n",
      " [3723.03 3740.51 3723.03 3735.36]]\n",
      "fake_output:\n",
      " [[3733.5647433  3745.90794077 3694.28917847 3715.8098385 ]]\n",
      "real_output:\n",
      " [[3694.03 3703.82 3689.32 3703.06]]\n",
      "120 [D loss: 0.637891, acc.: 62.83%] [G loss: 2.383555]\n",
      "input:\n",
      " [[4469.74 4471.52 4427.76 4432.99]\n",
      " [4477.09 4485.87 4443.8  4473.75]\n",
      " [4447.49 4486.87 4438.37 4480.7 ]\n",
      " [4479.33 4485.68 4435.46 4443.05]\n",
      " [4474.81 4492.99 4445.7  4468.73]]\n",
      "fake_output:\n",
      " [[4459.97040941 4476.50525926 4430.85467452 4437.9854113 ]]\n",
      "real_output:\n",
      " [[4506.92 4520.47 4457.66 4458.58]]\n",
      "121 [D loss: 0.639249, acc.: 62.33%] [G loss: 2.293594]\n",
      "input:\n",
      " [[4367.43 4416.75 4367.43 4395.64]\n",
      " [4374.45 4394.87 4347.96 4354.19]\n",
      " [4402.95 4402.95 4305.91 4357.73]\n",
      " [4469.74 4471.52 4427.76 4432.99]\n",
      " [4477.09 4485.87 4443.8  4473.75]]\n",
      "fake_output:\n",
      " [[4421.77811906 4430.34932925 4385.26165292 4400.30853796]]\n",
      "real_output:\n",
      " [[4447.49 4486.87 4438.37 4480.7 ]]\n",
      "122 [D loss: 0.636071, acc.: 63.50%] [G loss: 2.021329]\n",
      "input:\n",
      " [[3046.6  3086.25 3024.01 3083.76]\n",
      " [3114.4  3115.01 3032.13 3050.33]\n",
      " [3138.7  3154.9  3127.12 3131.29]\n",
      " [3094.42 3120.92 3079.39 3117.86]\n",
      " [3140.29 3155.53 3083.11 3097.74]]\n",
      "fake_output:\n",
      " [[3118.86549219 3134.4237555  3091.24889548 3109.06992557]]\n",
      "real_output:\n",
      " [[3101.64 3120.   3093.51 3115.34]]\n",
      "123 [D loss: 0.655267, acc.: 62.33%] [G loss: 1.147645]\n",
      "input:\n",
      " [[2578.28 2676.85 2574.57 2663.68]\n",
      " [2514.92 2538.18 2459.96 2488.65]\n",
      " [2458.54 2533.22 2455.79 2526.9 ]\n",
      " [2498.08 2522.75 2447.49 2470.5 ]\n",
      " [2614.69 2641.39 2571.15 2584.59]]\n",
      "fake_output:\n",
      " [[2551.91667224 2601.05483252 2532.09293295 2573.7966632 ]]\n",
      "real_output:\n",
      " [[2558.98 2631.8  2545.28 2626.65]]\n",
      "124 [D loss: 0.639105, acc.: 60.17%] [G loss: 2.660956]\n",
      "input:\n",
      " [[4562.84 4597.55 4562.84 4596.42]\n",
      " [4580.22 4584.57 4551.66 4551.68]\n",
      " [4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]\n",
      " [4546.12 4559.67 4524.   4544.9 ]]\n",
      "fake_output:\n",
      " [[4559.89160583 4574.76205826 4542.46293406 4557.70649377]]\n",
      "real_output:\n",
      " [[4532.24 4551.44 4526.89 4549.78]]\n",
      "125 [D loss: 0.661329, acc.: 62.17%] [G loss: 1.981758]\n",
      "input:\n",
      " [[4528.8  4537.11 4522.02 4524.09]\n",
      " [4529.75 4531.39 4515.8  4522.68]\n",
      " [4513.76 4537.36 4513.76 4528.79]\n",
      " [4474.1  4513.33 4474.1  4509.37]\n",
      " [4493.75 4495.9  4468.99 4470.  ]]\n",
      "fake_output:\n",
      " [[4486.49137855 4501.29333659 4470.92294288 4480.94509791]]\n",
      "real_output:\n",
      " [[4490.45 4501.71 4485.66 4496.19]]\n",
      "126 [D loss: 0.647595, acc.: 61.67%] [G loss: 2.470476]\n",
      "input:\n",
      " [[3392.51 3399.54 3369.66 3374.85]\n",
      " [3387.04 3395.06 3370.15 3389.78]\n",
      " [3380.86 3387.59 3379.22 3381.99]\n",
      " [3368.66 3378.51 3361.64 3372.85]\n",
      " [3372.95 3387.24 3363.35 3373.43]]\n",
      "fake_output:\n",
      " [[3381.0950433  3389.59177262 3369.56093007 3378.7446455 ]]\n",
      "real_output:\n",
      " [[3355.46 3387.89 3355.46 3380.35]]\n",
      "127 [D loss: 0.623001, acc.: 65.83%] [G loss: 1.350177]\n",
      "input:\n",
      " [[4795.49 4807.02 4780.04 4786.35]\n",
      " [4733.99 4791.49 4733.99 4791.19]\n",
      " [4703.96 4740.74 4703.96 4725.79]\n",
      " [4650.36 4697.67 4645.53 4696.56]\n",
      " [4594.96 4651.14 4583.16 4649.23]]\n",
      "fake_output:\n",
      " [[4750.42865145 4783.90284322 4767.43977684 4784.2218582 ]]\n",
      "real_output:\n",
      " [[4587.9  4587.9  4531.1  4568.02]]\n",
      "128 [D loss: 0.661920, acc.: 59.67%] [G loss: 1.375697]\n",
      "input:\n",
      " [[4392.74 4423.79 4373.   4423.15]\n",
      " [4406.86 4422.18 4384.81 4387.16]\n",
      " [4395.12 4412.25 4389.65 4395.26]\n",
      " [4403.59 4429.97 4403.59 4419.15]\n",
      " [4402.95 4415.47 4387.01 4400.64]]\n",
      "fake_output:\n",
      " [[4400.08038523 4419.16526429 4387.5124525  4402.77584933]]\n",
      "real_output:\n",
      " [[4416.38 4416.38 4372.51 4401.46]]\n",
      "129 [D loss: 0.623363, acc.: 67.50%] [G loss: 1.987296]\n",
      "input:\n",
      " [[4471.38 4494.52 4395.34 4397.94]\n",
      " [4547.35 4602.11 4477.95 4482.73]\n",
      " [4588.03 4611.55 4530.2  4532.76]\n",
      " [4632.24 4632.24 4568.7  4577.11]\n",
      " [4637.99 4665.13 4614.75 4662.85]]\n",
      "fake_output:\n",
      " [[4600.28948834 4620.6041596  4564.87056788 4573.5928156 ]]\n",
      "real_output:\n",
      " [[4733.56 4744.13 4650.29 4659.03]]\n",
      "130 [D loss: 0.638691, acc.: 62.67%] [G loss: 1.619289]\n",
      "input:\n",
      " [[3268.52 3277.29 3247.77 3257.3 ]\n",
      " [3224.29 3258.61 3215.16 3251.84]\n",
      " [3224.21 3233.52 3205.65 3224.73]\n",
      " [3208.36 3220.39 3198.59 3215.57]\n",
      " [3225.98 3238.28 3200.76 3226.56]]\n",
      "fake_output:\n",
      " [[3229.0755691  3240.53558585 3212.83040425 3232.75386209]]\n",
      "real_output:\n",
      " [[3141.11 3200.95 3127.66 3197.52]]\n",
      "131 [D loss: 0.664125, acc.: 57.50%] [G loss: 2.037166]\n",
      "input:\n",
      " [[2865.86 2874.14 2793.15 2820.  ]\n",
      " [2939.5  2945.82 2869.59 2870.12]\n",
      " [2915.46 2944.25 2903.44 2930.32]\n",
      " [2908.83 2932.16 2902.88 2929.8 ]\n",
      " [2878.26 2901.92 2876.48 2881.19]]\n",
      "fake_output:\n",
      " [[2896.72738277 2909.47697741 2862.30084148 2874.09722833]]\n",
      "real_output:\n",
      " [[2883.14 2891.11 2847.65 2848.42]]\n",
      "132 [D loss: 0.664025, acc.: 60.83%] [G loss: 1.605271]\n",
      "input:\n",
      " [[4719.13 4731.99 4651.89 4668.67]\n",
      " [4636.46 4712.6  4611.22 4709.85]\n",
      " [4642.99 4660.47 4606.52 4634.09]\n",
      " [4710.3  4710.3  4667.6  4668.97]\n",
      " [4687.64 4713.57 4670.24 4712.02]]\n",
      "fake_output:\n",
      " [[4714.66148911 4730.62540172 4684.09695224 4719.00029856]]\n",
      "real_output:\n",
      " [[4691.   4695.26 4665.98 4667.45]]\n",
      "133 [D loss: 0.662549, acc.: 58.50%] [G loss: 1.287046]\n",
      "input:\n",
      " [[3638.55 3644.31 3629.33 3638.35]\n",
      " [3635.5  3635.5  3617.76 3629.65]\n",
      " [3594.52 3642.31 3594.52 3635.41]\n",
      " [3566.82 3589.81 3552.77 3577.59]\n",
      " [3579.31 3581.23 3556.85 3557.54]]\n",
      "fake_output:\n",
      " [[3592.50473905 3603.3429186  3576.51639895 3590.27325432]]\n",
      "real_output:\n",
      " [[3559.41 3585.22 3543.84 3581.87]]\n",
      "134 [D loss: 0.633562, acc.: 65.00%] [G loss: 1.641904]\n",
      "input:\n",
      " [[3873.71 3928.65 3859.6  3925.43]\n",
      " [3857.07 3895.98 3805.59 3881.37]\n",
      " [3885.55 3902.92 3874.71 3876.5 ]\n",
      " [3921.16 3930.41 3903.07 3906.71]\n",
      " [3915.86 3921.98 3885.03 3913.97]]\n",
      "fake_output:\n",
      " [[3884.47429684 3910.02690999 3856.77380616 3894.16550699]]\n",
      "real_output:\n",
      " [[3918.5  3933.61 3900.43 3931.33]]\n",
      "135 [D loss: 0.654590, acc.: 60.00%] [G loss: 1.352383]\n",
      "input:\n",
      " [[3842.51 3914.5  3842.51 3901.82]\n",
      " [3839.66 3861.08 3789.54 3811.15]\n",
      " [3915.8  3925.02 3814.04 3829.34]\n",
      " [3873.71 3928.65 3859.6  3925.43]\n",
      " [3857.07 3895.98 3805.59 3881.37]]\n",
      "fake_output:\n",
      " [[3843.331128   3877.45154862 3795.53932026 3821.77548449]]\n",
      "real_output:\n",
      " [[3885.55 3902.92 3874.71 3876.5 ]]\n",
      "136 [D loss: 0.667104, acc.: 56.33%] [G loss: 1.440996]\n",
      "input:\n",
      " [[4652.5  4666.7  4600.22 4620.64]\n",
      " [4719.13 4731.99 4651.89 4668.67]\n",
      " [4636.46 4712.6  4611.22 4709.85]\n",
      " [4642.99 4660.47 4606.52 4634.09]\n",
      " [4710.3  4710.3  4667.6  4668.97]]\n",
      "fake_output:\n",
      " [[4633.49098195 4655.45683183 4588.47408738 4613.00187907]]\n",
      "real_output:\n",
      " [[4687.64 4713.57 4670.24 4712.02]]\n",
      "137 [D loss: 0.646910, acc.: 62.00%] [G loss: 2.222681]\n",
      "input:\n",
      " [[3277.17 3341.05 3259.82 3310.11]\n",
      " [3342.48 3342.48 3268.89 3271.03]\n",
      " [3403.15 3409.51 3388.71 3390.68]\n",
      " [3441.42 3441.42 3364.86 3400.97]\n",
      " [3464.9  3466.46 3440.45 3465.39]]\n",
      "fake_output:\n",
      " [[3382.30965313 3388.74773663 3347.88102038 3360.20085932]]\n",
      "real_output:\n",
      " [[3438.5  3460.53 3415.34 3453.49]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 [D loss: 0.649124, acc.: 61.17%] [G loss: 1.763909]\n",
      "input:\n",
      " [[3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]\n",
      " [3015.65 3036.25 2969.75 3036.13]\n",
      " [3004.08 3021.72 2988.17 2991.77]]\n",
      "fake_output:\n",
      " [[3023.76942875 3042.77271791 3000.05162137 3026.35638646]]\n",
      "real_output:\n",
      " [[2948.05 2956.76 2933.59 2955.45]]\n",
      "139 [D loss: 0.648962, acc.: 61.17%] [G loss: 1.637769]\n",
      "input:\n",
      " [[3803.14 3817.86 3789.02 3799.61]\n",
      " [3815.05 3826.69 3783.6  3824.68]\n",
      " [3764.71 3811.55 3764.71 3803.79]\n",
      " [3712.2  3783.04 3705.34 3748.14]\n",
      " [3698.02 3737.83 3695.07 3726.86]]\n",
      "fake_output:\n",
      " [[3765.71764997 3795.31662782 3757.24713678 3783.46678634]]\n",
      "real_output:\n",
      " [[3764.61 3769.99 3662.71 3700.65]]\n",
      "140 [D loss: 0.655050, acc.: 61.67%] [G loss: 1.774402]\n",
      "input:\n",
      " [[4548.37 4612.6  4540.51 4591.67]\n",
      " [4589.49 4608.03 4495.12 4538.43]\n",
      " [4504.73 4595.46 4504.73 4577.1 ]\n",
      " [4602.82 4652.94 4510.27 4513.04]\n",
      " [4640.25 4646.02 4560.   4567.  ]]\n",
      "fake_output:\n",
      " [[4490.57983659 4569.15695941 4463.54285808 4483.07115805]]\n",
      "real_output:\n",
      " [[4628.75 4672.95 4625.26 4655.27]]\n",
      "141 [D loss: 0.655830, acc.: 59.17%] [G loss: 1.405744]\n",
      "input:\n",
      " [[3098.9  3130.94 3098.9  3122.87]\n",
      " [3064.78 3081.07 3051.64 3080.82]\n",
      " [3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]]\n",
      "fake_output:\n",
      " [[3075.7321925  3103.48158747 3083.58449891 3102.49573824]]\n",
      "real_output:\n",
      " [[3015.65 3036.25 2969.75 3036.13]]\n",
      "142 [D loss: 0.645473, acc.: 61.83%] [G loss: 1.436712]\n",
      "input:\n",
      " [[4326.6  4355.43 4326.6  4352.34]\n",
      " [4300.73 4320.66 4300.73 4319.94]\n",
      " [4290.65 4302.43 4287.96 4297.5 ]\n",
      " [4293.21 4300.52 4287.04 4291.8 ]\n",
      " [4284.9  4292.14 4274.67 4290.61]]\n",
      "fake_output:\n",
      " [[4302.28064406 4317.23454862 4301.48943536 4314.72574709]]\n",
      "real_output:\n",
      " [[4274.45 4286.12 4271.16 4280.7 ]]\n",
      "143 [D loss: 0.636148, acc.: 64.67%] [G loss: 1.390909]\n",
      "input:\n",
      " [[4169.92 4171.92 4142.69 4163.29]\n",
      " [4129.58 4183.13 4129.58 4173.85]\n",
      " [4074.99 4131.58 4074.99 4112.5 ]\n",
      " [4130.55 4134.73 4056.88 4063.04]\n",
      " [4150.34 4162.04 4111.53 4152.1 ]]\n",
      "fake_output:\n",
      " [[4098.49441479 4128.07699383 4058.99823779 4072.56132696]]\n",
      "real_output:\n",
      " [[4228.29 4236.39 4188.13 4188.43]]\n",
      "144 [D loss: 0.670799, acc.: 56.33%] [G loss: 2.283358]\n",
      "input:\n",
      " [[3213.42 3223.27 3181.49 3190.14]\n",
      " [3213.32 3222.71 3193.11 3207.18]\n",
      " [3199.92 3233.13 3196.   3232.39]\n",
      " [3163.84 3211.72 3163.84 3193.93]\n",
      " [3111.56 3128.91 3090.41 3112.35]]\n",
      "fake_output:\n",
      " [[3217.53890555 3245.88499446 3220.38939166 3239.90357958]]\n",
      "real_output:\n",
      " [[3098.9  3130.94 3098.9  3122.87]]\n",
      "145 [D loss: 0.654051, acc.: 59.67%] [G loss: 1.397445]\n",
      "input:\n",
      " [[4440.94 4454.32 4397.59 4400.27]\n",
      " [4462.12 4462.12 4417.83 4448.08]\n",
      " [4461.65 4480.26 4437.66 4479.71]\n",
      " [4464.84 4468.37 4460.82 4468.  ]\n",
      " [4446.08 4461.77 4435.96 4460.83]]\n",
      "fake_output:\n",
      " [[4444.99265879 4453.04827476 4400.86386379 4410.57124201]]\n",
      "real_output:\n",
      " [[4442.18 4449.44 4436.42 4447.7 ]]\n",
      "146 [D loss: 0.660785, acc.: 58.00%] [G loss: 2.574125]\n",
      "input:\n",
      " [[4513.02 4529.9  4492.07 4493.28]\n",
      " [4518.09 4521.79 4493.95 4514.07]\n",
      " [4535.38 4535.38 4513.   4520.03]\n",
      " [4532.42 4541.45 4521.3  4535.43]\n",
      " [4534.48 4545.85 4524.66 4536.95]]\n",
      "fake_output:\n",
      " [[4529.91330901 4537.23703658 4515.28882779 4525.65632417]]\n",
      "real_output:\n",
      " [[4528.8  4537.11 4522.02 4524.09]]\n",
      "147 [D loss: 0.661965, acc.: 59.00%] [G loss: 1.682875]\n",
      "input:\n",
      " [[4415.95 4416.17 4400.23 4402.66]\n",
      " [4392.74 4423.79 4373.   4423.15]\n",
      " [4406.86 4422.18 4384.81 4387.16]\n",
      " [4395.12 4412.25 4389.65 4395.26]\n",
      " [4403.59 4429.97 4403.59 4419.15]]\n",
      "fake_output:\n",
      " [[4410.58832956 4427.38473293 4405.54408653 4422.38912901]]\n",
      "real_output:\n",
      " [[4402.95 4415.47 4387.01 4400.64]]\n",
      "148 [D loss: 0.678047, acc.: 55.67%] [G loss: 1.286091]\n",
      "input:\n",
      " [[3863.99 3874.47 3818.86 3819.72]\n",
      " [3903.64 3906.41 3868.57 3870.29]\n",
      " [3842.51 3914.5  3842.51 3901.82]\n",
      " [3839.66 3861.08 3789.54 3811.15]\n",
      " [3915.8  3925.02 3814.04 3829.34]]\n",
      "fake_output:\n",
      " [[3905.82500666 3925.36503702 3871.28142185 3897.13944688]]\n",
      "real_output:\n",
      " [[3873.71 3928.65 3859.6  3925.43]]\n",
      "149 [D loss: 0.676912, acc.: 54.50%] [G loss: 1.611903]\n",
      "input:\n",
      " [[4655.24 4688.47 4650.77 4682.85]\n",
      " [4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]\n",
      " [4707.25 4708.53 4670.87 4685.25]\n",
      " [4701.48 4714.92 4694.39 4701.7 ]]\n",
      "fake_output:\n",
      " [[4674.15222472 4685.36911278 4654.34749118 4664.88332429]]\n",
      "real_output:\n",
      " [[4699.26 4718.5  4681.32 4697.53]]\n",
      "150 [D loss: 0.648822, acc.: 58.67%] [G loss: 2.302565]\n",
      "input:\n",
      " [[4403.59 4429.97 4403.59 4419.15]\n",
      " [4402.95 4415.47 4387.01 4400.64]\n",
      " [4416.38 4416.38 4372.51 4401.46]\n",
      " [4409.58 4422.73 4405.45 4422.3 ]\n",
      " [4381.2  4415.18 4381.2  4411.79]]\n",
      "fake_output:\n",
      " [[4390.86317656 4412.521537   4374.69839249 4398.83679936]]\n",
      "real_output:\n",
      " [[4361.27 4369.87 4350.06 4367.48]]\n",
      "151 [D loss: 0.643212, acc.: 62.50%] [G loss: 1.509481]\n",
      "input:\n",
      " [[4386.75 4439.73 4386.75 4438.26]\n",
      " [4358.01 4372.87 4329.92 4363.8 ]\n",
      " [4368.31 4374.89 4342.09 4350.65]\n",
      " [4385.44 4415.88 4360.59 4361.19]\n",
      " [4406.51 4412.02 4386.22 4391.34]]\n",
      "fake_output:\n",
      " [[4371.13053514 4379.69747735 4343.28289275 4349.32163705]]\n",
      "real_output:\n",
      " [[4383.73 4429.97 4383.73 4399.76]]\n",
      "152 [D loss: 0.685585, acc.: 58.50%] [G loss: 1.830529]\n",
      "input:\n",
      " [[3071.04 3088.42 2984.47 3041.31]\n",
      " [3123.53 3123.53 2999.49 3002.1 ]\n",
      " [3213.42 3223.27 3181.49 3190.14]\n",
      " [3213.32 3222.71 3193.11 3207.18]\n",
      " [3199.92 3233.13 3196.   3232.39]]\n",
      "fake_output:\n",
      " [[3201.01851967 3220.23816781 3202.40125024 3213.18353155]]\n",
      "real_output:\n",
      " [[3163.84 3211.72 3163.84 3193.93]]\n",
      "153 [D loss: 0.696110, acc.: 60.50%] [G loss: 2.030275]\n",
      "input:\n",
      " [[4690.86 4705.06 4674.52 4701.21]\n",
      " [4631.97 4694.04 4631.97 4686.75]\n",
      " [4548.37 4612.6  4540.51 4591.67]\n",
      " [4589.49 4608.03 4495.12 4538.43]\n",
      " [4504.73 4595.46 4504.73 4577.1 ]]\n",
      "fake_output:\n",
      " [[4450.90281258 4512.91048325 4369.01818091 4426.17607856]]\n",
      "real_output:\n",
      " [[4602.82 4652.94 4510.27 4513.04]]\n",
      "154 [D loss: 0.690424, acc.: 56.50%] [G loss: 1.438119]\n",
      "input:\n",
      " [[4679.42 4714.95 4679.42 4700.9 ]\n",
      " [4689.3  4697.42 4672.86 4682.8 ]\n",
      " [4655.24 4688.47 4650.77 4682.85]\n",
      " [4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]]\n",
      "fake_output:\n",
      " [[4660.22033505 4670.72235608 4637.12717689 4645.86132301]]\n",
      "real_output:\n",
      " [[4707.25 4708.53 4670.87 4685.25]]\n",
      "155 [D loss: 0.689641, acc.: 56.33%] [G loss: 1.727474]\n",
      "input:\n",
      " [[3566.82 3589.81 3552.77 3577.59]\n",
      " [3579.31 3581.23 3556.85 3557.54]\n",
      " [3559.41 3585.22 3543.84 3581.87]\n",
      " [3612.09 3619.09 3567.33 3567.79]\n",
      " [3610.31 3623.11 3588.68 3609.53]]\n",
      "fake_output:\n",
      " [[3524.45014137 3538.73688733 3509.60660766 3511.8348181 ]]\n",
      "real_output:\n",
      " [[3600.16 3628.51 3600.16 3626.91]]\n",
      "156 [D loss: 0.666031, acc.: 62.17%] [G loss: 1.897119]\n",
      "input:\n",
      " [[4580.22 4584.57 4551.66 4551.68]\n",
      " [4578.69 4598.53 4569.17 4574.79]\n",
      " [4553.69 4572.62 4537.36 4566.48]\n",
      " [4546.12 4559.67 4524.   4544.9 ]\n",
      " [4532.24 4551.44 4526.89 4549.78]]\n",
      "fake_output:\n",
      " [[4505.68418755 4515.03558173 4482.99041826 4514.98173354]]\n",
      "real_output:\n",
      " [[4524.42 4540.87 4524.4  4536.19]]\n",
      "157 [D loss: 0.681099, acc.: 55.50%] [G loss: 1.380581]\n",
      "input:\n",
      " [[3363.56 3402.93 3363.56 3383.54]\n",
      " [3352.7  3368.95 3310.47 3340.97]\n",
      " [3412.56 3425.55 3329.25 3339.19]\n",
      " [3369.82 3424.77 3366.84 3398.96]\n",
      " [3371.88 3379.97 3329.27 3331.84]]\n",
      "fake_output:\n",
      " [[3351.59413419 3368.76791774 3311.48630207 3319.73623057]]\n",
      "real_output:\n",
      " [[3453.6  3479.15 3349.63 3426.96]]\n",
      "158 [D loss: 0.682992, acc.: 55.50%] [G loss: 2.104927]\n",
      "input:\n",
      " [[3293.59 3304.93 3233.94 3269.96]\n",
      " [3277.17 3341.05 3259.82 3310.11]\n",
      " [3342.48 3342.48 3268.89 3271.03]\n",
      " [3403.15 3409.51 3388.71 3390.68]\n",
      " [3441.42 3441.42 3364.86 3400.97]]\n",
      "fake_output:\n",
      " [[3293.16606263 3310.00498475 3237.16199742 3258.91464799]]\n",
      "real_output:\n",
      " [[3464.9  3466.46 3440.45 3465.39]]\n",
      "159 [D loss: 0.663819, acc.: 60.33%] [G loss: 1.730752]\n",
      "input:\n",
      " [[3412.56 3425.55 3329.25 3339.19]\n",
      " [3369.82 3424.77 3366.84 3398.96]\n",
      " [3371.88 3379.97 3329.27 3331.84]\n",
      " [3453.6  3479.15 3349.63 3426.96]\n",
      " [3564.74 3564.85 3427.41 3455.06]]\n",
      "fake_output:\n",
      " [[3568.23358691 3594.7547602  3465.79165368 3520.41692864]]\n",
      "real_output:\n",
      " [[3543.76 3588.11 3535.23 3580.84]]\n",
      "160 [D loss: 0.681323, acc.: 56.17%] [G loss: 1.483520]\n",
      "input:\n",
      " [[4309.87 4369.23 4309.87 4345.72]\n",
      " [4348.84 4355.51 4278.94 4300.46]\n",
      " [4317.16 4375.19 4288.52 4357.04]\n",
      " [4370.67 4382.55 4306.24 4307.54]\n",
      " [4362.41 4385.57 4355.08 4359.46]]\n",
      "fake_output:\n",
      " [[4371.10482625 4388.28701164 4357.19258913 4376.01320192]]\n",
      "real_output:\n",
      " [[4419.54 4419.54 4346.33 4352.63]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 [D loss: 0.690486, acc.: 58.17%] [G loss: 1.861891]\n",
      "input:\n",
      " [[3764.61 3769.99 3662.71 3700.65]\n",
      " [3733.27 3760.2  3726.88 3756.07]\n",
      " [3736.19 3744.63 3730.21 3732.04]\n",
      " [3750.01 3756.12 3723.31 3727.04]\n",
      " [3723.03 3740.51 3723.03 3735.36]]\n",
      "fake_output:\n",
      " [[3739.56722988 3750.81826188 3711.48822287 3724.7499841 ]]\n",
      "real_output:\n",
      " [[3694.03 3703.82 3689.32 3703.06]]\n",
      "162 [D loss: 0.707249, acc.: 54.00%] [G loss: 1.844883]\n",
      "input:\n",
      " [[2939.5  2945.82 2869.59 2870.12]\n",
      " [2915.46 2944.25 2903.44 2930.32]\n",
      " [2908.83 2932.16 2902.88 2929.8 ]\n",
      " [2878.26 2901.92 2876.48 2881.19]\n",
      " [2883.14 2891.11 2847.65 2848.42]]\n",
      "fake_output:\n",
      " [[2874.03825816 2883.80729623 2846.63623808 2829.60593326]]\n",
      "real_output:\n",
      " [[2868.88 2898.23 2863.55 2868.44]]\n",
      "163 [D loss: 0.712760, acc.: 50.67%] [G loss: 1.943700]\n",
      "input:\n",
      " [[3802.23 3820.96 3791.5  3809.84]\n",
      " [3801.62 3810.78 3776.51 3801.19]\n",
      " [3803.14 3817.86 3789.02 3799.61]\n",
      " [3815.05 3826.69 3783.6  3824.68]\n",
      " [3764.71 3811.55 3764.71 3803.79]]\n",
      "fake_output:\n",
      " [[3760.79431204 3802.52213057 3756.44422673 3782.81658535]]\n",
      "real_output:\n",
      " [[3712.2  3783.04 3705.34 3748.14]]\n",
      "164 [D loss: 0.698207, acc.: 50.00%] [G loss: 1.607977]\n",
      "input:\n",
      " [[4778.14 4796.64 4758.17 4796.56]\n",
      " [4775.21 4786.83 4765.75 4766.18]\n",
      " [4794.23 4808.93 4775.33 4778.73]\n",
      " [4788.64 4804.06 4778.08 4793.06]\n",
      " [4795.49 4807.02 4780.04 4786.35]]\n",
      "fake_output:\n",
      " [[4787.46468664 4801.39208302 4773.96504379 4785.3375294 ]]\n",
      "real_output:\n",
      " [[4733.99 4791.49 4733.99 4791.19]]\n",
      "165 [D loss: 0.700480, acc.: 58.33%] [G loss: 1.898890]\n",
      "input:\n",
      " [[2868.88 2898.23 2863.55 2868.44]\n",
      " [2815.01 2844.24 2797.85 2842.74]\n",
      " [2869.09 2869.09 2821.61 2830.71]\n",
      " [2930.91 2930.91 2892.47 2912.43]\n",
      " [2918.46 2954.86 2912.16 2939.51]]\n",
      "fake_output:\n",
      " [[2909.98270339 2934.10839349 2909.50719467 2923.80658284]]\n",
      "real_output:\n",
      " [[2909.96 2921.15 2860.71 2863.39]]\n",
      "166 [D loss: 0.722452, acc.: 51.67%] [G loss: 1.209778]\n",
      "input:\n",
      " [[4462.12 4462.12 4417.83 4448.08]\n",
      " [4461.65 4480.26 4437.66 4479.71]\n",
      " [4464.84 4468.37 4460.82 4468.  ]\n",
      " [4446.08 4461.77 4435.96 4460.83]\n",
      " [4442.18 4449.44 4436.42 4447.7 ]]\n",
      "fake_output:\n",
      " [[4455.70545458 4464.16220133 4439.71761627 4460.58542449]]\n",
      "real_output:\n",
      " [[4435.79 4445.21 4430.03 4436.75]]\n",
      "167 [D loss: 0.732828, acc.: 50.17%] [G loss: 1.771631]\n",
      "input:\n",
      " [[4462.12 4462.12 4417.83 4448.08]\n",
      " [4461.65 4480.26 4437.66 4479.71]\n",
      " [4464.84 4468.37 4460.82 4468.  ]\n",
      " [4446.08 4461.77 4435.96 4460.83]\n",
      " [4442.18 4449.44 4436.42 4447.7 ]]\n",
      "fake_output:\n",
      " [[4431.68326107 4434.11333842 4395.46306846 4420.14302357]]\n",
      "real_output:\n",
      " [[4435.79 4445.21 4430.03 4436.75]]\n",
      "168 [D loss: 0.691465, acc.: 56.17%] [G loss: 1.479067]\n",
      "input:\n",
      " [[4690.86 4705.06 4674.52 4701.21]\n",
      " [4631.97 4694.04 4631.97 4686.75]\n",
      " [4548.37 4612.6  4540.51 4591.67]\n",
      " [4589.49 4608.03 4495.12 4538.43]\n",
      " [4504.73 4595.46 4504.73 4577.1 ]]\n",
      "fake_output:\n",
      " [[4623.87482335 4669.18356132 4640.9350523  4663.24008403]]\n",
      "real_output:\n",
      " [[4602.82 4652.94 4510.27 4513.04]]\n",
      "169 [D loss: 0.675789, acc.: 63.33%] [G loss: 1.484838]\n",
      "input:\n",
      " [[3694.73 3697.41 3678.88 3691.96]\n",
      " [3670.94 3699.2  3670.94 3699.12]\n",
      " [3668.28 3682.73 3657.17 3666.72]\n",
      " [3653.78 3670.96 3644.84 3669.01]\n",
      " [3645.87 3678.45 3645.87 3662.45]]\n",
      "fake_output:\n",
      " [[3650.71892538 3672.84196036 3644.52395944 3659.17993443]]\n",
      "real_output:\n",
      " [[3634.18 3634.18 3594.39 3621.63]]\n",
      "170 [D loss: 0.712798, acc.: 54.00%] [G loss: 1.966484]\n",
      "input:\n",
      " [[3140.29 3155.53 3083.11 3097.74]\n",
      " [3101.64 3120.   3093.51 3115.34]\n",
      " [3136.13 3141.16 3108.03 3113.49]\n",
      " [3131.   3153.45 3076.06 3124.74]\n",
      " [2993.76 3079.76 2965.66 3066.59]]\n",
      "fake_output:\n",
      " [[2968.32865827 3046.97264782 2918.8726192  3038.55448223]]\n",
      "real_output:\n",
      " [[3071.04 3088.42 2984.47 3041.31]]\n",
      "171 [D loss: 0.679188, acc.: 56.33%] [G loss: 1.568915]\n",
      "input:\n",
      " [[3152.47 3186.82 3136.22 3185.04]\n",
      " [3176.17 3179.78 3115.7  3152.05]\n",
      " [3153.07 3171.8  3136.53 3169.94]\n",
      " [3166.44 3184.15 3142.93 3145.32]\n",
      " [3155.29 3182.59 3155.29 3179.72]]\n",
      "fake_output:\n",
      " [[3134.15017148 3163.02655807 3092.70312848 3107.95998583]]\n",
      "real_output:\n",
      " [[3143.64 3165.81 3124.52 3130.01]]\n",
      "172 [D loss: 0.685628, acc.: 56.33%] [G loss: 1.494755]\n",
      "input:\n",
      " [[3915.8  3925.02 3814.04 3829.34]\n",
      " [3873.71 3928.65 3859.6  3925.43]\n",
      " [3857.07 3895.98 3805.59 3881.37]\n",
      " [3885.55 3902.92 3874.71 3876.5 ]\n",
      " [3921.16 3930.41 3903.07 3906.71]]\n",
      "fake_output:\n",
      " [[3895.19713864 3918.52202535 3863.73603372 3890.23593092]]\n",
      "real_output:\n",
      " [[3915.86 3921.98 3885.03 3913.97]]\n",
      "173 [D loss: 0.676133, acc.: 56.50%] [G loss: 1.690612]\n",
      "input:\n",
      " [[2878.26 2901.92 2876.48 2881.19]\n",
      " [2883.14 2891.11 2847.65 2848.42]\n",
      " [2868.88 2898.23 2863.55 2868.44]\n",
      " [2815.01 2844.24 2797.85 2842.74]\n",
      " [2869.09 2869.09 2821.61 2830.71]]\n",
      "fake_output:\n",
      " [[2846.49616057 2861.24994466 2819.39643426 2837.53992475]]\n",
      "real_output:\n",
      " [[2930.91 2930.91 2892.47 2912.43]]\n",
      "174 [D loss: 0.663403, acc.: 59.33%] [G loss: 1.864940]\n",
      "input:\n",
      " [[4367.43 4375.09 4322.53 4327.16]\n",
      " [4369.02 4369.02 4340.7  4360.03]\n",
      " [4380.11 4393.68 4362.36 4374.3 ]\n",
      " [4381.07 4392.37 4366.92 4369.21]\n",
      " [4372.41 4386.68 4364.03 4384.63]]\n",
      "fake_output:\n",
      " [[4363.10822999 4359.93811569 4312.24003023 4314.11420873]]\n",
      "real_output:\n",
      " [[4329.38 4371.6  4329.38 4369.55]]\n",
      "175 [D loss: 0.696325, acc.: 54.67%] [G loss: 1.278331]\n",
      "input:\n",
      " [[4159.18 4159.18 4118.38 4134.94]\n",
      " [4179.8  4180.81 4150.47 4163.26]\n",
      " [4174.14 4191.31 4170.75 4185.47]\n",
      " [4139.76 4173.49 4139.76 4170.42]\n",
      " [4141.58 4151.69 4120.87 4124.66]]\n",
      "fake_output:\n",
      " [[4145.10997269 4155.59093244 4120.96272528 4130.72172847]]\n",
      "real_output:\n",
      " [[4130.1  4148.   4124.43 4141.59]]\n",
      "176 [D loss: 0.675572, acc.: 60.33%] [G loss: 1.845496]\n",
      "input:\n",
      " [[3563.22 3581.16 3557.   3572.66]\n",
      " [3543.26 3557.22 3511.91 3545.53]\n",
      " [3583.04 3645.99 3547.48 3550.5 ]\n",
      " [3508.34 3521.58 3484.34 3509.44]\n",
      " [3485.74 3529.05 3485.74 3510.45]]\n",
      "fake_output:\n",
      " [[3412.83659355 3367.63963178 3386.2248596  3424.22424375]]\n",
      "real_output:\n",
      " [[3406.46 3486.25 3405.17 3443.44]]\n",
      "177 [D loss: 0.729494, acc.: 56.67%] [G loss: 1.289525]\n",
      "input:\n",
      " [[4712.   4743.83 4682.17 4682.94]\n",
      " [4708.44 4717.75 4694.22 4697.96]\n",
      " [4700.72 4708.8  4672.78 4704.54]\n",
      " [4701.5  4701.5  4684.41 4688.67]\n",
      " [4679.42 4714.95 4679.42 4700.9 ]]\n",
      "fake_output:\n",
      " [[4699.10327823 4713.9374248  4682.42460462 4693.61149535]]\n",
      "real_output:\n",
      " [[4689.3  4697.42 4672.86 4682.8 ]]\n",
      "178 [D loss: 0.740156, acc.: 50.33%] [G loss: 1.496014]\n",
      "input:\n",
      " [[4034.44 4083.42 4034.44 4077.91]\n",
      " [3992.78 4020.63 3992.78 4019.87]\n",
      " [3967.25 3994.41 3966.98 3972.89]\n",
      " [3963.34 3968.01 3944.35 3958.55]\n",
      " [3969.31 3981.83 3943.25 3971.09]]\n",
      "fake_output:\n",
      " [[3980.13524806 3994.7265387  3970.97276945 3983.474608  ]]\n",
      "real_output:\n",
      " [[3917.12 3978.19 3917.12 3974.54]]\n",
      "179 [D loss: 0.671739, acc.: 57.50%] [G loss: 1.740901]\n",
      "input:\n",
      " [[4204.78 4204.78 4164.4  4166.45]\n",
      " [4220.37 4232.29 4196.05 4221.86]\n",
      " [4248.87 4251.89 4202.45 4223.7 ]\n",
      " [4255.28 4257.16 4238.35 4246.59]\n",
      " [4248.31 4255.59 4234.07 4255.15]]\n",
      "fake_output:\n",
      " [[4239.64221254 4240.35884347 4215.50849997 4225.75183387]]\n",
      "real_output:\n",
      " [[4242.9  4248.38 4232.25 4247.44]]\n",
      "180 [D loss: 0.746260, acc.: 47.33%] [G loss: 1.956679]\n",
      "input:\n",
      " [[3638.55 3644.31 3629.33 3638.35]\n",
      " [3635.5  3635.5  3617.76 3629.65]\n",
      " [3594.52 3642.31 3594.52 3635.41]\n",
      " [3566.82 3589.81 3552.77 3577.59]\n",
      " [3579.31 3581.23 3556.85 3557.54]]\n",
      "fake_output:\n",
      " [[3552.03970767 3555.5951167  3523.95216405 3528.38364146]]\n",
      "real_output:\n",
      " [[3559.41 3585.22 3543.84 3581.87]]\n",
      "181 [D loss: 0.714156, acc.: 49.50%] [G loss: 1.328223]\n",
      "input:\n",
      " [[2578.28 2676.85 2574.57 2663.68]\n",
      " [2514.92 2538.18 2459.96 2488.65]\n",
      " [2458.54 2533.22 2455.79 2526.9 ]\n",
      " [2498.08 2522.75 2447.49 2470.5 ]\n",
      " [2614.69 2641.39 2571.15 2584.59]]\n",
      "fake_output:\n",
      " [[2364.41932212 2325.49382375 2282.22510939 2257.24826324]]\n",
      "real_output:\n",
      " [[2558.98 2631.8  2545.28 2626.65]]\n",
      "182 [D loss: 0.711879, acc.: 54.83%] [G loss: 2.004096]\n",
      "input:\n",
      " [[4381.07 4392.37 4366.92 4369.21]\n",
      " [4372.41 4386.68 4364.03 4384.63]\n",
      " [4329.38 4371.6  4329.38 4369.55]\n",
      " [4321.07 4330.88 4289.37 4320.82]\n",
      " [4351.01 4361.88 4329.79 4358.13]]\n",
      "fake_output:\n",
      " [[4338.51046489 4350.02132468 4319.61659168 4344.51208024]]\n",
      "real_output:\n",
      " [[4356.46 4356.46 4314.37 4343.54]]\n",
      "183 [D loss: 0.706689, acc.: 50.83%] [G loss: 1.437993]\n",
      "input:\n",
      " [[3963.34 3968.01 3944.35 3958.55]\n",
      " [3969.31 3981.83 3943.25 3971.09]\n",
      " [3917.12 3978.19 3917.12 3974.54]\n",
      " [3879.34 3919.54 3853.5  3909.52]\n",
      " [3919.93 3942.08 3889.07 3889.14]]\n",
      "fake_output:\n",
      " [[3970.42612093 3995.11046969 3985.27678853 4008.39768433]]\n",
      "real_output:\n",
      " [[3937.6  3949.13 3901.57 3910.52]]\n",
      "184 [D loss: 0.709259, acc.: 50.50%] [G loss: 1.245934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " [[3098.9  3130.94 3098.9  3122.87]\n",
      " [3064.78 3081.07 3051.64 3080.82]\n",
      " [3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]]\n",
      "fake_output:\n",
      " [[3006.74014766 3007.14423353 2961.80713641 2981.29914469]]\n",
      "real_output:\n",
      " [[3015.65 3036.25 2969.75 3036.13]]\n",
      "185 [D loss: 0.721231, acc.: 47.17%] [G loss: 1.305458]\n",
      "input:\n",
      " [[3920.78 3931.5  3884.94 3909.88]\n",
      " [3910.49 3918.35 3902.64 3911.23]\n",
      " [3892.59 3915.77 3892.59 3915.59]\n",
      " [3878.3  3894.56 3874.93 3886.83]\n",
      " [3836.66 3872.42 3836.66 3871.74]]\n",
      "fake_output:\n",
      " [[3877.18123205 3893.9536488  3868.23331626 3888.98389278]]\n",
      "real_output:\n",
      " [[3840.27 3847.51 3816.68 3830.17]]\n",
      "186 [D loss: 0.675245, acc.: 54.33%] [G loss: 1.881258]\n",
      "input:\n",
      " [[3645.87 3678.45 3645.87 3662.45]\n",
      " [3634.18 3634.18 3594.39 3621.63]\n",
      " [3638.55 3644.31 3629.33 3638.35]\n",
      " [3635.5  3635.5  3617.76 3629.65]\n",
      " [3594.52 3642.31 3594.52 3635.41]]\n",
      "fake_output:\n",
      " [[3607.25712541 3620.03899091 3585.67351081 3614.29851996]]\n",
      "real_output:\n",
      " [[3566.82 3589.81 3552.77 3577.59]]\n",
      "187 [D loss: 0.700564, acc.: 54.33%] [G loss: 1.487243]\n",
      "input:\n",
      " [[3270.45 3272.17 3220.26 3271.12]\n",
      " [3231.76 3250.92 3204.13 3246.22]\n",
      " [3227.22 3264.74 3227.22 3258.44]\n",
      " [3234.27 3243.72 3216.17 3218.44]\n",
      " [3219.84 3241.43 3214.25 3239.41]]\n",
      "fake_output:\n",
      " [[3201.41929419 3223.60110935 3197.92163543 3199.23556781]]\n",
      "real_output:\n",
      " [[3218.58 3227.26 3200.05 3215.63]]\n",
      "188 [D loss: 0.654423, acc.: 59.17%] [G loss: 1.476021]\n",
      "input:\n",
      " [[3296.2  3330.14 3279.74 3310.24]\n",
      " [3293.59 3304.93 3233.94 3269.96]\n",
      " [3277.17 3341.05 3259.82 3310.11]\n",
      " [3342.48 3342.48 3268.89 3271.03]\n",
      " [3403.15 3409.51 3388.71 3390.68]]\n",
      "fake_output:\n",
      " [[3286.52160671 3310.18704523 3235.96092758 3265.65456682]]\n",
      "real_output:\n",
      " [[3441.42 3441.42 3364.86 3400.97]]\n",
      "189 [D loss: 0.669972, acc.: 57.33%] [G loss: 2.781305]\n",
      "input:\n",
      " [[2514.92 2538.18 2459.96 2488.65]\n",
      " [2458.54 2533.22 2455.79 2526.9 ]\n",
      " [2498.08 2522.75 2447.49 2470.5 ]\n",
      " [2614.69 2641.39 2571.15 2584.59]\n",
      " [2558.98 2631.8  2545.28 2626.65]]\n",
      "fake_output:\n",
      " [[2576.27337331 2625.15204296 2566.16001534 2608.04114258]]\n",
      "real_output:\n",
      " [[2555.87 2615.91 2520.02 2541.47]]\n",
      "190 [D loss: 0.697433, acc.: 52.83%] [G loss: 1.704520]\n",
      "input:\n",
      " [[4679.42 4714.95 4679.42 4700.9 ]\n",
      " [4689.3  4697.42 4672.86 4682.8 ]\n",
      " [4655.24 4688.47 4650.77 4682.85]\n",
      " [4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]]\n",
      "fake_output:\n",
      " [[4666.99693304 4682.13387383 4651.79804749 4663.54712335]]\n",
      "real_output:\n",
      " [[4707.25 4708.53 4670.87 4685.25]]\n",
      "191 [D loss: 0.724107, acc.: 49.17%] [G loss: 1.498860]\n",
      "input:\n",
      " [[3736.19 3744.63 3730.21 3732.04]\n",
      " [3750.01 3756.12 3723.31 3727.04]\n",
      " [3723.03 3740.51 3723.03 3735.36]\n",
      " [3694.03 3703.82 3689.32 3703.06]\n",
      " [3693.42 3711.24 3689.28 3690.01]]\n",
      "fake_output:\n",
      " [[3697.70634497 3702.52134227 3690.24311182 3692.32435183]]\n",
      "real_output:\n",
      " [[3698.08 3698.26 3676.16 3687.26]]\n",
      "192 [D loss: 0.762081, acc.: 47.67%] [G loss: 1.022244]\n",
      "input:\n",
      " [[4210.34 4238.04 4201.64 4232.6 ]\n",
      " [4169.14 4202.7  4147.33 4201.62]\n",
      " [4177.06 4187.72 4160.94 4167.59]\n",
      " [4179.04 4179.04 4128.59 4164.66]\n",
      " [4191.98 4209.39 4188.03 4192.66]]\n",
      "fake_output:\n",
      " [[4206.52920423 4242.24377961 4229.87774336 4250.12454501]]\n",
      "real_output:\n",
      " [[4198.1  4198.1  4174.85 4181.17]]\n",
      "193 [D loss: 0.686632, acc.: 56.83%] [G loss: 1.492538]\n",
      "input:\n",
      " [[3386.01 3399.96 3379.31 3397.16]\n",
      " [3360.48 3390.8  3354.69 3385.51]\n",
      " [3392.51 3399.54 3369.66 3374.85]\n",
      " [3387.04 3395.06 3370.15 3389.78]\n",
      " [3380.86 3387.59 3379.22 3381.99]]\n",
      "fake_output:\n",
      " [[3387.85911298 3397.86603438 3378.48361973 3391.4850976 ]]\n",
      "real_output:\n",
      " [[3368.66 3378.51 3361.64 3372.85]]\n",
      "194 [D loss: 0.744930, acc.: 50.33%] [G loss: 1.507225]\n",
      "input:\n",
      " [[4534.48 4545.85 4524.66 4536.95]\n",
      " [4528.8  4537.11 4522.02 4524.09]\n",
      " [4529.75 4531.39 4515.8  4522.68]\n",
      " [4513.76 4537.36 4513.76 4528.79]\n",
      " [4474.1  4513.33 4474.1  4509.37]]\n",
      "fake_output:\n",
      " [[4461.07417549 4496.47543601 4453.16547151 4494.21178903]]\n",
      "real_output:\n",
      " [[4493.75 4495.9  4468.99 4470.  ]]\n",
      "195 [D loss: 0.701123, acc.: 52.33%] [G loss: 2.427527]\n",
      "input:\n",
      " [[4130.55 4134.73 4056.88 4063.04]\n",
      " [4150.34 4162.04 4111.53 4152.1 ]\n",
      " [4228.29 4236.39 4188.13 4188.43]\n",
      " [4210.34 4238.04 4201.64 4232.6 ]\n",
      " [4169.14 4202.7  4147.33 4201.62]]\n",
      "fake_output:\n",
      " [[4125.99181932 4113.04727176 4050.9362587  4052.50780459]]\n",
      "real_output:\n",
      " [[4177.06 4187.72 4160.94 4167.59]]\n",
      "196 [D loss: 0.749966, acc.: 55.00%] [G loss: 1.269963]\n",
      "input:\n",
      " [[4381.07 4392.37 4366.92 4369.21]\n",
      " [4372.41 4386.68 4364.03 4384.63]\n",
      " [4329.38 4371.6  4329.38 4369.55]\n",
      " [4321.07 4330.88 4289.37 4320.82]\n",
      " [4351.01 4361.88 4329.79 4358.13]]\n",
      "fake_output:\n",
      " [[4340.36704899 4354.46524033 4321.51790563 4347.38145159]]\n",
      "real_output:\n",
      " [[4356.46 4356.46 4314.37 4343.54]]\n",
      "197 [D loss: 0.695558, acc.: 55.00%] [G loss: 1.730561]\n",
      "input:\n",
      " [[4678.48 4699.39 4652.66 4690.7 ]\n",
      " [4712.   4743.83 4682.17 4682.94]\n",
      " [4708.44 4717.75 4694.22 4697.96]\n",
      " [4700.72 4708.8  4672.78 4704.54]\n",
      " [4701.5  4701.5  4684.41 4688.67]]\n",
      "fake_output:\n",
      " [[4710.57167162 4732.60014307 4697.70032634 4703.35157553]]\n",
      "real_output:\n",
      " [[4679.42 4714.95 4679.42 4700.9 ]]\n",
      "198 [D loss: 0.712813, acc.: 56.17%] [G loss: 1.955238]\n",
      "input:\n",
      " [[4701.5  4701.5  4684.41 4688.67]\n",
      " [4679.42 4714.95 4679.42 4700.9 ]\n",
      " [4689.3  4697.42 4672.86 4682.8 ]\n",
      " [4655.24 4688.47 4650.77 4682.85]\n",
      " [4659.39 4664.55 4648.31 4649.27]]\n",
      "fake_output:\n",
      " [[4687.23226613 4705.18171928 4680.48495657 4694.86488154]]\n",
      "real_output:\n",
      " [[4670.26 4684.85 4630.86 4646.71]]\n",
      "199 [D loss: 0.735305, acc.: 47.00%] [G loss: 1.013596]\n",
      "input:\n",
      " [[3713.65 3725.12 3710.87 3722.48]\n",
      " [3696.25 3711.27 3688.57 3701.17]\n",
      " [3666.41 3695.29 3659.62 3694.62]\n",
      " [3675.27 3697.61 3645.84 3647.49]\n",
      " [3656.08 3665.91 3633.4  3663.46]]\n",
      "fake_output:\n",
      " [[3607.94954099 3611.12767141 3545.98820189 3564.46837011]]\n",
      "real_output:\n",
      " [[3659.13 3678.49 3645.18 3668.1 ]]\n",
      "200 [D loss: 0.706549, acc.: 51.83%] [G loss: 1.403516]\n",
      "input:\n",
      " [[3939.61 3950.43 3923.85 3932.59]\n",
      " [3911.65 3937.23 3905.78 3934.83]\n",
      " [3916.4  3925.99 3890.39 3916.38]\n",
      " [3920.78 3931.5  3884.94 3909.88]\n",
      " [3910.49 3918.35 3902.64 3911.23]]\n",
      "fake_output:\n",
      " [[3907.80389771 3917.68615796 3883.92563665 3906.51256543]]\n",
      "real_output:\n",
      " [[3892.59 3915.77 3892.59 3915.59]]\n",
      "201 [D loss: 0.756552, acc.: 46.67%] [G loss: 1.306814]\n",
      "input:\n",
      " [[3357.38 3362.27 3292.4  3319.47]\n",
      " [3346.86 3375.17 3328.82 3357.01]\n",
      " [3411.23 3428.92 3384.45 3385.49]\n",
      " [3407.73 3419.48 3389.25 3401.2 ]\n",
      " [3363.56 3402.93 3363.56 3383.54]]\n",
      "fake_output:\n",
      " [[3369.54788231 3384.35273847 3343.03194457 3357.51535094]]\n",
      "real_output:\n",
      " [[3352.7  3368.95 3310.47 3340.97]]\n",
      "202 [D loss: 0.771383, acc.: 48.50%] [G loss: 1.176987]\n",
      "input:\n",
      " [[4361.27 4369.87 4350.06 4367.48]\n",
      " [4331.13 4359.7  4331.13 4358.69]\n",
      " [4265.11 4336.84 4262.05 4323.06]\n",
      " [4296.4  4296.4  4233.13 4258.49]\n",
      " [4367.43 4375.09 4322.53 4327.16]]\n",
      "fake_output:\n",
      " [[4252.28722345 4280.63393342 4202.13908633 4235.1702573 ]]\n",
      "real_output:\n",
      " [[4369.02 4369.02 4340.7  4360.03]]\n",
      "203 [D loss: 0.679420, acc.: 55.50%] [G loss: 1.370239]\n",
      "input:\n",
      " [[3836.83 3836.83 3732.48 3750.77]\n",
      " [3862.96 3870.9  3847.78 3849.62]\n",
      " [3851.68 3859.23 3797.16 3855.36]\n",
      " [3844.24 3852.31 3830.41 3841.47]\n",
      " [3857.46 3861.45 3845.05 3853.07]]\n",
      "fake_output:\n",
      " [[3858.44842518 3867.85112415 3870.82392249 3880.31758593]]\n",
      "real_output:\n",
      " [[3816.22 3859.75 3816.22 3851.85]]\n",
      "204 [D loss: 0.705450, acc.: 54.17%] [G loss: 1.261557]\n",
      "input:\n",
      " [[3851.68 3859.23 3797.16 3855.36]\n",
      " [3844.24 3852.31 3830.41 3841.47]\n",
      " [3857.46 3861.45 3845.05 3853.07]\n",
      " [3816.22 3859.75 3816.22 3851.85]\n",
      " [3781.88 3804.53 3780.37 3798.91]]\n",
      "fake_output:\n",
      " [[3806.38726139 3823.37974815 3790.69585547 3817.1564668 ]]\n",
      "real_output:\n",
      " [[3788.73 3788.73 3749.62 3768.25]]\n",
      "205 [D loss: 0.716955, acc.: 52.17%] [G loss: 1.221742]\n",
      "input:\n",
      " [[4691.   4695.26 4665.98 4667.45]\n",
      " [4690.86 4705.06 4674.52 4701.21]\n",
      " [4631.97 4694.04 4631.97 4686.75]\n",
      " [4548.37 4612.6  4540.51 4591.67]\n",
      " [4589.49 4608.03 4495.12 4538.43]]\n",
      "fake_output:\n",
      " [[4672.60524603 4699.25468743 4676.90493942 4697.91574706]]\n",
      "real_output:\n",
      " [[4504.73 4595.46 4504.73 4577.1 ]]\n",
      "206 [D loss: 0.738472, acc.: 48.17%] [G loss: 1.311804]\n",
      "input:\n",
      " [[4204.78 4204.78 4164.4  4166.45]\n",
      " [4220.37 4232.29 4196.05 4221.86]\n",
      " [4248.87 4251.89 4202.45 4223.7 ]\n",
      " [4255.28 4257.16 4238.35 4246.59]\n",
      " [4248.31 4255.59 4234.07 4255.15]]\n",
      "fake_output:\n",
      " [[4224.87074177 4225.63376495 4190.86508266 4201.40793352]]\n",
      "real_output:\n",
      " [[4242.9  4248.38 4232.25 4247.44]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 [D loss: 0.682590, acc.: 56.33%] [G loss: 1.786676]\n",
      "input:\n",
      " [[4228.29 4236.39 4188.13 4188.43]\n",
      " [4210.34 4238.04 4201.64 4232.6 ]\n",
      " [4169.14 4202.7  4147.33 4201.62]\n",
      " [4177.06 4187.72 4160.94 4167.59]\n",
      " [4179.04 4179.04 4128.59 4164.66]]\n",
      "fake_output:\n",
      " [[4207.89539371 4226.99554458 4189.98175199 4212.8733721 ]]\n",
      "real_output:\n",
      " [[4191.98 4209.39 4188.03 4192.66]]\n",
      "208 [D loss: 0.735570, acc.: 47.00%] [G loss: 1.321617]\n",
      "input:\n",
      " [[3411.23 3428.92 3384.45 3385.49]\n",
      " [3407.73 3419.48 3389.25 3401.2 ]\n",
      " [3363.56 3402.93 3363.56 3383.54]\n",
      " [3352.7  3368.95 3310.47 3340.97]\n",
      " [3412.56 3425.55 3329.25 3339.19]]\n",
      "fake_output:\n",
      " [[3361.846124   3376.88179723 3315.71135713 3333.43059148]]\n",
      "real_output:\n",
      " [[3369.82 3424.77 3366.84 3398.96]]\n",
      "209 [D loss: 0.711578, acc.: 50.17%] [G loss: 1.416057]\n",
      "input:\n",
      " [[3873.71 3928.65 3859.6  3925.43]\n",
      " [3857.07 3895.98 3805.59 3881.37]\n",
      " [3885.55 3902.92 3874.71 3876.5 ]\n",
      " [3921.16 3930.41 3903.07 3906.71]\n",
      " [3915.86 3921.98 3885.03 3913.97]]\n",
      "fake_output:\n",
      " [[3911.7434382  3928.89515971 3907.5633856  3921.03437323]]\n",
      "real_output:\n",
      " [[3918.5  3933.61 3900.43 3931.33]]\n",
      "210 [D loss: 0.733925, acc.: 47.83%] [G loss: 1.295022]\n",
      "input:\n",
      " [[4130.55 4134.73 4056.88 4063.04]\n",
      " [4150.34 4162.04 4111.53 4152.1 ]\n",
      " [4228.29 4236.39 4188.13 4188.43]\n",
      " [4210.34 4238.04 4201.64 4232.6 ]\n",
      " [4169.14 4202.7  4147.33 4201.62]]\n",
      "fake_output:\n",
      " [[4127.51931663 4126.20537843 4060.57566365 4067.5390601 ]]\n",
      "real_output:\n",
      " [[4177.06 4187.72 4160.94 4167.59]]\n",
      "211 [D loss: 0.699596, acc.: 54.33%] [G loss: 1.772901]\n",
      "input:\n",
      " [[3152.47 3186.82 3136.22 3185.04]\n",
      " [3176.17 3179.78 3115.7  3152.05]\n",
      " [3153.07 3171.8  3136.53 3169.94]\n",
      " [3166.44 3184.15 3142.93 3145.32]\n",
      " [3155.29 3182.59 3155.29 3179.72]]\n",
      "fake_output:\n",
      " [[3165.8895996  3183.97025738 3147.6639574  3177.20856447]]\n",
      "real_output:\n",
      " [[3143.64 3165.81 3124.52 3130.01]]\n",
      "212 [D loss: 0.700684, acc.: 51.67%] [G loss: 1.366729]\n",
      "input:\n",
      " [[2869.09 2869.09 2821.61 2830.71]\n",
      " [2930.91 2930.91 2892.47 2912.43]\n",
      " [2918.46 2954.86 2912.16 2939.51]\n",
      " [2909.96 2921.15 2860.71 2863.39]\n",
      " [2854.65 2887.72 2852.89 2878.48]]\n",
      "fake_output:\n",
      " [[2827.05890325 2822.128534   2781.47133364 2772.08162577]]\n",
      "real_output:\n",
      " [[2812.64 2842.71 2791.76 2836.74]]\n",
      "213 [D loss: 0.716020, acc.: 52.67%] [G loss: 1.385693]\n",
      "input:\n",
      " [[3635.5  3635.5  3617.76 3629.65]\n",
      " [3594.52 3642.31 3594.52 3635.41]\n",
      " [3566.82 3589.81 3552.77 3577.59]\n",
      " [3579.31 3581.23 3556.85 3557.54]\n",
      " [3559.41 3585.22 3543.84 3581.87]]\n",
      "fake_output:\n",
      " [[3630.36318016 3656.91652601 3644.87264089 3668.95894072]]\n",
      "real_output:\n",
      " [[3612.09 3619.09 3567.33 3567.79]]\n",
      "214 [D loss: 0.725077, acc.: 49.33%] [G loss: 1.353038]\n",
      "input:\n",
      " [[4775.21 4786.83 4765.75 4766.18]\n",
      " [4794.23 4808.93 4775.33 4778.73]\n",
      " [4788.64 4804.06 4778.08 4793.06]\n",
      " [4795.49 4807.02 4780.04 4786.35]\n",
      " [4733.99 4791.49 4733.99 4791.19]]\n",
      "fake_output:\n",
      " [[4719.39742412 4772.70589801 4717.27949995 4752.28119756]]\n",
      "real_output:\n",
      " [[4703.96 4740.74 4703.96 4725.79]]\n",
      "215 [D loss: 0.704331, acc.: 51.00%] [G loss: 1.332888]\n",
      "input:\n",
      " [[4707.25 4708.53 4670.87 4685.25]\n",
      " [4701.48 4714.92 4694.39 4701.7 ]\n",
      " [4699.26 4718.5  4681.32 4697.53]\n",
      " [4662.93 4683.   4662.59 4680.06]\n",
      " [4630.65 4663.46 4621.19 4660.57]]\n",
      "fake_output:\n",
      " [[4641.74810393 4665.11651817 4630.34437527 4661.86008465]]\n",
      "real_output:\n",
      " [[4613.34 4635.15 4613.34 4630.65]]\n",
      "216 [D loss: 0.709849, acc.: 51.17%] [G loss: 1.492463]\n",
      "input:\n",
      " [[4631.97 4694.04 4631.97 4686.75]\n",
      " [4548.37 4612.6  4540.51 4591.67]\n",
      " [4589.49 4608.03 4495.12 4538.43]\n",
      " [4504.73 4595.46 4504.73 4577.1 ]\n",
      " [4602.82 4652.94 4510.27 4513.04]]\n",
      "fake_output:\n",
      " [[4536.86157018 4592.02240966 4491.96790396 4515.43250708]]\n",
      "real_output:\n",
      " [[4640.25 4646.02 4560.   4567.  ]]\n",
      "217 [D loss: 0.706874, acc.: 52.67%] [G loss: 1.943627]\n",
      "input:\n",
      " [[3863.99 3874.47 3818.86 3819.72]\n",
      " [3903.64 3906.41 3868.57 3870.29]\n",
      " [3842.51 3914.5  3842.51 3901.82]\n",
      " [3839.66 3861.08 3789.54 3811.15]\n",
      " [3915.8  3925.02 3814.04 3829.34]]\n",
      "fake_output:\n",
      " [[3869.47616124 3890.46328812 3826.93350217 3840.02965528]]\n",
      "real_output:\n",
      " [[3873.71 3928.65 3859.6  3925.43]]\n",
      "218 [D loss: 0.681534, acc.: 55.17%] [G loss: 2.067454]\n",
      "input:\n",
      " [[3141.11 3200.95 3127.66 3197.52]\n",
      " [3205.08 3235.32 3149.43 3155.22]\n",
      " [3152.47 3186.82 3136.22 3185.04]\n",
      " [3176.17 3179.78 3115.7  3152.05]\n",
      " [3153.07 3171.8  3136.53 3169.94]]\n",
      "fake_output:\n",
      " [[3134.3684814  3158.87786141 3116.0022669  3143.99295984]]\n",
      "real_output:\n",
      " [[3166.44 3184.15 3142.93 3145.32]]\n",
      "219 [D loss: 0.723668, acc.: 50.50%] [G loss: 1.550380]\n",
      "input:\n",
      " [[3406.46 3486.25 3405.17 3443.44]\n",
      " [3336.25 3389.49 3336.25 3369.16]\n",
      " [3296.2  3330.14 3279.74 3310.24]\n",
      " [3293.59 3304.93 3233.94 3269.96]\n",
      " [3277.17 3341.05 3259.82 3310.11]]\n",
      "fake_output:\n",
      " [[3381.03090355 3469.00903183 3425.79112148 3456.7607828 ]]\n",
      "real_output:\n",
      " [[3342.48 3342.48 3268.89 3271.03]]\n",
      "220 [D loss: 0.724574, acc.: 49.33%] [G loss: 1.176029]\n",
      "input:\n",
      " [[3356.04 3363.29 3335.44 3360.47]\n",
      " [3340.05 3352.54 3328.72 3351.28]\n",
      " [3323.17 3351.03 3318.14 3349.16]\n",
      " [3317.37 3330.77 3317.37 3327.77]\n",
      " [3289.92 3306.84 3286.37 3306.51]]\n",
      "fake_output:\n",
      " [[3367.25648857 3386.24072107 3368.46180048 3396.40917477]]\n",
      "real_output:\n",
      " [[3288.26 3302.73 3284.53 3294.61]]\n",
      "221 [D loss: 0.685425, acc.: 55.17%] [G loss: 1.663354]\n",
      "input:\n",
      " [[3407.73 3419.48 3389.25 3401.2 ]\n",
      " [3363.56 3402.93 3363.56 3383.54]\n",
      " [3352.7  3368.95 3310.47 3340.97]\n",
      " [3412.56 3425.55 3329.25 3339.19]\n",
      " [3369.82 3424.77 3366.84 3398.96]]\n",
      "fake_output:\n",
      " [[3355.82833928 3377.32434957 3316.45218782 3333.02636962]]\n",
      "real_output:\n",
      " [[3371.88 3379.97 3329.27 3331.84]]\n",
      "222 [D loss: 0.730884, acc.: 46.33%] [G loss: 1.267940]\n",
      "input:\n",
      " [[4630.65 4663.46 4621.19 4660.57]\n",
      " [4613.34 4635.15 4613.34 4630.65]\n",
      " [4610.62 4620.34 4595.06 4613.67]\n",
      " [4572.87 4608.08 4567.59 4605.38]\n",
      " [4562.84 4597.55 4562.84 4596.42]]\n",
      "fake_output:\n",
      " [[4647.53412535 4679.94524391 4666.05554236 4690.48038588]]\n",
      "real_output:\n",
      " [[4580.22 4584.57 4551.66 4551.68]]\n",
      "223 [D loss: 0.700384, acc.: 54.17%] [G loss: 1.395517]\n",
      "input:\n",
      " [[3493.5  3515.76 3480.45 3483.81]\n",
      " [3453.72 3489.08 3440.89 3483.34]\n",
      " [3515.47 3527.94 3480.55 3488.67]\n",
      " [3534.01 3534.01 3500.86 3511.93]\n",
      " [3500.02 3549.85 3499.61 3534.22]]\n",
      "fake_output:\n",
      " [[3535.11693271 3557.25271632 3527.01051485 3541.58947369]]\n",
      "real_output:\n",
      " [[3459.67 3482.34 3458.07 3477.13]]\n",
      "224 [D loss: 0.689353, acc.: 55.17%] [G loss: 1.628034]\n",
      "input:\n",
      " [[3670.94 3699.2  3670.94 3699.12]\n",
      " [3668.28 3682.73 3657.17 3666.72]\n",
      " [3653.78 3670.96 3644.84 3669.01]\n",
      " [3645.87 3678.45 3645.87 3662.45]\n",
      " [3634.18 3634.18 3594.39 3621.63]]\n",
      "fake_output:\n",
      " [[3663.46162449 3687.99306056 3665.52458389 3683.61760975]]\n",
      "real_output:\n",
      " [[3638.55 3644.31 3629.33 3638.35]]\n",
      "225 [D loss: 0.716259, acc.: 51.50%] [G loss: 1.366487]\n",
      "input:\n",
      " [[4659.39 4664.55 4648.31 4649.27]\n",
      " [4670.26 4684.85 4630.86 4646.71]\n",
      " [4707.25 4708.53 4670.87 4685.25]\n",
      " [4701.48 4714.92 4694.39 4701.7 ]\n",
      " [4699.26 4718.5  4681.32 4697.53]]\n",
      "fake_output:\n",
      " [[4633.42540691 4622.10131709 4587.24354162 4589.42488   ]]\n",
      "real_output:\n",
      " [[4662.93 4683.   4662.59 4680.06]]\n",
      "226 [D loss: 0.734648, acc.: 49.00%] [G loss: 1.166698]\n",
      "input:\n",
      " [[2501.29 2637.01 2500.72 2630.07]\n",
      " [2457.77 2571.42 2407.53 2475.56]\n",
      " [2344.44 2449.71 2344.44 2447.33]\n",
      " [2290.71 2300.73 2191.86 2237.4 ]\n",
      " [2431.94 2453.01 2295.56 2304.92]]\n",
      "fake_output:\n",
      " [[2163.11670786 2007.66947752 1961.29334306 1866.93677179]]\n",
      "real_output:\n",
      " [[2393.48 2466.97 2319.78 2409.39]]\n",
      "227 [D loss: 0.719889, acc.: 49.67%] [G loss: 1.390655]\n",
      "input:\n",
      " [[3818.53 3843.67 3723.34 3768.47]\n",
      " [3863.99 3874.47 3818.86 3819.72]\n",
      " [3903.64 3906.41 3868.57 3870.29]\n",
      " [3842.51 3914.5  3842.51 3901.82]\n",
      " [3839.66 3861.08 3789.54 3811.15]]\n",
      "fake_output:\n",
      " [[3859.2124524  3884.93493997 3826.88374847 3844.46863077]]\n",
      "real_output:\n",
      " [[3915.8  3925.02 3814.04 3829.34]]\n",
      "228 [D loss: 0.728973, acc.: 50.00%] [G loss: 1.560978]\n",
      "input:\n",
      " [[3670.94 3699.2  3670.94 3699.12]\n",
      " [3668.28 3682.73 3657.17 3666.72]\n",
      " [3653.78 3670.96 3644.84 3669.01]\n",
      " [3645.87 3678.45 3645.87 3662.45]\n",
      " [3634.18 3634.18 3594.39 3621.63]]\n",
      "fake_output:\n",
      " [[3616.05199962 3596.56410592 3559.02469297 3578.07927032]]\n",
      "real_output:\n",
      " [[3638.55 3644.31 3629.33 3638.35]]\n",
      "229 [D loss: 0.698953, acc.: 53.67%] [G loss: 1.356224]\n",
      "input:\n",
      " [[3352.7  3368.95 3310.47 3340.97]\n",
      " [3412.56 3425.55 3329.25 3339.19]\n",
      " [3369.82 3424.77 3366.84 3398.96]\n",
      " [3371.88 3379.97 3329.27 3331.84]\n",
      " [3453.6  3479.15 3349.63 3426.96]]\n",
      "fake_output:\n",
      " [[3383.51319565 3398.46850859 3336.64685941 3356.67593757]]\n",
      "real_output:\n",
      " [[3564.74 3564.85 3427.41 3455.06]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 [D loss: 0.711430, acc.: 50.00%] [G loss: 2.012141]\n",
      "input:\n",
      " [[3064.78 3081.07 3051.64 3080.82]\n",
      " [3038.78 3062.18 3031.54 3055.73]\n",
      " [3025.17 3049.17 2998.61 3044.31]\n",
      " [3046.61 3068.67 3023.4  3029.73]\n",
      " [3015.65 3036.25 2969.75 3036.13]]\n",
      "fake_output:\n",
      " [[3043.31474382 3063.84015571 3027.03204709 3055.28700776]]\n",
      "real_output:\n",
      " [[3004.08 3021.72 2988.17 2991.77]]\n",
      "231 [D loss: 0.689670, acc.: 51.00%] [G loss: 1.872452]\n",
      "input:\n",
      " [[4664.63 4664.63 4585.43 4594.62]\n",
      " [4675.78 4702.87 4659.89 4701.46]\n",
      " [4678.48 4699.39 4652.66 4690.7 ]\n",
      " [4712.   4743.83 4682.17 4682.94]\n",
      " [4708.44 4717.75 4694.22 4697.96]]\n",
      "fake_output:\n",
      " [[4635.50293667 4613.32599955 4532.45373155 4531.54439376]]\n",
      "real_output:\n",
      " [[4700.72 4708.8  4672.78 4704.54]]\n",
      "232 [D loss: 0.766314, acc.: 43.50%] [G loss: 1.161325]\n",
      "input:\n",
      " [[2784.81 2785.54 2727.1  2736.56]\n",
      " [2845.62 2868.98 2820.43 2823.16]\n",
      " [2842.43 2879.22 2830.88 2874.56]\n",
      " [2799.34 2806.51 2764.32 2799.55]\n",
      " [2795.64 2801.88 2761.54 2783.36]]\n",
      "fake_output:\n",
      " [[2753.52576855 2704.69027387 2667.08999082 2656.78658332]]\n",
      "real_output:\n",
      " [[2805.1  2851.85 2805.1  2846.06]]\n",
      "233 [D loss: 0.719245, acc.: 49.17%] [G loss: 1.330879]\n",
      "input:\n",
      " [[3921.16 3930.41 3903.07 3906.71]\n",
      " [3915.86 3921.98 3885.03 3913.97]\n",
      " [3918.5  3933.61 3900.43 3931.33]\n",
      " [3939.61 3950.43 3923.85 3932.59]\n",
      " [3911.65 3937.23 3905.78 3934.83]]\n",
      "fake_output:\n",
      " [[3888.72845956 3893.31171883 3853.45074827 3873.41649451]]\n",
      "real_output:\n",
      " [[3916.4  3925.99 3890.39 3916.38]]\n",
      "234 [D loss: 0.730440, acc.: 50.50%] [G loss: 1.842641]\n",
      "input:\n",
      " [[3123.53 3123.53 2999.49 3002.1 ]\n",
      " [3213.42 3223.27 3181.49 3190.14]\n",
      " [3213.32 3222.71 3193.11 3207.18]\n",
      " [3199.92 3233.13 3196.   3232.39]\n",
      " [3163.84 3211.72 3163.84 3193.93]]\n",
      "fake_output:\n",
      " [[3194.88482363 3217.55309097 3188.03413631 3203.44323094]]\n",
      "real_output:\n",
      " [[3111.56 3128.91 3090.41 3112.35]]\n",
      "235 [D loss: 0.682856, acc.: 55.00%] [G loss: 2.063344]\n",
      "input:\n",
      " [[4098.45 4116.93 4061.41 4115.68]\n",
      " [4165.94 4169.15 4125.99 4127.83]\n",
      " [4169.92 4171.92 4142.69 4163.29]\n",
      " [4129.58 4183.13 4129.58 4173.85]\n",
      " [4074.99 4131.58 4074.99 4112.5 ]]\n",
      "fake_output:\n",
      " [[4127.73252009 4151.08624006 4107.9909672  4134.8273964 ]]\n",
      "real_output:\n",
      " [[4130.55 4134.73 4056.88 4063.04]]\n",
      "236 [D loss: 0.702617, acc.: 51.50%] [G loss: 1.781339]\n",
      "input:\n",
      " [[3015.65 3036.25 2969.75 3036.13]\n",
      " [3004.08 3021.72 2988.17 2991.77]\n",
      " [2948.05 2956.76 2933.59 2955.45]\n",
      " [2969.95 2978.5  2938.57 2948.51]\n",
      " [2953.63 2980.29 2953.63 2971.61]]\n",
      "fake_output:\n",
      " [[2973.56071243 2985.6792954  2954.86437041 2973.17444027]]\n",
      "real_output:\n",
      " [[2948.59 2964.21 2922.35 2922.94]]\n",
      "237 [D loss: 0.671660, acc.: 57.00%] [G loss: 1.484552]\n",
      "input:\n",
      " [[3937.6  3949.13 3901.57 3910.52]\n",
      " [3916.48 3955.31 3914.16 3940.59]\n",
      " [3913.14 3930.12 3886.75 3913.1 ]\n",
      " [3953.5  3969.62 3910.86 3915.46]\n",
      " [3949.57 3983.87 3935.74 3974.12]]\n",
      "fake_output:\n",
      " [[3948.37726162 3976.32145668 3930.88068008 3959.61765169]]\n",
      "real_output:\n",
      " [[3973.59 3981.04 3953.44 3962.71]]\n",
      "238 [D loss: 0.716537, acc.: 54.67%] [G loss: 1.970060]\n",
      "input:\n",
      " [[2915.46 2944.25 2903.44 2930.32]\n",
      " [2908.83 2932.16 2902.88 2929.8 ]\n",
      " [2878.26 2901.92 2876.48 2881.19]\n",
      " [2883.14 2891.11 2847.65 2848.42]\n",
      " [2868.88 2898.23 2863.55 2868.44]]\n",
      "fake_output:\n",
      " [[2908.37877973 2937.39357451 2914.65208156 2940.80990941]]\n",
      "real_output:\n",
      " [[2815.01 2844.24 2797.85 2842.74]]\n",
      "239 [D loss: 0.689203, acc.: 53.33%] [G loss: 1.953989]\n",
      "input:\n",
      " [[3920.78 3931.5  3884.94 3909.88]\n",
      " [3910.49 3918.35 3902.64 3911.23]\n",
      " [3892.59 3915.77 3892.59 3915.59]\n",
      " [3878.3  3894.56 3874.93 3886.83]\n",
      " [3836.66 3872.42 3836.66 3871.74]]\n",
      "fake_output:\n",
      " [[3854.63797365 3874.58590552 3846.45796943 3873.03195723]]\n",
      "real_output:\n",
      " [[3840.27 3847.51 3816.68 3830.17]]\n",
      "240 [D loss: 0.690007, acc.: 55.50%] [G loss: 1.860001]\n",
      "input:\n",
      " [[3288.26 3302.73 3284.53 3294.61]\n",
      " [3270.45 3272.17 3220.26 3271.12]\n",
      " [3231.76 3250.92 3204.13 3246.22]\n",
      " [3227.22 3264.74 3227.22 3258.44]\n",
      " [3234.27 3243.72 3216.17 3218.44]]\n",
      "fake_output:\n",
      " [[3174.10054904 3180.30222694 3118.58561372 3147.39659916]]\n",
      "real_output:\n",
      " [[3219.84 3241.43 3214.25 3239.41]]\n",
      "241 [D loss: 0.690382, acc.: 56.67%] [G loss: 1.493140]\n",
      "input:\n",
      " [[3653.78 3670.96 3644.84 3669.01]\n",
      " [3645.87 3678.45 3645.87 3662.45]\n",
      " [3634.18 3634.18 3594.39 3621.63]\n",
      " [3638.55 3644.31 3629.33 3638.35]\n",
      " [3635.5  3635.5  3617.76 3629.65]]\n",
      "fake_output:\n",
      " [[3653.41068107 3688.94160355 3677.28296178 3691.22219446]]\n",
      "real_output:\n",
      " [[3594.52 3642.31 3594.52 3635.41]]\n",
      "242 [D loss: 0.775126, acc.: 45.33%] [G loss: 1.694036]\n",
      "input:\n",
      " [[3073.2  3073.73 3004.63 3009.05]\n",
      " [3046.6  3086.25 3024.01 3083.76]\n",
      " [3114.4  3115.01 3032.13 3050.33]\n",
      " [3138.7  3154.9  3127.12 3131.29]\n",
      " [3094.42 3120.92 3079.39 3117.86]]\n",
      "fake_output:\n",
      " [[3124.034269   3138.13731514 3120.46133442 3134.9074119 ]]\n",
      "real_output:\n",
      " [[3140.29 3155.53 3083.11 3097.74]]\n",
      "243 [D loss: 0.710960, acc.: 53.83%] [G loss: 2.158297]\n",
      "input:\n",
      " [[4139.76 4173.49 4139.76 4170.42]\n",
      " [4141.58 4151.69 4120.87 4124.66]\n",
      " [4130.1  4148.   4124.43 4141.59]\n",
      " [4124.71 4131.76 4114.82 4127.99]\n",
      " [4096.11 4129.48 4095.51 4128.8 ]]\n",
      "fake_output:\n",
      " [[4139.13846995 4160.81462999 4135.52615292 4155.95278274]]\n",
      "real_output:\n",
      " [[4089.95 4098.19 4082.54 4097.17]]\n",
      "244 [D loss: 0.703032, acc.: 53.83%] [G loss: 1.280625]\n",
      "input:\n",
      " [[3791.84 3843.09 3791.84 3826.31]\n",
      " [3731.17 3784.32 3725.62 3773.86]\n",
      " [3778.05 3778.05 3694.12 3714.24]\n",
      " [3755.75 3830.5  3755.75 3787.38]\n",
      " [3836.83 3836.83 3732.48 3750.77]]\n",
      "fake_output:\n",
      " [[3705.61240298 3745.71625724 3659.92151025 3672.85287163]]\n",
      "real_output:\n",
      " [[3862.96 3870.9  3847.78 3849.62]]\n",
      "245 [D loss: 0.719488, acc.: 48.67%] [G loss: 1.941782]\n",
      "input:\n",
      " [[4415.95 4416.17 4400.23 4402.66]\n",
      " [4392.74 4423.79 4373.   4423.15]\n",
      " [4406.86 4422.18 4384.81 4387.16]\n",
      " [4395.12 4412.25 4389.65 4395.26]\n",
      " [4403.59 4429.97 4403.59 4419.15]]\n",
      "fake_output:\n",
      " [[4375.79232637 4396.723717   4348.17144609 4348.9447108 ]]\n",
      "real_output:\n",
      " [[4402.95 4415.47 4387.01 4400.64]]\n",
      "246 [D loss: 0.695925, acc.: 54.00%] [G loss: 1.849316]\n",
      "input:\n",
      " [[3508.34 3521.58 3484.34 3509.44]\n",
      " [3485.74 3529.05 3485.74 3510.45]\n",
      " [3406.46 3486.25 3405.17 3443.44]\n",
      " [3336.25 3389.49 3336.25 3369.16]\n",
      " [3296.2  3330.14 3279.74 3310.24]]\n",
      "fake_output:\n",
      " [[3332.37020065 3363.54356982 3315.28361247 3340.65598678]]\n",
      "real_output:\n",
      " [[3293.59 3304.93 3233.94 3269.96]]\n",
      "247 [D loss: 0.750240, acc.: 45.00%] [G loss: 1.390698]\n",
      "input:\n",
      " [[3879.34 3919.54 3853.5  3909.52]\n",
      " [3919.93 3942.08 3889.07 3889.14]\n",
      " [3937.6  3949.13 3901.57 3910.52]\n",
      " [3916.48 3955.31 3914.16 3940.59]\n",
      " [3913.14 3930.12 3886.75 3913.1 ]]\n",
      "fake_output:\n",
      " [[3880.37802959 3912.34819469 3847.65050547 3876.94269648]]\n",
      "real_output:\n",
      " [[3953.5  3969.62 3910.86 3915.46]]\n",
      "248 [D loss: 0.709032, acc.: 51.00%] [G loss: 1.267803]\n",
      "input:\n",
      " [[4442.12 4457.3  4436.19 4443.11]\n",
      " [4438.04 4463.12 4430.27 4455.48]\n",
      " [4406.75 4465.4  4406.75 4448.98]\n",
      " [4367.43 4416.75 4367.43 4395.64]\n",
      " [4374.45 4394.87 4347.96 4354.19]]\n",
      "fake_output:\n",
      " [[4296.4693487  4312.06721625 4251.25751735 4240.71685659]]\n",
      "real_output:\n",
      " [[4402.95 4402.95 4305.91 4357.73]]\n",
      "249 [D loss: 0.724928, acc.: 55.50%] [G loss: 1.614407]\n",
      "input:\n",
      " [[4206.05 4233.45 4206.05 4229.89]\n",
      " [4191.43 4204.39 4167.93 4192.85]\n",
      " [4206.82 4217.37 4198.27 4208.12]\n",
      " [4216.52 4234.12 4197.59 4202.04]\n",
      " [4210.77 4218.36 4203.57 4204.11]]\n",
      "fake_output:\n",
      " [[4195.41085065 4203.97773814 4174.1594926  4187.24786135]]\n",
      "real_output:\n",
      " [[4201.94 4213.38 4197.78 4200.88]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-f2210bf9ef26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlstmgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstmgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-283bca7259c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# First training (wants generator to imitate real data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mg_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# Second training (wants discriminator to mistake songs as real)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2087\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2089\u001b[0;31m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[0m\u001b[1;32m   2090\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m                                                     class_weight)\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_distribute_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3313\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3315\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3316\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstmgan = LSTMGAN(5, 4, load_data())\n",
    "lstmgan.train(epochs=1000, batch_size=50, save_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installinging Mido Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Stock Prices\n",
    "Generating random input and letting model predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [4557.37015061 4617.81516452 4568.37038931 4537.43873694], real price: [4632.24 4632.24 4568.7  4577.11]\n",
      "prediction: [4596.97931896 4638.79509799 4606.06806737 4572.56554807], real price: [4637.99 4665.13 4614.75 4662.85]\n",
      "prediction: [4621.79198755 4658.52104893 4615.09393932 4642.8673289 ], real price: [4733.56 4744.13 4650.29 4659.03]\n",
      "prediction: [4695.68244747 4723.85752235 4677.21356967 4707.8861573 ], real price: [4728.59 4748.83 4706.71 4726.35]\n",
      "prediction: [4718.98111881 4751.28397429 4711.80714387 4739.1878278 ], real price: [4669.14 4714.13 4638.27 4713.07]\n",
      "prediction: [4663.17473006 4674.53387114 4621.33548362 4641.90762877], real price: [4655.34 4673.02 4582.24 4670.29]\n",
      "prediction: [4626.42163842 4642.95264132 4565.68151518 4633.14300594], real price: [4697.66 4707.95 4662.74 4677.03]\n",
      "prediction: [4664.98249931 4686.07910281 4601.64865237 4658.050087  ], real price: [4693.39 4725.01 4671.26 4696.05]\n",
      "prediction: [4702.5127319  4727.52980907 4681.94672102 4709.61198399], real price: [4787.99 4797.7  4699.44 4700.58]\n",
      "prediction: [4770.28551091 4802.15794103 4748.77543177 4728.97633459], real price: [4804.51 4818.62 4774.27 4793.54]\n",
      "prediction: [4786.62093853 4816.92205485 4781.21529336 4781.1302777 ], real price: [4778.14 4796.64 4758.17 4796.56]\n",
      "prediction: [4774.05070857 4796.27542541 4752.75352081 4773.60766464], real price: [4775.21 4786.83 4765.75 4766.18]\n",
      "prediction: [4761.55105411 4776.95706949 4732.58135555 4743.60201619], real price: [4794.23 4808.93 4775.33 4778.73]\n",
      "prediction: [4777.76639637 4788.33042184 4723.47139056 4724.77720487], real price: [4788.64 4804.06 4778.08 4793.06]\n",
      "prediction: [4785.57442083 4799.8532172  4768.78469033 4782.29995068], real price: [4795.49 4807.02 4780.04 4786.35]\n",
      "prediction: [4796.3100298  4813.13723748 4787.68296569 4805.10604347], real price: [4733.99 4791.49 4733.99 4791.19]\n",
      "prediction: [4701.5541495  4761.29651286 4697.79443398 4740.30147241], real price: [4703.96 4740.74 4703.96 4725.79]\n",
      "prediction: [4687.87715711 4730.86977171 4683.33535011 4713.69121055], real price: [4650.36 4697.67 4645.53 4696.56]\n",
      "prediction: [4637.2762682  4682.49892455 4624.51942188 4672.81087136], real price: [4594.96 4651.14 4583.16 4649.23]\n",
      "prediction: [4577.99582463 4627.99483693 4554.55401485 4619.68541223], real price: [4587.9  4587.9  4531.1  4568.02]\n",
      "prediction: [4570.62202621 4583.35113007 4516.44289014 4558.71531745], real price: [4652.5  4666.7  4600.22 4620.64]\n",
      "prediction: [4648.06388074 4679.21263816 4629.63212883 4664.20304135], real price: [4719.13 4731.99 4651.89 4668.67]\n",
      "prediction: [4710.11683472 4754.83265917 4706.41841394 4737.99731395], real price: [4636.46 4712.6  4611.22 4709.85]\n",
      "prediction: [4647.74026864 4683.29240747 4614.91647764 4661.23124049], real price: [4642.99 4660.47 4606.52 4634.09]\n",
      "prediction: [4622.69403994 4630.2997301  4576.10266829 4602.90387843], real price: [4710.3  4710.3  4667.6  4668.97]\n",
      "prediction: [4682.0270143  4704.96786923 4639.15973812 4672.27206338], real price: [4687.64 4713.57 4670.24 4712.02]\n",
      "prediction: [4671.48944579 4698.82132278 4636.69553938 4671.26635373], real price: [4691.   4695.26 4665.98 4667.45]\n",
      "prediction: [4701.28064476 4722.4017073  4688.42152932 4721.98501823], real price: [4690.86 4705.06 4674.52 4701.21]\n",
      "prediction: [4680.81460064 4691.982169   4655.64753367 4671.95184006], real price: [4631.97 4694.04 4631.97 4686.75]\n",
      "prediction: [4595.26142034 4670.89438673 4601.19291681 4612.70986218], real price: [4548.37 4612.6  4540.51 4591.67]\n",
      "prediction: [4533.9551542  4595.05630926 4513.7540664  4562.3695389 ], real price: [4589.49 4608.03 4495.12 4538.43]\n",
      "prediction: [4575.28133624 4616.74954064 4522.16231518 4565.70685246], real price: [4504.73 4595.46 4504.73 4577.1 ]\n",
      "prediction: [4486.68873868 4558.20905813 4434.6392663  4493.90306279], real price: [4602.82 4652.94 4510.27 4513.04]\n",
      "prediction: [4607.08545711 4658.84878608 4583.37825883 4628.02076328], real price: [4640.25 4646.02 4560.   4567.  ]\n",
      "prediction: [4646.69318932 4664.91793512 4581.10044968 4622.52160444], real price: [4628.75 4672.95 4625.26 4655.27]\n",
      "prediction: [4625.14435293 4659.80376967 4593.1765623  4621.71616301], real price: [4664.63 4664.63 4585.43 4594.62]\n",
      "prediction: [4662.00996861 4680.19761035 4629.44692688 4652.9930593 ], real price: [4675.78 4702.87 4659.89 4701.46]\n",
      "prediction: [4668.89155603 4694.08247769 4674.52240469 4715.69896114], real price: [4678.48 4699.39 4652.66 4690.7 ]\n",
      "prediction: [4676.98568744 4704.461822   4678.63911913 4725.86768131], real price: [4712.   4743.83 4682.17 4682.94]\n",
      "prediction: [4706.33196629 4742.88201869 4711.35173833 4744.72580838], real price: [4708.44 4717.75 4694.22 4697.96]\n",
      "prediction: [4709.04528565 4743.27206265 4724.25567695 4746.35633965], real price: [4700.72 4708.8  4672.78 4704.54]\n",
      "prediction: [4699.67334952 4720.463164   4681.36452811 4699.45482095], real price: [4701.5  4701.5  4684.41 4688.67]\n",
      "prediction: [4696.16670277 4706.17506623 4672.57772309 4689.57006095], real price: [4679.42 4714.95 4679.42 4700.9 ]\n",
      "prediction: [4660.89791927 4652.87245659 4652.93341401 4658.46658618], real price: [4689.3  4697.42 4672.86 4682.8 ]\n",
      "prediction: [4680.71953507 4694.98190279 4666.94316356 4680.60893614], real price: [4655.24 4688.47 4650.77 4682.85]\n",
      "prediction: [4647.54185498 4678.31389308 4642.18917781 4667.05592015], real price: [4659.39 4664.55 4648.31 4649.27]\n",
      "prediction: [4654.53066307 4669.7936438  4645.54440696 4655.04901557], real price: [4670.26 4684.85 4630.86 4646.71]\n",
      "prediction: [4672.56062149 4691.47872022 4659.21578292 4674.36891195], real price: [4707.25 4708.53 4670.87 4685.25]\n",
      "prediction: [4701.13684896 4711.43389725 4685.81079779 4701.89438362], real price: [4701.48 4714.92 4694.39 4701.7 ]\n",
      "prediction: [4704.02391524 4719.10899947 4700.46395412 4713.43391136], real price: [4699.26 4718.5  4681.32 4697.53]\n",
      "prediction: [4698.19891307 4713.56426104 4688.19569387 4698.3510656 ], real price: [4662.93 4683.   4662.59 4680.06]\n",
      "prediction: [4649.08171256 4659.49659498 4613.00227395 4627.57013204], real price: [4630.65 4663.46 4621.19 4660.57]\n",
      "prediction: [4620.49550991 4647.6897265  4607.29903185 4648.9630124 ], real price: [4613.34 4635.15 4613.34 4630.65]\n",
      "prediction: [4605.40197593 4628.3628479  4596.48936057 4625.07108675], real price: [4610.62 4620.34 4595.06 4613.67]\n",
      "prediction: [4605.0824499  4621.34561641 4593.01761156 4615.35339663], real price: [4572.87 4608.08 4567.59 4605.38]\n",
      "prediction: [4566.1867164  4587.63954613 4548.07959653 4578.10601212], real price: [4562.84 4597.55 4562.84 4596.42]\n",
      "prediction: [4548.29579118 4575.11289471 4539.61302262 4568.72399321], real price: [4580.22 4584.57 4551.66 4551.68]\n",
      "prediction: [4579.27832784 4600.59867662 4566.66137764 4584.8504247 ], real price: [4578.69 4598.53 4569.17 4574.79]\n",
      "prediction: [4583.87935244 4603.3758415  4572.20559713 4591.63995291], real price: [4553.69 4572.62 4537.36 4566.48]\n",
      "prediction: [4555.6403023  4571.4730252  4538.06537137 4544.76728233], real price: [4546.12 4559.67 4524.   4544.9 ]\n",
      "prediction: [4538.61156835 4549.15279859 4511.9865285  4524.22841507], real price: [4532.24 4551.44 4526.89 4549.78]\n",
      "prediction: [4515.30886789 4528.38533471 4497.18390702 4526.12384426], real price: [4524.42 4540.87 4524.4  4536.19]\n",
      "prediction: [4517.11793986 4530.05022895 4505.3666824  4527.78253196], real price: [4497.34 4520.4  4496.41 4519.63]\n",
      "prediction: [4491.02607766 4508.0741558  4489.78707975 4505.39590115], real price: [4463.72 4488.75 4447.47 4486.46]\n",
      "prediction: [4457.98931065 4478.25699164 4438.23430749 4475.68684061], real price: [4447.69 4475.82 4447.69 4471.37]\n",
      "prediction: [4437.55061754 4461.4686379  4421.02786606 4453.56021779], real price: [4386.75 4439.73 4386.75 4438.26]\n",
      "prediction: [4377.72387571 4420.70068838 4360.43192384 4413.54469313], real price: [4358.01 4372.87 4329.92 4363.8 ]\n",
      "prediction: [4344.67406346 4365.29446852 4310.39498252 4349.44242891], real price: [4368.31 4374.89 4342.09 4350.65]\n",
      "prediction: [4358.89574709 4373.82620561 4329.69394355 4352.56756971], real price: [4385.44 4415.88 4360.59 4361.19]\n",
      "prediction: [4389.33196836 4413.9345959  4372.95125281 4393.83868988], real price: [4406.51 4412.02 4386.22 4391.34]\n",
      "prediction: [4404.62015576 4448.01157572 4413.02498747 4448.41794572], real price: [4383.73 4429.97 4383.73 4399.76]\n",
      "prediction: [4386.07318757 4411.87123914 4376.80327794 4385.16170561], real price: [4319.57 4365.57 4290.49 4363.55]\n",
      "prediction: [4291.43624307 4311.11502577 4236.17372701 4305.79937178], real price: [4309.87 4369.23 4309.87 4345.72]\n",
      "prediction: [4282.08746002 4336.6910575  4253.90722656 4322.61499012], real price: [4348.84 4355.51 4278.94 4300.46]\n",
      "prediction: [4351.34210062 4382.88001974 4325.64548247 4354.97503486], real price: [4317.16 4375.19 4288.52 4357.04]\n",
      "prediction: [4318.27830784 4360.19749195 4282.54948429 4328.67793313], real price: [4370.67 4382.55 4306.24 4307.54]\n",
      "prediction: [4370.27040599 4388.00239728 4325.46691649 4399.80393869], real price: [4362.41 4385.57 4355.08 4359.46]\n",
      "prediction: [4369.79281365 4389.18555721 4356.57558677 4379.47840456], real price: [4419.54 4419.54 4346.33 4352.63]\n",
      "prediction: [4404.3116556  4416.1735045  4375.50708355 4385.89919632], real price: [4442.12 4457.3  4436.19 4443.11]\n",
      "prediction: [4432.60444444 4449.12533369 4441.80216882 4444.91820161], real price: [4438.04 4463.12 4430.27 4455.48]\n",
      "prediction: [4434.83403437 4459.2500184  4445.89601561 4462.0237997 ], real price: [4406.75 4465.4  4406.75 4448.98]\n",
      "prediction: [4404.09628743 4422.80581187 4386.11972804 4393.22005541], real price: [4367.43 4416.75 4367.43 4395.64]\n",
      "prediction: [4336.1498616  4363.90365485 4274.70728592 4271.23935442], real price: [4374.45 4394.87 4347.96 4354.19]\n",
      "prediction: [4365.80825631 4399.46543071 4347.02750667 4360.72087553], real price: [4402.95 4402.95 4305.91 4357.73]\n",
      "prediction: [4403.90480498 4434.52854248 4383.87892696 4411.19595496], real price: [4469.74 4471.52 4427.76 4432.99]\n",
      "prediction: [4456.38802279 4487.44511888 4470.90908986 4481.13726263], real price: [4477.09 4485.87 4443.8  4473.75]\n",
      "prediction: [4469.30740626 4486.48093592 4469.44929953 4482.86726523], real price: [4447.49 4486.87 4438.37 4480.7 ]\n",
      "prediction: [4447.08399276 4466.40804065 4431.71540561 4452.13616388], real price: [4479.33 4485.68 4435.46 4443.05]\n",
      "prediction: [4469.98857731 4488.3587991  4457.75790499 4474.5551145 ], real price: [4474.81 4492.99 4445.7  4468.73]\n",
      "prediction: [4474.91802427 4488.49107883 4442.93871313 4472.26065879], real price: [4506.92 4520.47 4457.66 4458.58]\n",
      "prediction: [4508.00500703 4522.05170891 4465.05676249 4498.86189561], real price: [4513.02 4529.9  4492.07 4493.28]\n",
      "prediction: [4515.61918681 4534.3329332  4498.5341224  4505.82525856], real price: [4518.09 4521.79 4493.95 4514.07]\n",
      "prediction: [4512.17741126 4527.78430462 4496.16533277 4507.70500536], real price: [4535.38 4535.38 4513.   4520.03]\n",
      "prediction: [4525.19316709 4535.08715769 4513.23765141 4522.2375576 ], real price: [4532.42 4541.45 4521.3  4535.43]\n",
      "prediction: [4531.41626688 4539.49201395 4529.36103937 4544.71913673], real price: [4534.48 4545.85 4524.66 4536.95]\n",
      "prediction: [4533.22718605 4542.81030331 4525.49793605 4538.74439101], real price: [4528.8  4537.11 4522.02 4524.09]\n",
      "prediction: [4529.41954863 4535.31649682 4516.17793794 4525.92074528], real price: [4529.75 4531.39 4515.8  4522.68]\n",
      "prediction: [4526.52467966 4524.8446235  4508.3265733  4508.84440996], real price: [4513.76 4537.36 4513.76 4528.79]\n",
      "prediction: [4508.74181509 4523.39364388 4506.90723987 4510.68696686], real price: [4474.1  4513.33 4474.1  4509.37]\n",
      "prediction: [4466.7680169  4504.5008392  4461.87744299 4499.61609654], real price: [4493.75 4495.9  4468.99 4470.  ]\n",
      "prediction: [4487.35544326 4505.89960326 4474.20005211 4486.67213862], real price: [4490.45 4501.71 4485.66 4496.19]\n",
      "prediction: [4486.89112108 4503.69227503 4476.18606836 4488.04978408], real price: [4484.4  4492.81 4482.28 4486.23]\n",
      "prediction: [4484.1730082  4498.3627813  4475.48015477 4485.11890793], real price: [4450.29 4489.88 4450.29 4479.53]\n",
      "prediction: [4439.90200755 4473.3776783  4435.49409633 4445.72710391], real price: [4410.56 4444.35 4406.8  4441.67]\n",
      "prediction: [4396.17819234 4431.7117087  4385.05275476 4424.71997992], real price: [4382.44 4418.61 4367.73 4405.8 ]\n",
      "prediction: [4372.91765064 4408.856871   4350.59639575 4394.16297452], real price: [4440.94 4454.32 4397.59 4400.27]\n",
      "prediction: [4441.54259507 4465.2390188  4431.75671203 4449.59763845], real price: [4462.12 4462.12 4417.83 4448.08]\n",
      "prediction: [4463.61183288 4486.39373478 4456.30580498 4483.04133591], real price: [4461.65 4480.26 4437.66 4479.71]\n",
      "prediction: [4461.91089218 4477.39032636 4442.27181301 4480.69737765], real price: [4464.84 4468.37 4460.82 4468.  ]\n",
      "prediction: [4458.25877227 4470.85800693 4446.48887401 4468.36600426], real price: [4446.08 4461.77 4435.96 4460.83]\n",
      "prediction: [4441.94097107 4449.55166669 4396.63152826 4401.74054103], real price: [4442.18 4449.44 4436.42 4447.7 ]\n",
      "prediction: [4431.65813078 4432.9971535  4396.88589442 4422.08572404], real price: [4435.79 4445.21 4430.03 4436.75]\n",
      "prediction: [4432.02153657 4438.12710161 4420.51796092 4429.65383224], real price: [4437.77 4439.39 4424.74 4432.35]\n",
      "prediction: [4436.46190106 4443.03327507 4425.58861667 4435.39275658], real price: [4429.07 4440.82 4429.07 4436.52]\n",
      "prediction: [4426.25235898 4428.45683186 4420.68293854 4416.9848408 ], real price: [4408.86 4429.76 4408.86 4429.1 ]\n",
      "prediction: [4402.60762268 4422.26524172 4399.67465767 4417.83921936], real price: [4415.95 4416.17 4400.23 4402.66]\n",
      "prediction: [4411.88593901 4420.54050781 4402.27379149 4409.47119662], real price: [4392.74 4423.79 4373.   4423.15]\n",
      "prediction: [4380.16814271 4404.52131907 4352.36716996 4390.62617486], real price: [4406.86 4422.18 4384.81 4387.16]\n",
      "prediction: [4404.21584747 4421.39388656 4386.91723037 4403.29811457], real price: [4395.12 4412.25 4389.65 4395.26]\n",
      "prediction: [4393.88590946 4412.73916479 4374.73988275 4384.88133401], real price: [4403.59 4429.97 4403.59 4419.15]\n",
      "prediction: [4394.92710722 4413.50182683 4378.12993289 4388.91912655], real price: [4402.95 4415.47 4387.01 4400.64]\n",
      "prediction: [4402.72192831 4424.07334195 4394.6661871  4414.2715372 ], real price: [4416.38 4416.38 4372.51 4401.46]\n",
      "prediction: [4410.34292639 4424.94629993 4399.06539451 4412.22631599], real price: [4409.58 4422.73 4405.45 4422.3 ]\n",
      "prediction: [4410.43748843 4424.62897704 4404.61902696 4418.99348997], real price: [4381.2  4415.18 4381.2  4411.79]\n",
      "prediction: [4369.47691744 4399.56300326 4346.82853191 4379.02787095], real price: [4361.27 4369.87 4350.06 4367.48]\n",
      "prediction: [4349.93662612 4357.99326005 4332.91661693 4351.36328153], real price: [4331.13 4359.7  4331.13 4358.69]\n",
      "prediction: [4318.67506117 4338.191471   4310.52048613 4333.79859601], real price: [4265.11 4336.84 4262.05 4323.06]\n",
      "prediction: [4253.88416886 4308.57824172 4235.78512488 4291.57055782], real price: [4296.4  4296.4  4233.13 4258.49]\n",
      "prediction: [4284.87299449 4313.28356537 4248.59708191 4283.8157985 ], real price: [4367.43 4375.09 4322.53 4327.16]\n",
      "prediction: [4364.71059277 4381.65475294 4366.97649955 4378.72193281], real price: [4369.02 4369.02 4340.7  4360.03]\n",
      "prediction: [4372.82833448 4388.53353712 4375.6943243  4390.21777531], real price: [4380.11 4393.68 4362.36 4374.3 ]\n",
      "prediction: [4376.4735349  4393.58621205 4375.57946827 4386.52658937], real price: [4381.07 4392.37 4366.92 4369.21]\n",
      "prediction: [4375.69396225 4390.74847202 4372.10572986 4376.66302069], real price: [4372.41 4386.68 4364.03 4384.63]\n",
      "prediction: [4372.00527635 4378.31327862 4346.82651907 4354.69981567], real price: [4329.38 4371.6  4329.38 4369.55]\n",
      "prediction: [4306.02626293 4340.21606814 4295.70485301 4338.56615134], real price: [4321.07 4330.88 4289.37 4320.82]\n",
      "prediction: [4309.18182888 4326.42673887 4279.62177232 4315.10828927], real price: [4351.01 4361.88 4329.79 4358.13]\n",
      "prediction: [4336.1525647  4353.52862759 4315.49419979 4344.13644834], real price: [4356.46 4356.46 4314.37 4343.54]\n",
      "prediction: [4360.73490012 4377.24878659 4351.58131021 4376.20169463], real price: [4326.6  4355.43 4326.6  4352.34]\n",
      "prediction: [4335.30908782 4352.81615338 4317.38174725 4346.62199355], real price: [4300.73 4320.66 4300.73 4319.94]\n",
      "prediction: [4291.04483805 4305.19725896 4276.80579087 4299.55097532], real price: [4290.65 4302.43 4287.96 4297.5 ]\n",
      "prediction: [4282.49060123 4296.87018507 4282.55874802 4290.67625664], real price: [4293.21 4300.52 4287.04 4291.8 ]\n",
      "prediction: [4288.51959392 4300.54567562 4285.93916612 4292.81378546], real price: [4284.9  4292.14 4274.67 4290.61]\n",
      "prediction: [4280.85720258 4283.43809614 4270.10883142 4275.71611215], real price: [4274.45 4286.12 4271.16 4280.7 ]\n",
      "prediction: [4270.82270941 4273.10652159 4259.25172142 4263.63283143], real price: [4256.97 4271.28 4256.97 4266.49]\n",
      "prediction: [4255.29642852 4266.63081325 4250.85355731 4260.79987816], real price: [4249.27 4256.6  4241.43 4241.84]\n",
      "prediction: [4245.43420011 4253.95490705 4237.69957587 4239.12845341], real price: [4224.61 4255.84 4217.27 4246.44]\n",
      "prediction: [4216.07885757 4238.70076788 4203.30683167 4219.35964223], real price: [4173.4  4226.24 4173.4  4224.79]\n",
      "prediction: [4161.37759251 4210.85139084 4147.24085848 4201.54615874], real price: [4204.78 4204.78 4164.4  4166.45]\n",
      "prediction: [4197.40491921 4222.0540885  4177.46309875 4196.73571241], real price: [4220.37 4232.29 4196.05 4221.86]\n",
      "prediction: [4216.14471749 4235.48636964 4200.6482935  4221.04014314], real price: [4248.87 4251.89 4202.45 4223.7 ]\n",
      "prediction: [4247.50205234 4264.50657073 4231.36597315 4269.33712572], real price: [4255.28 4257.16 4238.35 4246.59]\n",
      "prediction: [4256.22682077 4263.41154654 4245.48823258 4268.18662253], real price: [4248.31 4255.59 4234.07 4255.15]\n",
      "prediction: [4247.79122877 4256.98278241 4237.21138991 4255.60477123], real price: [4242.9  4248.38 4232.25 4247.44]\n",
      "prediction: [4237.12936069 4242.65629254 4212.38857142 4230.23644175], real price: [4228.56 4249.74 4220.34 4239.18]\n",
      "prediction: [4215.32060403 4238.48849133 4174.40403016 4197.33884112], real price: [4232.99 4237.09 4218.74 4219.55]\n",
      "prediction: [4229.64657574 4240.12232012 4217.92629713 4224.18834093], real price: [4233.81 4236.74 4208.41 4227.26]\n",
      "prediction: [4232.80090269 4240.3963655  4215.87820921 4227.67084606], real price: [4229.34 4232.34 4215.66 4226.52]\n",
      "prediction: [4228.70882719 4233.69103756 4210.81683147 4220.96622794], real price: [4206.05 4233.45 4206.05 4229.89]\n",
      "prediction: [4194.09216429 4213.49536231 4192.48737853 4202.90736796], real price: [4191.43 4204.39 4167.93 4192.85]\n",
      "prediction: [4181.9102915  4197.60466968 4157.26104575 4183.27251279], real price: [4206.82 4217.37 4198.27 4208.12]\n",
      "prediction: [4196.9508321  4210.89612001 4179.63074193 4199.46186089], real price: [4216.52 4234.12 4197.59 4202.04]\n",
      "prediction: [4220.00460101 4234.49604459 4214.58123258 4225.64752619], real price: [4210.77 4218.36 4203.57 4204.11]\n",
      "prediction: [4216.54905856 4238.32201416 4221.30410006 4230.07503161], real price: [4201.94 4213.38 4197.78 4200.88]\n",
      "prediction: [4202.6981864  4212.81994331 4189.63621752 4199.50518108], real price: [4191.59 4202.61 4184.11 4195.99]\n",
      "prediction: [4189.91976925 4195.04951625 4182.23368587 4193.16477139], real price: [4205.94 4213.42 4182.52 4188.13]\n",
      "prediction: [4206.18689406 4216.75514755 4193.94718559 4198.44425932], real price: [4170.16 4209.52 4170.16 4197.05]\n",
      "prediction: [4165.5291697  4198.17994921 4157.82051254 4182.95674109], real price: [4168.61 4188.72 4151.72 4155.86]\n",
      "prediction: [4164.67317243 4189.96453363 4150.88346109 4158.43110815], real price: [4121.97 4172.8  4121.97 4159.12]\n",
      "prediction: [4113.29881356 4162.11290435 4106.79922667 4134.1355754 ], real price: [4098.45 4116.93 4061.41 4115.68]\n",
      "prediction: [4085.52314213 4111.19620668 4049.69234259 4102.54442738], real price: [4165.94 4169.15 4125.99 4127.83]\n",
      "prediction: [4160.91656087 4187.84864176 4152.21149803 4167.29135447], real price: [4169.92 4171.92 4142.69 4163.29]\n",
      "prediction: [4166.2831493  4184.06652061 4153.59367068 4162.76024475], real price: [4129.58 4183.13 4129.58 4173.85]\n",
      "prediction: [4132.4107212  4156.67414402 4114.38861636 4143.75511476], real price: [4074.99 4131.58 4074.99 4112.5 ]\n",
      "prediction: [4058.68498918 4093.69587754 4035.99622121 4078.31102082], real price: [4130.55 4134.73 4056.88 4063.04]\n",
      "prediction: [4121.63399198 4149.03464532 4091.70974001 4109.14317322], real price: [4150.34 4162.04 4111.53 4152.1 ]\n",
      "prediction: [4147.5067265  4167.36726869 4125.45387296 4156.36214984], real price: [4228.29 4236.39 4188.13 4188.43]\n",
      "prediction: [4208.74332651 4234.01319976 4210.91110848 4232.06820247], real price: [4210.34 4238.04 4201.64 4232.6 ]\n",
      "prediction: [4208.41024581 4235.92575089 4213.62946067 4235.82131655], real price: [4169.14 4202.7  4147.33 4201.62]\n",
      "prediction: [4164.83396508 4173.57963806 4127.1583744  4142.44254734], real price: [4177.06 4187.72 4160.94 4167.59]\n",
      "prediction: [4163.87218738 4174.43905201 4132.26970053 4159.06832668], real price: [4179.04 4179.04 4128.59 4164.66]\n",
      "prediction: [4171.33830111 4183.56142503 4136.78564612 4163.49381288], real price: [4191.98 4209.39 4188.03 4192.66]\n",
      "prediction: [4191.71904864 4211.98304469 4180.15864208 4203.45601184], real price: [4198.1  4198.1  4174.85 4181.17]\n",
      "prediction: [4198.54408096 4215.55642629 4210.1688804  4214.58045167], real price: [4206.14 4218.78 4176.81 4211.47]\n",
      "prediction: [4201.32268124 4216.65948506 4198.65769597 4210.71746679], real price: [4185.14 4201.53 4181.78 4183.18]\n",
      "prediction: [4188.18879206 4193.5141895  4162.23079456 4178.54065517], real price: [4188.25 4193.35 4176.22 4186.72]\n",
      "prediction: [4181.21148125 4185.75041741 4169.81993322 4167.9723879 ], real price: [4185.03 4194.19 4182.36 4187.62]\n",
      "prediction: [4173.46064757 4174.98659505 4170.15608694 4158.60532437], real price: [4138.78 4194.17 4138.78 4180.17]\n",
      "prediction: [4124.36255265 4171.07069118 4122.13076379 4154.68190112], real price: [4170.46 4179.57 4123.69 4134.98]\n",
      "prediction: [4165.41197113 4188.85613999 4147.99812371 4163.27479717], real price: [4128.42 4175.02 4126.35 4173.42]\n",
      "prediction: [4111.53151452 4167.3396254  4089.0961146  4123.23739482], real price: [4159.18 4159.18 4118.38 4134.94]\n",
      "prediction: [4152.83068687 4177.331103   4133.09418257 4156.29009338], real price: [4179.8  4180.81 4150.47 4163.26]\n",
      "prediction: [4174.87723236 4191.35404371 4149.36422793 4185.04234156], real price: [4174.14 4191.31 4170.75 4185.47]\n",
      "prediction: [4171.1932087  4183.38621938 4153.34906859 4173.55214224], real price: [4139.76 4173.49 4139.76 4170.42]\n",
      "prediction: [4139.46066895 4163.80602617 4123.53410319 4146.21884283], real price: [4141.58 4151.69 4120.87 4124.66]\n",
      "prediction: [4127.77273625 4137.97420879 4096.88525645 4102.34160321], real price: [4130.1  4148.   4124.43 4141.59]\n",
      "prediction: [4118.5477989  4136.76299896 4105.21943249 4112.78446684], real price: [4124.71 4131.76 4114.82 4127.99]\n",
      "prediction: [4116.27807805 4125.12798814 4099.82318555 4107.58604293], real price: [4096.11 4129.48 4095.51 4128.8 ]\n",
      "prediction: [4081.57999651 4094.72354679 4072.41663826 4080.82897376], real price: [4089.95 4098.19 4082.54 4097.17]\n",
      "prediction: [4079.44240869 4092.2325068  4073.47308189 4091.59357569], real price: [4074.29 4083.13 4068.31 4079.95]\n",
      "prediction: [4070.1721451  4077.71186629 4060.82969577 4073.09528121], real price: [4075.57 4086.23 4068.14 4073.94]\n",
      "prediction: [4072.26405879 4081.26325585 4064.01089414 4072.07693839], real price: [4034.44 4083.42 4034.44 4077.91]\n",
      "prediction: [4022.83696545 4046.64948105 4012.40474013 4031.59302598], real price: [3992.78 4020.63 3992.78 4019.87]\n",
      "prediction: [3983.79046449 4012.6332567  3975.49662636 4007.37494771], real price: [3967.25 3994.41 3966.98 3972.89]\n",
      "prediction: [3957.09315853 3982.677819   3949.14381755 3961.24725491], real price: [3963.34 3968.01 3944.35 3958.55]\n",
      "prediction: [3952.26093824 3965.57222688 3936.47742422 3946.89267611], real price: [3969.31 3981.83 3943.25 3971.09]\n",
      "prediction: [3958.9135368  3965.8470885  3937.51564114 3948.44998026], real price: [3917.12 3978.19 3917.12 3974.54]\n",
      "prediction: [3897.68360212 3932.13944912 3874.26470532 3910.86403782], real price: [3879.34 3919.54 3853.5  3909.52]\n",
      "prediction: [3865.20292294 3905.78396693 3830.22053418 3894.93006297], real price: [3919.93 3942.08 3889.07 3889.14]\n",
      "prediction: [3916.81263467 3947.20284978 3893.76571937 3922.79724626], real price: [3937.6  3949.13 3901.57 3910.52]\n",
      "prediction: [3946.18466846 3972.08166604 3930.21951858 3960.27488736], real price: [3916.48 3955.31 3914.16 3940.59]\n",
      "prediction: [3929.28580116 3966.52605706 3922.50688581 3958.32331183], real price: [3913.14 3930.12 3886.75 3913.1 ]\n",
      "prediction: [3907.35007569 3933.25753811 3884.1818091  3906.17102505], real price: [3953.5  3969.62 3910.86 3915.46]\n",
      "prediction: [3940.53786055 3962.3632343  3914.30898865 3933.4913055 ], real price: [3949.57 3983.87 3935.74 3974.12]\n",
      "prediction: [3946.51645569 3974.61277498 3928.80298446 3958.63133219], real price: [3973.59 3981.04 3953.44 3962.71]\n",
      "prediction: [3966.57309467 3991.64066849 3960.7895281  3984.25761677], real price: [3942.96 3970.08 3923.54 3968.94]\n",
      "prediction: [3940.26229687 3957.84532966 3916.98701898 3936.54588888], real price: [3924.52 3944.99 3915.21 3943.34]\n",
      "prediction: [3903.47663423 3920.61765219 3875.50040323 3875.00360064], real price: [3915.54 3960.27 3915.54 3939.34]\n",
      "prediction: [3911.56587016 3944.57039389 3904.36272964 3933.3050248 ], real price: [3891.99 3917.35 3885.73 3898.81]\n",
      "prediction: [3887.55013666 3916.99854159 3880.46716821 3897.46665576], real price: [3851.93 3903.76 3851.93 3875.44]\n",
      "prediction: [3844.96152569 3884.24882802 3839.06181998 3847.01142016], real price: [3844.39 3881.06 3819.25 3821.35]\n",
      "prediction: [3835.60711551 3873.45993528 3811.79866475 3813.39784699], real price: [3793.58 3851.69 3730.19 3841.94]\n",
      "prediction: [3769.872395   3814.54661534 3682.09188637 3767.39537612], real price: [3818.53 3843.67 3723.34 3768.47]\n",
      "prediction: [3808.96542699 3850.57525923 3732.76205167 3791.49365436], real price: [3863.99 3874.47 3818.86 3819.72]\n",
      "prediction: [3859.81790242 3895.18416657 3863.68055103 3870.11895819], real price: [3903.64 3906.41 3868.57 3870.29]\n",
      "prediction: [3890.3940857  3905.28403795 3900.65311735 3886.72917695], real price: [3842.51 3914.5  3842.51 3901.82]\n",
      "prediction: [3854.78893305 3888.51406479 3833.98031276 3863.50677053], real price: [3839.66 3861.08 3789.54 3811.15]\n",
      "prediction: [3825.45920914 3845.04049151 3752.8628495  3773.98035118], real price: [3915.8  3925.02 3814.04 3829.34]\n",
      "prediction: [3906.56793672 3927.29292075 3869.93803026 3897.77922284], real price: [3873.71 3928.65 3859.6  3925.43]\n",
      "prediction: [3878.81545018 3909.19487825 3841.5220023  3872.76410025], real price: [3857.07 3895.98 3805.59 3881.37]\n",
      "prediction: [3854.11861636 3890.75525888 3811.34620636 3846.07912775], real price: [3885.55 3902.92 3874.71 3876.5 ]\n",
      "prediction: [3858.88128907 3882.78038462 3807.34726029 3833.05867583], real price: [3921.16 3930.41 3903.07 3906.71]\n",
      "prediction: [3898.38835385 3921.51942884 3869.3296776  3898.04805494], real price: [3915.86 3921.98 3885.03 3913.97]\n",
      "prediction: [3920.67492991 3937.45975374 3930.84718972 3936.93355521], real price: [3918.5  3933.61 3900.43 3931.33]\n",
      "prediction: [3910.75289772 3926.0001455  3904.49980484 3918.07619523], real price: [3939.61 3950.43 3923.85 3932.59]\n",
      "prediction: [3930.32460759 3944.30662515 3919.96002794 3939.29982388], real price: [3911.65 3937.23 3905.78 3934.83]\n",
      "prediction: [3907.12969818 3916.48839197 3882.42472805 3902.0527997 ], real price: [3916.4  3925.99 3890.39 3916.38]\n",
      "prediction: [3913.08876703 3924.19834864 3889.67488371 3917.3792246 ], real price: [3920.78 3931.5  3884.94 3909.88]\n",
      "prediction: [3925.52343211 3939.05464421 3908.52615875 3929.24477729], real price: [3910.49 3918.35 3902.64 3911.23]\n",
      "prediction: [3913.25212406 3925.25343945 3892.01110602 3913.02467317], real price: [3892.59 3915.77 3892.59 3915.59]\n",
      "prediction: [3885.12082818 3899.95608684 3870.91235604 3887.79894467], real price: [3878.3  3894.56 3874.93 3886.83]\n",
      "prediction: [3869.42271051 3885.26051223 3866.21699374 3879.36289422], real price: [3836.66 3872.42 3836.66 3871.74]\n",
      "prediction: [3829.06068002 3859.07485427 3825.80254036 3858.12036959], real price: [3840.27 3847.51 3816.68 3830.17]\n",
      "prediction: [3832.57632747 3850.40915539 3814.30660132 3834.11495469], real price: [3791.84 3843.09 3791.84 3826.31]\n",
      "prediction: [3784.79072863 3819.62842499 3766.5383426  3793.25141313], real price: [3731.17 3784.32 3725.62 3773.86]\n",
      "prediction: [3720.80678173 3769.67526912 3700.54092061 3747.79242477], real price: [3778.05 3778.05 3694.12 3714.24]\n",
      "prediction: [3772.97396327 3801.72562332 3737.23245939 3764.96003246], real price: [3755.75 3830.5  3755.75 3787.38]\n",
      "prediction: [3752.12772973 3792.30642881 3719.7974586  3749.17796676], real price: [3836.83 3836.83 3732.48 3750.77]\n",
      "prediction: [3831.70555704 3864.9554246  3817.51555589 3852.9313656 ], real price: [3862.96 3870.9  3847.78 3849.62]\n",
      "prediction: [3852.45712934 3873.60111564 3853.44784654 3861.50774761], real price: [3851.68 3859.23 3797.16 3855.36]\n",
      "prediction: [3846.21210596 3864.01584387 3827.78680611 3853.89211046], real price: [3844.24 3852.31 3830.41 3841.47]\n",
      "prediction: [3837.29091816 3853.45143257 3813.27047752 3831.46080493], real price: [3857.46 3861.45 3845.05 3853.07]\n",
      "prediction: [3848.46462758 3852.1524088  3803.5776773  3819.09915789], real price: [3816.22 3859.75 3816.22 3851.85]\n",
      "prediction: [3796.48204907 3837.62303493 3758.15822076 3831.49523505], real price: [3781.88 3804.53 3780.37 3798.91]\n",
      "prediction: [3772.49279556 3794.32118928 3758.38203469 3786.49424921], real price: [3788.73 3788.73 3749.62 3768.25]\n",
      "prediction: [3780.90083194 3791.83193673 3755.38369489 3773.71913418], real price: [3814.98 3823.6  3792.86 3795.54]\n",
      "prediction: [3814.1492984  3828.68289941 3799.81984712 3814.77592327], real price: [3802.23 3820.96 3791.5  3809.84]\n",
      "prediction: [3808.98626058 3834.56679813 3803.61700954 3824.51643837], real price: [3801.62 3810.78 3776.51 3801.19]\n",
      "prediction: [3801.50432725 3814.7104782  3787.56564917 3801.9361574 ], real price: [3803.14 3817.86 3789.02 3799.61]\n",
      "prediction: [3797.79828926 3803.19551356 3771.1054262  3785.21605805], real price: [3815.05 3826.69 3783.6  3824.68]\n",
      "prediction: [3804.49126071 3816.7819581  3783.73994956 3800.2376153 ], real price: [3764.71 3811.55 3764.71 3803.79]\n",
      "prediction: [3751.41835001 3797.31438961 3749.86511352 3776.3067265 ], real price: [3712.2  3783.04 3705.34 3748.14]\n",
      "prediction: [3702.49890351 3774.67482029 3691.32981474 3731.88481578], real price: [3698.02 3737.83 3695.07 3726.86]\n",
      "prediction: [3680.62771565 3735.8154871  3672.25683297 3707.80274762], real price: [3764.61 3769.99 3662.71 3700.65]\n",
      "prediction: [3766.10254702 3796.38207653 3742.56579299 3777.12701806], real price: [3733.27 3760.2  3726.88 3756.07]\n",
      "prediction: [3746.48332424 3782.78066541 3730.27346081 3762.92162819], real price: [3736.19 3744.63 3730.21 3732.04]\n",
      "prediction: [3735.66345934 3764.42748001 3715.98156866 3740.69681505], real price: [3750.01 3756.12 3723.31 3727.04]\n",
      "prediction: [3744.07333185 3758.36659985 3722.76867686 3737.70308448], real price: [3723.03 3740.51 3723.03 3735.36]\n",
      "prediction: [3701.87903368 3717.37996043 3630.6209554  3668.16374299], real price: [3694.03 3703.82 3689.32 3703.06]\n",
      "prediction: [3691.64384501 3696.28004169 3685.37023293 3690.84271889], real price: [3693.42 3711.24 3689.28 3690.01]\n",
      "prediction: [3688.09442188 3700.44040456 3682.72636873 3688.28970497], real price: [3698.08 3698.26 3676.16 3687.26]\n",
      "prediction: [3695.10154186 3703.75088868 3683.51133163 3690.95326587], real price: [3684.28 3702.9  3636.48 3694.92]\n",
      "prediction: [3678.70569148 3685.2815514  3633.39381723 3669.93194675], real price: [3722.39 3726.7  3685.84 3709.41]\n",
      "prediction: [3709.05416752 3718.2542588  3700.37369829 3706.62552196], real price: [3713.65 3725.12 3710.87 3722.48]\n",
      "prediction: [3708.61430412 3719.33805473 3698.60661392 3710.33217676], real price: [3696.25 3711.27 3688.57 3701.17]\n",
      "prediction: [3695.30105978 3703.68651561 3665.34382189 3693.99787385], real price: [3666.41 3695.29 3659.62 3694.62]\n",
      "prediction: [3657.48345312 3682.46101938 3617.57664849 3678.76652419], real price: [3675.27 3697.61 3645.84 3647.49]\n",
      "prediction: [3669.52254703 3694.19514273 3647.50424684 3659.79711524], real price: [3656.08 3665.91 3633.4  3663.46]\n",
      "prediction: [3648.46983351 3664.54145151 3616.04649772 3634.90816618], real price: [3659.13 3678.49 3645.18 3668.1 ]\n",
      "prediction: [3646.95047947 3660.77325449 3618.79736491 3635.72001354], real price: [3705.98 3712.39 3660.54 3672.82]\n",
      "prediction: [3695.49517707 3715.1698292  3669.29722919 3698.19087429], real price: [3683.05 3708.45 3678.83 3702.25]\n",
      "prediction: [3677.76065407 3694.66756545 3657.83165965 3674.7308543 ], real price: [3694.73 3697.41 3678.88 3691.96]\n",
      "prediction: [3686.09692458 3700.15782386 3671.62553758 3688.30963819], real price: [3670.94 3699.2  3670.94 3699.12]\n",
      "prediction: [3655.30922506 3673.49746108 3642.17956566 3656.73968074], real price: [3668.28 3682.73 3657.17 3666.72]\n",
      "prediction: [3651.86555497 3671.81254758 3645.04161509 3646.35905571], real price: [3653.78 3670.96 3644.84 3669.01]\n",
      "prediction: [3648.77659253 3664.2514855  3638.05491245 3652.61532239], real price: [3645.87 3678.45 3645.87 3662.45]\n",
      "prediction: [3638.80992341 3665.61652881 3633.7800802  3648.55408069], real price: [3634.18 3634.18 3594.39 3621.63]\n",
      "prediction: [3628.78141883 3627.34595017 3586.36519634 3607.73139539], real price: [3638.55 3644.31 3629.33 3638.35]\n",
      "prediction: [3631.48698468 3633.03214316 3600.15773476 3621.53074091], real price: [3635.5  3635.5  3617.76 3629.65]\n",
      "prediction: [3631.95024272 3626.02253805 3597.86509986 3615.61703005], real price: [3594.52 3642.31 3594.52 3635.41]\n",
      "prediction: [3579.19283656 3590.99248251 3549.37132192 3588.73554664], real price: [3566.82 3589.81 3552.77 3577.59]\n",
      "prediction: [3554.07224774 3579.63928731 3533.67510381 3563.51995209], real price: [3579.31 3581.23 3556.85 3557.54]\n",
      "prediction: [3572.14866662 3587.35994069 3553.06534448 3566.35770287], real price: [3559.41 3585.22 3543.84 3581.87]\n",
      "prediction: [3548.86752239 3565.83122973 3527.51591677 3545.01946461], real price: [3612.09 3619.09 3567.33 3567.79]\n",
      "prediction: [3607.10221237 3639.74983585 3597.78780013 3632.92789907], real price: [3610.31 3623.11 3588.68 3609.53]\n",
      "prediction: [3607.54191753 3622.35960286 3586.83484892 3606.79171976], real price: [3600.16 3628.51 3600.16 3626.91]\n",
      "prediction: [3596.88959549 3613.44480867 3582.78788845 3599.96269187], real price: [3552.57 3593.66 3552.57 3585.15]\n",
      "prediction: [3537.91206241 3567.43799901 3522.72657763 3541.86112478], real price: [3562.67 3569.02 3518.58 3537.01]\n",
      "prediction: [3541.93247267 3559.8902159  3505.10297695 3516.13735374], real price: [3563.22 3581.16 3557.   3572.66]\n",
      "prediction: [3553.54478861 3572.47120413 3529.02241379 3548.17514075], real price: [3543.26 3557.22 3511.91 3545.53]\n",
      "prediction: [3538.38668032 3549.27903076 3499.24217818 3522.27123685], real price: [3583.04 3645.99 3547.48 3550.5 ]\n",
      "prediction: [3579.75391178 3643.19034871 3579.54823044 3596.24496146], real price: [3508.34 3521.58 3484.34 3509.44]\n",
      "prediction: [3522.13563656 3515.46972057 3487.27895959 3512.14220228], real price: [3485.74 3529.05 3485.74 3510.45]\n",
      "prediction: [3480.6451155  3484.75261916 3461.15298945 3490.26128979], real price: [3406.46 3486.25 3405.17 3443.44]\n",
      "prediction: [3401.92408702 3439.85446001 3391.95425588 3430.8130946 ], real price: [3336.25 3389.49 3336.25 3369.16]\n",
      "prediction: [3318.74592179 3357.74447866 3307.77349954 3346.25517632], real price: [3296.2  3330.14 3279.74 3310.24]\n",
      "prediction: [3273.76923427 3312.09602689 3248.32723845 3277.49094187], real price: [3293.59 3304.93 3233.94 3269.96]\n",
      "prediction: [3276.34847185 3296.7570407  3227.08109015 3259.15461279], real price: [3277.17 3341.05 3259.82 3310.11]\n",
      "prediction: [3255.33038546 3270.12899142 3202.96497986 3238.17050433], real price: [3342.48 3342.48 3268.89 3271.03]\n",
      "prediction: [3337.88151399 3376.80007796 3331.32126685 3359.03556552], real price: [3403.15 3409.51 3388.71 3390.68]\n",
      "prediction: [3379.32244949 3400.40594197 3393.58378082 3396.65621651], real price: [3441.42 3441.42 3364.86 3400.97]\n",
      "prediction: [3421.0189325  3439.51359213 3414.88713076 3430.74429895], real price: [3464.9  3466.46 3440.45 3465.39]\n",
      "prediction: [3451.20468675 3464.06816328 3455.69710109 3476.37604939], real price: [3438.5  3460.53 3415.34 3453.49]\n",
      "prediction: [3440.61042214 3456.25977292 3433.16534935 3458.73273108], real price: [3439.91 3464.86 3433.06 3435.56]\n",
      "prediction: [3437.9751032  3448.49178976 3414.77561041 3432.07847544], real price: [3439.38 3476.93 3435.65 3443.12]\n",
      "prediction: [3430.93657836 3441.09664745 3373.25390794 3400.4999263 ], real price: [3493.66 3502.42 3419.93 3426.92]\n",
      "prediction: [3493.51920812 3507.21945588 3456.84783836 3481.14985562], real price: [3493.5  3515.76 3480.45 3483.81]\n",
      "prediction: [3495.33401042 3519.54651309 3485.50436656 3489.11592996], real price: [3453.72 3489.08 3440.89 3483.34]\n",
      "prediction: [3448.31914777 3473.72535379 3428.45496127 3434.07333958], real price: [3515.47 3527.94 3480.55 3488.67]\n",
      "prediction: [3487.04490448 3508.82741036 3464.94980606 3476.8174795 ], real price: [3534.01 3534.01 3500.86 3511.93]\n",
      "prediction: [3514.7520216  3526.74332868 3494.23779343 3506.2494094 ], real price: [3500.02 3549.85 3499.61 3534.22]\n",
      "prediction: [3494.34068661 3517.52855843 3479.14715802 3496.56187714], real price: [3459.67 3482.34 3458.07 3477.13]\n",
      "prediction: [3454.63087477 3475.25944125 3442.95191524 3465.71132578], real price: [3434.28 3447.28 3428.15 3446.83]\n",
      "prediction: [3414.04407692 3418.89173039 3408.53444902 3417.95890883], real price: [3384.56 3426.26 3384.56 3419.45]\n",
      "prediction: [3371.20824781 3394.01537273 3364.6473638  3389.8565895 ], real price: [3408.74 3431.56 3354.54 3360.95]\n",
      "prediction: [3401.42119823 3423.12741251 3372.14362067 3386.2338297 ], real price: [3367.27 3409.57 3367.27 3408.63]\n",
      "prediction: [3350.69478866 3389.40555299 3317.42482393 3337.93363992], real price: [3338.94 3369.1  3323.69 3348.44]\n",
      "prediction: [3321.54459501 3356.43227348 3292.14884482 3308.52560942], real price: [3385.87 3397.18 3361.39 3380.8 ]\n",
      "prediction: [3365.89099204 3394.51632905 3347.4848402  3368.01368248], real price: [3341.21 3393.56 3340.47 3363.  ]\n",
      "prediction: [3327.44823244 3363.13881176 3321.34352294 3333.19831789], real price: [3350.92 3357.92 3327.54 3335.47]\n",
      "prediction: [3353.15044077 3380.26702053 3339.99886925 3359.65644044], real price: [3333.9  3360.74 3332.91 3351.6 ]\n",
      "prediction: [3328.32279125 3352.34551115 3319.09395299 3333.86739338], real price: [3236.66 3306.88 3228.44 3298.46]\n",
      "prediction: [3231.65069361 3289.34609816 3211.89548061 3278.80608658], real price: [3226.14 3278.7  3209.45 3246.59]\n",
      "prediction: [3211.209483   3266.74269933 3184.62630477 3238.99757432], real price: [3320.11 3323.35 3232.57 3236.92]\n",
      "prediction: [3325.24838375 3344.72195584 3308.70898261 3323.57281395], real price: [3295.75 3320.31 3270.95 3315.57]\n",
      "prediction: [3310.33906604 3335.98216091 3292.71032191 3322.69228234], real price: [3285.57 3285.57 3229.1  3281.06]\n",
      "prediction: [3288.40599148 3312.42557187 3248.7599311  3295.60304028], real price: [3357.38 3362.27 3292.4  3319.47]\n",
      "prediction: [3326.37491256 3340.08788525 3280.34383295 3316.84459013], real price: [3346.86 3375.17 3328.82 3357.01]\n",
      "prediction: [3338.75496442 3359.01864569 3309.27740098 3342.36189131], real price: [3411.23 3428.92 3384.45 3385.49]\n",
      "prediction: [3385.21898621 3418.03505288 3387.95762073 3390.49708793], real price: [3407.73 3419.48 3389.25 3401.2 ]\n",
      "prediction: [3396.5854962  3425.34206626 3401.90758492 3404.04577592], real price: [3363.56 3402.93 3363.56 3383.54]\n",
      "prediction: [3359.75834409 3374.14691162 3327.20713938 3344.60923045], real price: [3352.7  3368.95 3310.47 3340.97]\n",
      "prediction: [3353.97110877 3374.93504844 3326.30762409 3351.36895356], real price: [3412.56 3425.55 3329.25 3339.19]\n",
      "prediction: [3415.83985447 3433.71280391 3399.66457545 3401.36068118], real price: [3369.82 3424.77 3366.84 3398.96]\n",
      "prediction: [3378.97365189 3405.132395   3350.34747245 3368.49718473], real price: [3371.88 3379.97 3329.27 3331.84]\n",
      "prediction: [3380.27177547 3407.78823834 3350.296175   3369.20995679], real price: [3453.6  3479.15 3349.63 3426.96]\n",
      "prediction: [3419.34217499 3452.28815959 3360.00143839 3411.91929917], real price: [3564.74 3564.85 3427.41 3455.06]\n",
      "prediction: [3511.72404253 3541.25759803 3422.88740732 3472.07113451], real price: [3543.76 3588.11 3535.23 3580.84]\n",
      "prediction: [3539.47104849 3585.55942845 3518.40848182 3565.71442688], real price: [3507.44 3528.03 3494.6  3526.65]\n",
      "prediction: [3498.45592079 3521.90798173 3463.46859995 3491.99869022], real price: [3509.73 3514.77 3493.25 3500.31]\n",
      "prediction: [3481.64908599 3488.60229725 3393.00233364 3433.36531094], real price: [3494.69 3509.23 3484.32 3508.01]\n",
      "prediction: [3450.56220021 3434.9251911  3371.80065437 3369.60345234], real price: [3485.14 3501.38 3468.35 3484.55]\n",
      "prediction: [3476.96092532 3474.20994381 3455.21561005 3457.71042788], real price: [3449.97 3481.07 3444.15 3478.73]\n",
      "prediction: [3441.99772837 3467.46605431 3428.66617589 3453.758687  ], real price: [3435.95 3444.21 3425.84 3443.62]\n",
      "prediction: [3427.9831695  3441.78479367 3414.46984225 3437.82245219], real price: [3418.09 3432.09 3413.13 3431.28]\n",
      "prediction: [3410.08711913 3419.76839061 3398.96720661 3415.84137521], real price: [3386.01 3399.96 3379.31 3397.16]\n",
      "prediction: [3380.36312449 3385.9257013  3369.25659294 3383.49174662], real price: [3360.48 3390.8  3354.69 3385.51]\n",
      "prediction: [3347.47974234 3360.0792971  3332.1221415  3350.27814078], real price: [3392.51 3399.54 3369.66 3374.85]\n",
      "prediction: [3389.20129818 3404.66453459 3377.05392418 3393.59550793], real price: [3387.04 3395.06 3370.15 3389.78]\n",
      "prediction: [3390.22714502 3403.85055113 3378.87691515 3396.1194423 ], real price: [3380.86 3387.59 3379.22 3381.99]\n",
      "prediction: [3384.24483377 3395.71161631 3373.99126015 3387.99606851], real price: [3368.66 3378.51 3361.64 3372.85]\n",
      "prediction: [3369.84422293 3383.88841984 3360.48601059 3375.31377891], real price: [3372.95 3387.24 3363.35 3373.43]\n",
      "prediction: [3364.1388435  3374.13401401 3355.46905867 3364.01311875], real price: [3355.46 3387.89 3355.46 3380.35]\n",
      "prediction: [3344.95860627 3370.77849089 3340.92509639 3359.39535511], real price: [3370.34 3381.01 3326.44 3333.69]\n",
      "prediction: [3368.8915386  3383.77560536 3355.30774773 3364.89361664], real price: [3356.04 3363.29 3335.44 3360.47]\n",
      "prediction: [3354.61421804 3365.48058635 3325.02719959 3336.77463808], real price: [3340.05 3352.54 3328.72 3351.28]\n",
      "prediction: [3330.00990842 3333.72902544 3299.43648    3310.11944961], real price: [3323.17 3351.03 3318.14 3349.16]\n",
      "prediction: [3302.44554137 3314.7585183  3289.47573802 3299.09627226], real price: [3317.37 3330.77 3317.37 3327.77]\n",
      "prediction: [3296.70651866 3312.67902105 3307.48975099 3311.54738528], real price: [3289.92 3306.84 3286.37 3306.51]\n",
      "prediction: [3286.42840552 3301.84537328 3283.38539957 3298.29283573], real price: [3288.26 3302.73 3284.53 3294.61]\n",
      "prediction: [3282.31243547 3294.86142919 3276.65652976 3286.54779951], real price: [3270.45 3272.17 3220.26 3271.12]\n",
      "prediction: [3264.82249574 3262.76113164 3216.4857292  3255.79213899], real price: [3231.76 3250.92 3204.13 3246.22]\n",
      "prediction: [3228.58100117 3236.0708023  3172.91831269 3227.92573615], real price: [3227.22 3264.74 3227.22 3258.44]\n",
      "prediction: [3210.63045996 3233.50070715 3170.30322661 3224.95908324], real price: [3234.27 3243.72 3216.17 3218.44]\n",
      "prediction: [3227.44496268 3245.89192888 3200.54238654 3229.90935034], real price: [3219.84 3241.43 3214.25 3239.41]\n",
      "prediction: [3208.97321651 3232.64465925 3202.4850856  3212.58736562], real price: [3218.58 3227.26 3200.05 3215.63]\n",
      "prediction: [3213.9441315  3216.80610755 3190.20382605 3195.7948662 ], real price: [3271.64 3279.99 3222.66 3235.66]\n",
      "prediction: [3263.59227041 3285.90251474 3238.38455425 3268.29078519], real price: [3254.86 3279.32 3253.1  3276.02]\n",
      "prediction: [3254.09663377 3273.05137036 3240.91400115 3260.54652086], real price: [3268.52 3277.29 3247.77 3257.3 ]\n",
      "prediction: [3265.78174189 3284.75124101 3254.88740519 3272.05523161], real price: [3224.29 3258.61 3215.16 3251.84]\n",
      "prediction: [3213.59944557 3223.63410099 3191.92798473 3206.20178673], real price: [3224.21 3233.52 3205.65 3224.73]\n",
      "prediction: [3205.76666187 3222.39759578 3184.52172824 3204.52388283], real price: [3208.36 3220.39 3198.59 3215.57]\n",
      "prediction: [3205.05302128 3217.93632876 3188.62854196 3208.59581697], real price: [3225.98 3238.28 3200.76 3226.56]\n",
      "prediction: [3221.81751687 3236.07400045 3204.645835   3226.32642708], real price: [3141.11 3200.95 3127.66 3197.52]\n",
      "prediction: [3141.73664273 3186.42494587 3117.57260378 3180.93110109], real price: [3205.08 3235.32 3149.43 3155.22]\n",
      "prediction: [3211.5376084  3229.81136913 3189.87032538 3211.87164692], real price: [3152.47 3186.82 3136.22 3185.04]\n",
      "prediction: [3154.2328701  3194.32043914 3127.74648406 3166.56520088], real price: [3176.17 3179.78 3115.7  3152.05]\n",
      "prediction: [3178.05710989 3204.96724624 3143.15556722 3179.03464133], real price: [3153.07 3171.8  3136.53 3169.94]\n",
      "prediction: [3151.61888374 3178.01493207 3125.32848931 3158.65545195], real price: [3166.44 3184.15 3142.93 3145.32]\n",
      "prediction: [3157.34884981 3174.0199389  3127.4696481  3149.9775004 ], real price: [3155.29 3182.59 3155.29 3179.72]\n",
      "prediction: [3152.61778253 3175.13295494 3124.40078555 3148.77814794], real price: [3143.64 3165.81 3124.52 3130.01]\n",
      "prediction: [3135.35721036 3158.96055532 3101.00719289 3109.22204065], real price: [3105.92 3128.44 3101.17 3115.86]\n",
      "prediction: [3100.25071848 3115.19928565 3085.89528314 3085.06329635], real price: [3050.2  3111.51 3047.83 3100.29]\n",
      "prediction: [3031.60560837 3080.10648296 3017.70447929 3061.62682702], real price: [3018.59 3053.89 2999.74 3053.24]\n",
      "prediction: [2997.21905407 3035.5281179  2967.77428626 3024.87938175], real price: [3073.2  3073.73 3004.63 3009.05]\n",
      "prediction: [3076.55147941 3102.70549262 3052.27133809 3076.28437301], real price: [3046.6  3086.25 3024.01 3083.76]\n",
      "prediction: [3048.76151269 3079.92204349 3020.65334051 3055.26804825], real price: [3114.4  3115.01 3032.13 3050.33]\n",
      "prediction: [3108.74826111 3131.28013194 3064.96492598 3131.4073315 ], real price: [3138.7  3154.9  3127.12 3131.29]\n",
      "prediction: [3128.84453395 3149.16127179 3125.05977395 3141.18170507], real price: [3094.42 3120.92 3079.39 3117.86]\n",
      "prediction: [3096.80321839 3113.63215556 3069.61146709 3089.15267875], real price: [3140.29 3155.53 3083.11 3097.74]\n",
      "prediction: [3134.63970843 3153.41341119 3118.21476891 3132.01039705], real price: [3101.64 3120.   3093.51 3115.34]\n",
      "prediction: [3089.22524771 3097.9465165  3028.32965509 3047.25772206], real price: [3136.13 3141.16 3108.03 3113.49]\n",
      "prediction: [3132.94605783 3147.22314934 3110.90232861 3121.98966671], real price: [3131.   3153.45 3076.06 3124.74]\n",
      "prediction: [3121.07269457 3137.9126216  3090.01727186 3114.39108703], real price: [2993.76 3079.76 2965.66 3066.59]\n",
      "prediction: [2988.94484288 3061.68180483 2944.11510124 3052.42690394], real price: [3071.04 3088.42 2984.47 3041.31]\n",
      "prediction: [3070.98811903 3105.93815371 3024.88521619 3078.64702688], real price: [3123.53 3123.53 2999.49 3002.1 ]\n",
      "prediction: [3149.706776   3152.28291963 3113.06696497 3131.28256767], real price: [3213.42 3223.27 3181.49 3190.14]\n",
      "prediction: [3194.05428475 3211.79955154 3193.64131541 3206.55726718], real price: [3213.32 3222.71 3193.11 3207.18]\n",
      "prediction: [3211.27952963 3233.33903021 3237.80692216 3241.19631207], real price: [3199.92 3233.13 3196.   3232.39]\n",
      "prediction: [3197.74578919 3225.12928197 3212.94751508 3227.77968191], real price: [3163.84 3211.72 3163.84 3193.93]\n",
      "prediction: [3151.31927175 3153.04321202 3071.41225271 3065.11145881], real price: [3111.56 3128.91 3090.41 3112.35]\n",
      "prediction: [3097.09342139 3108.39748607 3067.84091888 3081.8897169 ], real price: [3098.9  3130.94 3098.9  3122.87]\n",
      "prediction: [3076.92487521 3095.84663505 3056.94008726 3073.96336623], real price: [3064.78 3081.07 3051.64 3080.82]\n",
      "prediction: [3044.88507359 3049.53788001 3016.77684163 3033.59551298], real price: [3038.78 3062.18 3031.54 3055.73]\n",
      "prediction: [3020.83925143 3022.09836171 2995.30997351 3014.92539269], real price: [3025.17 3049.17 2998.61 3044.31]\n",
      "prediction: [3012.92512118 3029.0885239  2984.09095639 3023.14798735], real price: [3046.61 3068.67 3023.4  3029.73]\n",
      "prediction: [3044.62640121 3065.50983337 3024.75110473 3049.36011206], real price: [3015.65 3036.25 2969.75 3036.13]\n",
      "prediction: [3015.02718834 3035.69224297 2970.36521801 3019.79467401], real price: [3004.08 3021.72 2988.17 2991.77]\n",
      "prediction: [3004.06342524 3019.63711684 2964.61065132 2993.95022467], real price: [2948.05 2956.76 2933.59 2955.45]\n",
      "prediction: [2946.59535948 2944.83297605 2917.79253873 2936.2614169 ], real price: [2969.95 2978.5  2938.57 2948.51]\n",
      "prediction: [2958.88746207 2964.58932165 2929.27051669 2945.55420812], real price: [2953.63 2980.29 2953.63 2971.61]\n",
      "prediction: [2938.08663192 2945.68260177 2922.35381849 2924.91820991], real price: [2948.59 2964.21 2922.35 2922.94]\n",
      "prediction: [2947.89216611 2960.02664449 2926.23204903 2935.87535072], real price: [2913.86 2968.09 2913.86 2953.91]\n",
      "prediction: [2898.37558383 2940.19803976 2889.04762936 2896.97874776], real price: [2829.95 2865.01 2816.78 2863.7 ]\n",
      "prediction: [2815.08133765 2841.27348204 2787.85446731 2832.75379222], real price: [2794.54 2852.8  2766.64 2852.5 ]\n",
      "prediction: [2765.19893693 2807.24165969 2718.67053247 2803.71497731], real price: [2865.86 2874.14 2793.15 2820.  ]\n",
      "prediction: [2862.37659968 2894.56218388 2830.56436279 2870.95292296], real price: [2939.5  2945.82 2869.59 2870.12]\n",
      "prediction: [2942.45412594 2979.4397862  2947.88698878 2960.71780678], real price: [2915.46 2944.25 2903.44 2930.32]\n",
      "prediction: [2921.82012836 2947.33662642 2910.41962425 2924.14408432], real price: [2908.83 2932.16 2902.88 2929.8 ]\n",
      "prediction: [2896.78338678 2922.00231358 2880.1618596  2900.53377637], real price: [2878.26 2901.92 2876.48 2881.19]\n",
      "prediction: [2858.12471855 2860.20893013 2791.61866725 2797.97089121], real price: [2883.14 2891.11 2847.65 2848.42]\n",
      "prediction: [2862.95991889 2874.67175084 2834.16629868 2817.68559273], real price: [2868.88 2898.23 2863.55 2868.44]\n",
      "prediction: [2862.19164876 2877.08000438 2838.99500386 2829.1109149 ], real price: [2815.01 2844.24 2797.85 2842.74]\n",
      "prediction: [2798.56805711 2815.89483858 2761.66702208 2784.49275772], real price: [2869.09 2869.09 2821.61 2830.71]\n",
      "prediction: [2863.69998733 2880.32423452 2842.16954663 2853.81453722], real price: [2930.91 2930.91 2892.47 2912.43]\n",
      "prediction: [2897.85465425 2909.45873691 2876.88115382 2887.72804045], real price: [2918.46 2954.86 2912.16 2939.51]\n",
      "prediction: [2914.17193331 2940.91691252 2913.62603314 2932.01708069], real price: [2909.96 2921.15 2860.71 2863.39]\n",
      "prediction: [2926.14539548 2950.97894388 2919.09909635 2937.04602044], real price: [2854.65 2887.72 2852.89 2878.48]\n",
      "prediction: [2842.52872137 2840.83414458 2799.89836768 2795.60471615], real price: [2812.64 2842.71 2791.76 2836.74]\n",
      "prediction: [2789.41177563 2811.51137398 2759.61028867 2791.77448804], real price: [2810.42 2844.9  2794.26 2797.8 ]\n",
      "prediction: [2791.51596954 2818.49908761 2764.52094296 2779.18711257], real price: [2787.89 2815.1  2775.95 2799.31]\n",
      "prediction: [2778.31860091 2808.90240971 2763.21211032 2784.56724245], real price: [2784.81 2785.54 2727.1  2736.56]\n",
      "prediction: [2779.34270001 2789.85774187 2731.89955856 2741.84011421], real price: [2845.62 2868.98 2820.43 2823.16]\n",
      "prediction: [2833.10786182 2870.42626128 2835.53761378 2854.4101561 ], real price: [2842.43 2879.22 2830.88 2874.56]\n",
      "prediction: [2836.405029   2875.6404856  2839.36878513 2865.08133374], real price: [2799.34 2806.51 2764.32 2799.55]\n",
      "prediction: [2804.39630575 2815.83351213 2775.09202231 2790.73046014], real price: [2795.64 2801.88 2761.54 2783.36]\n",
      "prediction: [2780.0235923  2764.88793927 2720.67059439 2727.10283736], real price: [2805.1  2851.85 2805.1  2846.06]\n",
      "prediction: [2772.77821455 2765.1602518  2728.24347112 2744.0226023 ], real price: [2782.46 2782.46 2721.17 2761.63]\n",
      "prediction: [2774.42269818 2762.35789446 2709.39340199 2736.77917911], real price: [2776.99 2818.57 2762.36 2789.82]\n",
      "prediction: [2766.86170401 2745.01675614 2688.24922603 2712.65675995], real price: [2685.   2760.75 2663.3  2749.98]\n",
      "prediction: [2664.55793037 2712.17806041 2606.31024788 2686.06830168], real price: [2738.65 2756.89 2657.67 2659.41]\n",
      "prediction: [2727.92168008 2766.01155989 2676.2337256  2709.83345244], real price: [2578.28 2676.85 2574.57 2663.68]\n",
      "prediction: [2574.53516862 2661.51943711 2540.801798   2606.78421365], real price: [2514.92 2538.18 2459.96 2488.65]\n",
      "prediction: [2494.64241927 2528.63075675 2428.87516213 2462.6099832 ], real price: [2458.54 2533.22 2455.79 2526.9 ]\n",
      "prediction: [2409.54955237 2453.09961126 2375.90827704 2412.26536591], real price: [2498.08 2522.75 2447.49 2470.5 ]\n",
      "prediction: [2469.31175407 2514.46998348 2433.95806371 2473.9708801 ], real price: [2614.69 2641.39 2571.15 2584.59]\n",
      "prediction: [2588.44709178 2655.94278582 2586.5522958  2641.82125347], real price: [2558.98 2631.8  2545.28 2626.65]\n",
      "prediction: [2557.92325468 2609.67637538 2543.73480835 2590.79311063], real price: [2555.87 2615.91 2520.02 2541.47]\n",
      "prediction: [2569.65612928 2628.57238284 2558.13649173 2601.50573731], real price: [2501.29 2637.01 2500.72 2630.07]\n",
      "prediction: [2457.3221387  2490.87624251 2414.50517041 2411.04451477], real price: [2457.77 2571.42 2407.53 2475.56]\n",
      "prediction: [2417.41792257 2552.82803866 2362.7371288  2413.15936814], real price: [2344.44 2449.71 2344.44 2447.33]\n",
      "prediction: [2311.00818544 2405.51430316 2271.44048203 2343.88677362], real price: [2290.71 2300.73 2191.86 2237.4 ]\n",
      "prediction: [2259.18846865 2272.68418027 2156.02963289 2195.83581997], real price: [2431.94 2453.01 2295.56 2304.92]\n",
      "prediction: [2420.62711708 2500.75788367 2372.52029011 2442.24506889], real price: [2393.48 2466.97 2319.78 2409.39]\n",
      "prediction: [2410.84840711 2487.16866926 2354.0155834  2419.60304023], real price: [2436.5  2453.57 2280.52 2398.1 ]\n",
      "prediction: [2436.05472435 2503.20560771 2370.03438007 2478.72058026], real price: [2425.66 2553.93 2367.04 2529.19]\n",
      "prediction: [2403.32862158 2460.2850447  2315.82846601 2406.80189356], real price: [2508.59 2562.98 2380.94 2386.13]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# random = np.random.normal(0,1,(1,5,4))\n",
    "(real_input, real_output) = split_time_series(5, load_data())\n",
    "(stzd_input, scalers) = batch_standardize(input)\n",
    "\n",
    "stzd_output = lstmgan.generator(tf.convert_to_tensor(stzd_input))\n",
    "predictions = batch_inverse_scale(stzd_output, scalers)\n",
    "\n",
    "for p, r in zip(predictions, real_output):\n",
    "     print(f'prediction: {p}, real price: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#TODO: separate graph by features \n",
    "length = len(predictions)\n",
    "\n",
    "plt.plot(range(length), [p[0] for p in predictions], color ='r', \n",
    "         label ='predicted')\n",
    "  \n",
    "plt.plot(range(length), [p[0] for p in real_output], color ='b', \n",
    "         label ='real')\n",
    "  \n",
    "# naming of x-axis and y-axis\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "  \n",
    "# naming the title of the plot\n",
    "plt.title('Predicted Open Price vs. Real Open Price')\n",
    "  \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
