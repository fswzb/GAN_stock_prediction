{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout, Bidirectional, LSTM, Reshape, RepeatVector, TimeDistributed\nfrom keras.layers import BatchNormalization, Activation\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport sys\n\nimport numpy as np\n\nimport os\n\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data\nLoading from preprocessed numpy array","metadata":{}},{"cell_type":"code","source":"def load_data():\n    x_train = np.load(r'../input/blues-genre-midi-melodies/answers.npy',allow_pickle=True)\n    x_train = x_train.reshape(721,4,4)\n    return x_train","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating GAN","metadata":{}},{"cell_type":"code","source":"class LSTMGAN():\n    def __init__(self):\n        # Input shape\n        self.img_rows = 4\n        self.img_cols = 4\n        self.img_shape = (self.img_rows, self.img_cols)\n        self.latent_dim = 16\n\n        optimizer = Adam(0.0001, 0.4)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # The generator takes noise as input and generates song\n        z = Input(shape=(4,4))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains the generator to fool the discriminator\n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        model = Sequential()\n        model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(4, 4)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, return_sequences=True)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128)))\n        model.add(LeakyReLU(alpha=0.2))\n        #specifying output to have 40 timesteps\n        model.add(RepeatVector(16))\n        #specifying 1 feature as the output\n        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.3))   \n        model.add(TimeDistributed(Dense(128)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(128)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(1)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.summary()\n\n        noise = Input(shape=(4,4))\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        model = Sequential()\n\n        model.add(Bidirectional(LSTM(128, activation = 'relu', return_sequences=True), input_shape=(16, 1)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, activation = 'relu')))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(RepeatVector(1))\n        model.add(TimeDistributed(Dense(128, activation = 'sigmoid')))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(128, activation = 'relu')))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(1, activation = 'linear')))\n        model.summary()\n\n        img = Input(shape=(16,1))\n        validity = model(img)\n\n        return Model(img, validity)\n    \n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        X_train = load_data()\n\n        # Rescale 0 to 1\n        X_train = X_train / 128\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size,1,1))\n        fake = np.zeros((batch_size,1,1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half of songs\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs = X_train[idx]\n            imgs = np.array(imgs)\n            imgs = imgs.reshape(len(imgs),16,1)\n\n            # Sample noise and generate a batch of new songs\n            noise = np.random.normal(0, 1, (batch_size,4,4))\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator (real classified as ones and generated as zeros)\n            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # Train the generator (wants discriminator to mistake songs as real)\n            g_loss = self.combined.train_on_batch(noise, valid)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval => save model\n            if epoch % save_interval == 0:\n                self.generator.save(\"LSTM_generator.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Summary\nI couldn't train the model on this online notebook so I trained it locally for 1000 epochs and uploaded the h5 file.","metadata":{}},{"cell_type":"code","source":"lstmgan = LSTMGAN()\n#lstmgan.train(epochs=1000, batch_size=20, save_interval=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading pretrained model","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(r'../input/bilstm-gan/LSTM_generator.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Installinging Mido Library","metadata":{}},{"cell_type":"code","source":"!pip install mido","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mido # easy to use python MIDI library\nfrom mido import MidiFile, MidiTrack, Message","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating Melody\nGenerating random input and letting model predict output","metadata":{}},{"cell_type":"code","source":"random = np.random.normal(0,1,(1,4,4))\n\npredict = model.predict(random)\n\n#adjusting for normalization\npredict = predict * 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Back to MIDI\nSave generated melody back to a .mid file","metadata":{}},{"cell_type":"code","source":"midler = MidiFile()\ntrack = MidiTrack()\nmidler.tracks.append(track)\ntrack.append(Message('program_change', program=2, time=0))\nfor x in range(16):\n    track.append(Message('note_on', note=int(predict[0][x][0]), velocity=64, time=20))\n    track.append(Message('note_off', note=int(predict[0][x][0]), velocity=64, time=20))\n    midler.save('new_song.mid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}