{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gan in c:\\users\\zheng\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: tensorflow-probability>=0.7 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-gan) (0.16.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.2 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-gan) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-hub>=0.2->tensorflow-gan) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-hub>=0.2->tensorflow-gan) (1.20.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.0.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.5.3)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (2.0.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.1.6)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.16.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\zheng\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (5.1.0)\n",
      "WARNING:tensorflow:From C:\\Users\\zheng\\anaconda3\\lib\\site-packages\\tensorflow_gan\\python\\estimator\\tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that imports for the rest of the file work.\n",
    "import tensorflow.compat.v1 as tf\n",
    "!pip install tensorflow-gan\n",
    "import tensorflow_gan as tfgan\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Allow matplotlib images to render immediately.\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # Disable noisy outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tough-poetry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2425.66</td>\n",
       "      <td>2553.93</td>\n",
       "      <td>2367.04</td>\n",
       "      <td>2529.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2436.50</td>\n",
       "      <td>2453.57</td>\n",
       "      <td>2280.52</td>\n",
       "      <td>2398.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2393.48</td>\n",
       "      <td>2466.97</td>\n",
       "      <td>2319.78</td>\n",
       "      <td>2409.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2431.94</td>\n",
       "      <td>2453.01</td>\n",
       "      <td>2295.56</td>\n",
       "      <td>2304.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2290.71</td>\n",
       "      <td>2300.73</td>\n",
       "      <td>2191.86</td>\n",
       "      <td>2237.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open     High      Low    Close\n",
       "1  2425.66  2553.93  2367.04  2529.19\n",
       "2  2436.50  2453.57  2280.52  2398.10\n",
       "3  2393.48  2466.97  2319.78  2409.39\n",
       "4  2431.94  2453.01  2295.56  2304.92\n",
       "5  2290.71  2300.73  2191.86  2237.40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_average = pd.read_csv(\n",
    "    \"./data_stock/SP500_average.csv\",\n",
    "    ).drop([0]).drop(columns=['Date'])\n",
    "SP500_average.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(mode, params):\n",
    "  assert 'batch_size' in params\n",
    "  assert 'noise_dims' in params\n",
    "  bs = params['batch_size']\n",
    "  nd = params['noise_dims']\n",
    "  split = 'train' if mode == tf.estimator.ModeKeys.TRAIN else 'test'\n",
    "  shuffle = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  just_noise = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "  \n",
    "  noise_ds = (tf.data.Dataset.from_tensors(0).repeat()\n",
    "              .map(lambda _: tf.random.normal([bs, nd])))\n",
    "  if just_noise:\n",
    "    return noise_ds\n",
    "  SP500_average = pd.read_csv(\n",
    "    \"./data_stock/SP500_average.csv\",\n",
    "    ).drop([0]).drop(columns=['Date'])\n",
    "  SP500_average_ds = tf.data.Dataset.from_tensor_slices(SP500_average.values.tolist()).cache()\n",
    "  train_size = tf.data.experimental.cardinality(SP500_average_ds)\n",
    "    \n",
    "  if split == 'train':\n",
    "    SP500_average_ds.take(train_size)\n",
    "  else:\n",
    "    SP500_average_ds.skip(train_size)\n",
    "    \n",
    "  if shuffle:\n",
    "    SP500_average_ds = SP500_average_ds.shuffle(\n",
    "        buffer_size=10000, reshuffle_each_iteration=True)\n",
    "  SP500_average_ds = (SP500_average_ds.batch(bs, drop_remainder=True)\n",
    "               .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "  return tf.data.Dataset.zip((noise_ds, SP500_average_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imported-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3814.98 3823.6  3792.86 3795.54]\n",
      " [3937.6  3949.13 3901.57 3910.52]\n",
      " [3166.44 3184.15 3142.93 3145.32]\n",
      " [4201.94 4213.38 4197.78 4200.88]\n",
      " [2908.83 2932.16 2902.88 2929.8 ]\n",
      " [3733.27 3760.2  3726.88 3756.07]\n",
      " [3969.31 3981.83 3943.25 3971.09]\n",
      " [4669.14 4714.13 4638.27 4713.07]\n",
      " [2738.65 2756.89 2657.67 2659.41]\n",
      " [4435.79 4445.21 4430.03 4436.75]\n",
      " [4256.97 4271.28 4256.97 4266.49]\n",
      " [4788.64 4804.06 4778.08 4793.06]\n",
      " [3892.59 3915.77 3892.59 3915.59]\n",
      " [4410.56 4444.35 4406.8  4441.67]\n",
      " [4392.74 4423.79 4373.   4423.15]\n",
      " [3543.76 3588.11 3535.23 3580.84]\n",
      " [4329.38 4371.6  4329.38 4369.55]\n",
      " [4642.99 4660.47 4606.52 4634.09]\n",
      " [3418.09 3432.09 3413.13 3431.28]\n",
      " [3840.27 3847.51 3816.68 3830.17]\n",
      " [2457.77 2571.42 2407.53 2475.56]\n",
      " [3694.73 3697.41 3678.88 3691.96]\n",
      " [3915.8  3925.02 3814.04 3829.34]\n",
      " [3406.46 3486.25 3405.17 3443.44]\n",
      " [4406.86 4422.18 4384.81 4387.16]\n",
      " [4474.81 4492.99 4445.7  4468.73]\n",
      " [4385.44 4415.88 4360.59 4361.19]\n",
      " [3441.42 3441.42 3364.86 3400.97]\n",
      " [3152.47 3186.82 3136.22 3185.04]\n",
      " [4309.87 4369.23 4309.87 4345.72]\n",
      " [3712.2  3783.04 3705.34 3748.14]\n",
      " [3949.57 3983.87 3935.74 3974.12]\n",
      " [4089.95 4098.19 4082.54 4097.17]\n",
      " [3385.87 3397.18 3361.39 3380.8 ]\n",
      " [4775.21 4786.83 4765.75 4766.18]\n",
      " [4546.12 4559.67 4524.   4544.9 ]\n",
      " [3453.6  3479.15 3349.63 3426.96]\n",
      " [4408.86 4429.76 4408.86 4429.1 ]\n",
      " [3213.32 3222.71 3193.11 3207.18]\n",
      " [4248.87 4251.89 4202.45 4223.7 ]\n",
      " [3296.2  3330.14 3279.74 3310.24]\n",
      " [4130.55 4134.73 4056.88 4063.04]\n",
      " [4361.27 4369.87 4350.06 4367.48]\n",
      " [4636.46 4712.6  4611.22 4709.85]\n",
      " [4074.99 4131.58 4074.99 4112.5 ]\n",
      " [2878.26 2901.92 2876.48 2881.19]\n",
      " [3453.72 3489.08 3440.89 3483.34]\n",
      " [4613.34 4635.15 4613.34 4630.65]\n",
      " [3155.29 3182.59 3155.29 3179.72]\n",
      " [4138.78 4194.17 4138.78 4180.17]\n",
      " [4331.13 4359.7  4331.13 4358.69]\n",
      " [3371.88 3379.97 3329.27 3331.84]\n",
      " [2614.69 2641.39 2571.15 2584.59]\n",
      " [4655.24 4688.47 4650.77 4682.85]\n",
      " [4469.74 4471.52 4427.76 4432.99]\n",
      " [3873.71 3928.65 3859.6  3925.43]\n",
      " [4372.41 4386.68 4364.03 4384.63]\n",
      " [3071.04 3088.42 2984.47 3041.31]\n",
      " [3336.25 3389.49 3336.25 3369.16]\n",
      " [4659.39 4664.55 4648.31 4649.27]\n",
      " [4719.13 4731.99 4651.89 4668.67]\n",
      " [3412.56 3425.55 3329.25 3339.19]\n",
      " [3094.42 3120.92 3079.39 3117.86]\n",
      " [3801.62 3810.78 3776.51 3801.19]\n",
      " [3218.58 3227.26 3200.05 3215.63]\n",
      " [2869.09 2869.09 2821.61 2830.71]\n",
      " [2845.62 2868.98 2820.43 2823.16]\n",
      " [3493.66 3502.42 3419.93 3426.92]\n",
      " [3713.65 3725.12 3710.87 3722.48]\n",
      " [3018.59 3053.89 2999.74 3053.24]\n",
      " [3333.9  3360.74 3332.91 3351.6 ]\n",
      " [4532.42 4541.45 4521.3  4535.43]\n",
      " [3764.71 3811.55 3764.71 3803.79]\n",
      " [3360.48 3390.8  3354.69 3385.51]\n",
      " [3004.08 3021.72 2988.17 2991.77]\n",
      " [4415.95 4416.17 4400.23 4402.66]\n",
      " [4170.16 4209.52 4170.16 4197.05]\n",
      " [4366.64 4411.01 4287.11 4356.45]\n",
      " [3363.56 3402.93 3363.56 3383.54]\n",
      " [3791.84 3843.09 3791.84 3826.31]\n",
      " [3594.52 3642.31 3594.52 3635.41]\n",
      " [4675.78 4702.87 4659.89 4701.46]\n",
      " [3140.29 3155.53 3083.11 3097.74]\n",
      " [4687.64 4713.57 4670.24 4712.02]\n",
      " [3098.9  3130.94 3098.9  3122.87]\n",
      " [4367.43 4416.75 4367.43 4395.64]\n",
      " [3439.38 3476.93 3435.65 3443.12]\n",
      " [2810.42 2844.9  2794.26 2797.8 ]\n",
      " [3403.15 3409.51 3388.71 3390.68]\n",
      " [4165.94 4169.15 4125.99 4127.83]\n",
      " [4580.22 4584.57 4551.66 4551.68]\n",
      " [2993.76 3079.76 2965.66 3066.59]\n",
      " [4703.96 4740.74 4703.96 4725.79]\n",
      " [3863.99 3874.47 3818.86 3819.72]\n",
      " [4628.75 4672.95 4625.26 4655.27]\n",
      " [4232.99 4237.09 4218.74 4219.55]\n",
      " [3750.01 3756.12 3723.31 3727.04]\n",
      " [3105.92 3128.44 3101.17 3115.86]\n",
      " [4248.31 4255.59 4234.07 4255.15]\n",
      " [3534.01 3534.01 3500.86 3511.93]]\n"
     ]
    }
   ],
   "source": [
    "# sanity check dataset\n",
    "params = {'batch_size': 100, 'noise_dims':64}\n",
    "with tf.Graph().as_default():\n",
    "  ds = input_fn(tf.estimator.ModeKeys.TRAIN, params)\n",
    "  example = next(iter(tfds.as_numpy(ds)))[1]\n",
    "  print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "careful-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dense(inputs, units, l2_weight, activation = None):\n",
    "  return tf.layers.dense(\n",
    "      inputs, units, activation,\n",
    "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
    "\n",
    "\n",
    "def _batch_norm(inputs, is_training):\n",
    "  return tf.layers.batch_normalization(\n",
    "      inputs, momentum=0.999, epsilon=0.001, training=is_training)\n",
    "\n",
    "def _deconv2d(inputs, filters, kernel_size, stride, l2_weight):\n",
    "  return tf.layers.conv2d_transpose(\n",
    "      inputs, filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
    "      activation=tf.nn.relu, padding='same',\n",
    "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
    "\n",
    "def _conv2d(inputs, filters, kernel_size, stride, l2_weight):\n",
    "  return tf.layers.conv2d(\n",
    "      inputs, filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
    "      activation=None, padding='same',\n",
    "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "super-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "_leaky_relu = lambda net: tf.nn.leaky_relu(net, alpha=0.01)\n",
    "def unconditional_generator(noise, mode, weight_decay=2.5e-5):\n",
    "  \"\"\"Generator to produce unconditional MNIST images.\"\"\"\n",
    "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  \n",
    "  net = _dense(noise, 100, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 72, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 10, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 4, weight_decay)\n",
    "\n",
    "  return net\n",
    "\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weekly-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "_leaky_relu = lambda net: tf.nn.leaky_relu(net, alpha=0.01)\n",
    "\n",
    "def unconditional_discriminator(price, unused_conditioning, mode, weight_decay=2.5e-5):\n",
    "  del unused_conditioning\n",
    "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  \n",
    "  net = _dense(price, 100, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 72, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 10, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 1, weight_decay)\n",
    "\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compliant-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_gan.examples.mnist import util as eval_util\n",
    "import os\n",
    "\n",
    "def get_eval_metric_ops_fn(gan_model):\n",
    "  real_data_logits = tf.reduce_mean(gan_model.discriminator_real_outputs)\n",
    "  gen_data_logits = tf.reduce_mean(gan_model.discriminator_gen_outputs)\n",
    "  return {\n",
    "      'real_data_logits': tf.metrics.mean(real_data_logits),\n",
    "      'gen_data_logits': tf.metrics.mean(gen_data_logits),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "european-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32 #@param\n",
    "noise_dimensions = 4 #@param\n",
    "generator_lr = 0.001 #@param\n",
    "discriminator_lr = 0.0002 #@param\n",
    "\n",
    "def gen_opt():\n",
    "  gstep = tf.train.get_or_create_global_step()\n",
    "  base_lr = generator_lr\n",
    "  # Halve the learning rate at 1000 steps.\n",
    "  lr = tf.cond(gstep < 1000, lambda: base_lr, lambda: base_lr / 2.0)\n",
    "  return tf.train.AdamOptimizer(lr, 0.5)\n",
    "\n",
    "gan_estimator = tfgan.estimator.GANEstimator(\n",
    "    generator_fn=unconditional_generator,\n",
    "    discriminator_fn=unconditional_discriminator,\n",
    "    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n",
    "    discriminator_loss_fn=tfgan.losses.wasserstein_discriminator_loss,\n",
    "    params={'batch_size': train_batch_size, 'noise_dims': noise_dimensions},\n",
    "    generator_optimizer=gen_opt,\n",
    "    discriminator_optimizer=tf.train.AdamOptimizer(discriminator_lr, 0.5),\n",
    "    get_eval_metric_ops_fn=get_eval_metric_ops_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepted-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zheng\\AppData\\Local\\Temp/ipykernel_28652/1206689090.py:2: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n",
      "C:\\Users\\zheng\\anaconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time since start: 0.03 min\n",
      "Trained from step 0 to 500 in 260.42 steps / sec\n",
      "Average discriminator output on Real: 826.92  Fake: 0.07\n",
      "[-0.6839396  -0.5093892  -0.029005   -0.35985088]\n",
      "[-0.7331737  -0.46559614 -0.04137171 -0.4668968 ]\n",
      "[-0.5983864  -0.49118713  0.01635591 -0.36307248]\n",
      "[-0.39220762 -0.12818916  0.07325451 -0.18351325]\n",
      "[-0.6725071  -0.39149603  0.097769   -0.42888764]\n",
      "[-0.28325713 -0.15181573  0.0510788  -0.10019849]\n",
      "[-0.46315226 -0.21304107  0.01682877 -0.23406969]\n",
      "[-0.9201392  -0.8738374   0.02346537 -0.7861449 ]\n",
      "[-0.31297907 -0.18801922  0.03637781 -0.12036449]\n",
      "[-0.54106057 -0.45148578  0.05616545 -0.44779098]\n",
      "[-0.20076112 -0.27815196 -0.0795952  -0.21969707]\n",
      "[-1.1066921  -0.5715309   0.05576683 -0.6314213 ]\n",
      "[-0.35729223 -0.19659129  0.03565373 -0.23032482]\n",
      "[-0.23239015 -0.06281055  0.12312994 -0.11706465]\n",
      "[-0.4450921  -0.32321656  0.01034956 -0.36300284]\n",
      "[-0.4449376  -0.23843798  0.1071898  -0.31541196]\n",
      "[-0.22992252 -0.10171118  0.01688176 -0.09088056]\n",
      "[-0.5326958  -0.30200362 -0.00838552 -0.26774415]\n",
      "[-0.24303772 -0.1398908   0.05211573 -0.17068352]\n",
      "[-0.15779045 -0.19265828  0.0372007  -0.15481459]\n",
      "Time since start: 0.07 min\n",
      "Trained from step 500 to 1000 in 312.30 steps / sec\n",
      "Average discriminator output on Real: 1193.49  Fake: 0.12\n",
      "[-0.6484847  -0.47594225  0.12079947 -0.51460546]\n",
      "[-1.4509497  -0.5172795   0.29396868 -0.7329533 ]\n",
      "[-0.34025308 -0.23553951  0.0632655  -0.23614262]\n",
      "[-1.0608664  -0.41810247  0.16803427 -0.50731283]\n",
      "[-1.266569   -0.79666525  0.18142095 -0.868608  ]\n",
      "[-0.4938318  -0.3656833   0.04964708 -0.34904656]\n",
      "[-0.7121786  -0.7511396   0.16379304 -0.7629516 ]\n",
      "[-0.6077104  -0.34261483  0.08021848 -0.35922265]\n",
      "[-0.7621638  -0.5091679   0.11810309 -0.58713776]\n",
      "[-0.5163504  -0.20269328  0.08538704 -0.2694723 ]\n",
      "[-1.1967058  -1.1326439   0.30577695 -1.0852187 ]\n",
      "[-0.57304597 -0.32757798  0.10697636 -0.3633633 ]\n",
      "[-0.70334864 -0.8009003   0.18819745 -0.7065564 ]\n",
      "[-0.54947674 -0.24619381  0.11129548 -0.29863545]\n",
      "[-0.47993594 -0.33352295  0.03196678 -0.2983495 ]\n",
      "[-0.8063369  -0.49827707  0.11253569 -0.4996848 ]\n",
      "[-0.7642676  -0.5073154   0.15210056 -0.4205253 ]\n",
      "[-1.0428956  -0.61810464  0.06107306 -0.44825128]\n",
      "[-1.3118428  -0.56386834  0.2558695  -0.67532396]\n",
      "[-0.80983126 -0.3399941   0.10977059 -0.43943384]\n",
      "Time since start: 0.11 min\n",
      "Trained from step 1000 to 1500 in 271.00 steps / sec\n",
      "Average discriminator output on Real: 1558.07  Fake: 0.17\n",
      "[-1.8230848  -0.98978263  0.28371117 -1.1875823 ]\n",
      "[-1.2369995  -0.8236235   0.27545857 -0.79843366]\n",
      "[-1.0627875  -0.8094608   0.12809753 -0.74061996]\n",
      "[-1.2077787  -0.8322903   0.26147383 -0.84497315]\n",
      "[-1.1453276  -0.5692783   0.3239997  -0.68677163]\n",
      "[-0.9682046  -0.83764946  0.26396632 -0.7838157 ]\n",
      "[-2.1062396  -1.2725358   0.63535255 -1.4856007 ]\n",
      "[-2.266764  -1.120563   0.555434  -1.4015905]\n",
      "[-0.98550993 -0.68309975  0.18734895 -0.7148892 ]\n",
      "[-0.52468747 -0.33786052  0.14044446 -0.34564146]\n",
      "[-1.3273047  -0.68505335  0.3432043  -0.83553   ]\n",
      "[-1.5480634  -0.8439297   0.27483037 -0.9579404 ]\n",
      "[-1.8112732  -1.4356658   0.45049867 -1.309658  ]\n",
      "[-1.3059204  -0.6994122   0.26664528 -0.7699991 ]\n",
      "[-0.5148078  -0.3589336   0.07308488 -0.34272712]\n",
      "[-0.9860696  -0.5010808   0.21353778 -0.6194342 ]\n",
      "[-1.2267511  -0.6805283   0.34271052 -0.7477887 ]\n",
      "[-1.058351   -0.5120861   0.2587588  -0.63500583]\n",
      "[-1.5315591  -0.80451614  0.27942672 -0.9292396 ]\n",
      "[-1.9837765  -1.3127382   0.36426583 -1.4037952 ]\n",
      "Time since start: 0.15 min\n",
      "Trained from step 1500 to 2000 in 302.48 steps / sec\n",
      "Average discriminator output on Real: 1908.01  Fake: 0.22\n",
      "[-2.802117  -1.4815369  0.9360153 -1.9439924]\n",
      "[-0.70191675 -0.36661127  0.24758677 -0.49740207]\n",
      "[-2.4415207  -1.1495141   0.77394396 -1.5449638 ]\n",
      "[-1.4069729 -0.8281281  0.5058441 -0.9724413]\n",
      "[-0.785892   -0.39229238  0.29050097 -0.5061188 ]\n",
      "[-3.1406934 -1.6083926  0.7171419 -1.7205594]\n",
      "[-2.7949417 -1.5954229  0.852813  -1.711453 ]\n",
      "[-1.6733404  -0.9046799   0.57652575 -1.1909904 ]\n",
      "[-1.2836567  -0.73033434  0.42548016 -0.8972634 ]\n",
      "[-2.3790805 -1.3404492  0.5484104 -1.5088168]\n",
      "[-0.7378465  -0.37543914  0.2623651  -0.4875659 ]\n",
      "[-1.012174   -0.4999729   0.34047657 -0.69905597]\n",
      "[-2.8202024  -1.4252744   0.97804517 -1.8409435 ]\n",
      "[-1.3903954  -0.7529541   0.45937935 -0.95632637]\n",
      "[-1.932106  -0.9484291  0.5219297 -1.1103809]\n",
      "[-1.7701408  -1.1685393   0.62362325 -1.3714893 ]\n",
      "[-1.5615823  -0.91906923  0.4178668  -1.1129155 ]\n",
      "[-2.9695518  -1.8907366   0.96527445 -2.275498  ]\n",
      "[-2.0458703  -0.93950397  0.6638022  -1.3903495 ]\n",
      "[-3.644655  -1.9054585  1.2897127 -2.4525127]\n",
      "Time since start: 0.19 min\n",
      "Trained from step 2000 to 2500 in 292.06 steps / sec\n",
      "Average discriminator output on Real: 2263.07  Fake: 0.25\n",
      "[-1.7221136  -0.89053816  0.59910595 -1.1811382 ]\n",
      "[-2.557409  -1.3011596  0.9131713 -1.7052203]\n",
      "[-5.805265  -2.7211485  1.7152078 -3.7827218]\n",
      "[-4.8168993 -2.3071651  1.4600829 -3.180799 ]\n",
      "[-3.0245726 -1.4978577  0.9645092 -2.028606 ]\n",
      "[-3.7303488 -1.8635975  1.3037037 -2.4875526]\n",
      "[-2.1108835 -0.9966883  0.6369276 -1.3636959]\n",
      "[-2.959824  -1.2798645  1.0066576 -1.6861167]\n",
      "[-3.4686165 -1.6959058  1.0555412 -2.256406 ]\n",
      "[-3.7446647 -1.9237386  1.1561228 -2.4755406]\n",
      "[-2.581938  -1.3760066  0.8179489 -1.7158084]\n",
      "[-3.0663993 -1.4907     1.1301175 -1.9398679]\n",
      "[-3.5553608 -1.6779786  1.0991278 -2.2884233]\n",
      "[-1.9620908  -0.90148336  0.6973086  -1.1531957 ]\n",
      "[-1.8633344 -1.0007333  0.5333875 -1.1991808]\n",
      "[-2.7072222 -1.3007734  0.8379597 -1.6509807]\n",
      "[-2.7051842 -1.4475335  0.9897693 -1.9528636]\n",
      "[-3.7918332 -1.862611   1.0860766 -2.424802 ]\n",
      "[-4.465056  -2.267737   1.4863566 -3.0665119]\n",
      "[-2.5205238  -1.4040363   0.73804253 -1.7121284 ]\n",
      "Time since start: 0.23 min\n",
      "Trained from step 2500 to 3000 in 305.06 steps / sec\n",
      "Average discriminator output on Real: 2652.05  Fake: 0.21\n",
      "[-2.625834  -1.3665934  0.8797755 -1.8297359]\n",
      "[-4.7200756 -2.1338904  1.4109545 -3.027096 ]\n",
      "[-4.4637275 -2.2301981  1.4495739 -2.9744267]\n",
      "[-4.8400726 -2.3332286  1.6563305 -3.0724993]\n",
      "[-2.9168847 -1.3963709  0.9669537 -1.8189346]\n",
      "[-4.6121616 -2.1951766  1.5047176 -3.0957737]\n",
      "[-3.6291091 -1.6761999  1.4586571 -2.312587 ]\n",
      "[-3.81226   -1.9329575  1.2038136 -2.5198832]\n",
      "[-2.5248427 -1.2091465  0.9134579 -1.576402 ]\n",
      "[-2.3526762 -1.1281524  0.8447664 -1.5018969]\n",
      "[-5.169537  -2.3534603  1.9312738 -3.1314998]\n",
      "[-2.9967554 -1.3086065  1.1310418 -1.804813 ]\n",
      "[-4.2341948 -1.8834556  1.3811357 -2.4736881]\n",
      "[-3.4037712 -1.7412835  1.0716071 -2.2965302]\n",
      "[-6.5475936 -3.0693588  1.9739411 -4.2263937]\n",
      "[-3.6571991 -1.7434464  1.096197  -2.312543 ]\n",
      "[-4.8859997 -2.2920225  1.6242546 -3.0650256]\n",
      "[-3.6623695 -1.7679585  1.1799082 -2.381064 ]\n",
      "[-1.6916006  -0.7926334   0.59330815 -1.0687791 ]\n",
      "[-5.103906  -2.5671513  1.6562766 -3.42173  ]\n",
      "Time since start: 0.27 min\n",
      "Trained from step 3000 to 3500 in 261.64 steps / sec\n",
      "Average discriminator output on Real: 3051.18  Fake: 0.07\n",
      "[-3.5428436 -1.734468   1.1084951 -2.3317037]\n",
      "[-2.9723952 -1.4026039  0.9428472 -1.9693677]\n",
      "[-6.3738976 -3.102855   1.8997018 -4.208145 ]\n",
      "[-8.454817  -4.0971384  2.6430144 -5.665715 ]\n",
      "[-5.521959  -2.721862   1.6924764 -3.6901178]\n",
      "[-3.8624802 -1.8972102  1.2335877 -2.503253 ]\n",
      "[-3.295721  -1.6072173  1.1193144 -2.137161 ]\n",
      "[-4.864412  -2.3455205  1.4695352 -3.1867836]\n",
      "[-3.281046  -1.5751842  1.0380316 -2.1754637]\n",
      "[-5.0325375 -2.4444642  1.6358191 -3.3613777]\n",
      "[-4.321517  -2.1492963  1.378617  -2.8705788]\n",
      "[-7.4476967 -3.7124743  2.3046923 -5.0528007]\n",
      "[-5.8412924 -2.848937   1.8883601 -3.8573334]\n",
      "[-2.5897007 -1.3041898  0.84137   -1.7788169]\n",
      "[-3.2107716 -1.4918807  1.0873901 -2.0417156]\n",
      "[-4.843442  -2.3602657  1.5570624 -3.1680658]\n",
      "[-7.2062464 -3.4840808  2.1991832 -4.731706 ]\n",
      "[-3.4390414 -1.7375505  1.1252478 -2.3245547]\n",
      "[-7.323087  -3.7071738  2.270512  -4.763736 ]\n",
      "[-4.3063974 -2.1080728  1.5002462 -2.839814 ]\n",
      "Time since start: 0.31 min\n",
      "Trained from step 3500 to 4000 in 310.37 steps / sec\n",
      "Average discriminator output on Real: 3459.03  Fake: -0.12\n",
      "[-6.853049  -3.1377182  2.104871  -4.391458 ]\n",
      "[-6.0952315 -2.8572671  1.9907174 -3.8722231]\n",
      "[-5.6396728 -2.572947   1.6993977 -3.699748 ]\n",
      "[-6.8554945 -3.2349265  2.1481602 -4.411258 ]\n",
      "[-4.9965534 -2.3432324  1.5309182 -3.2957513]\n",
      "[-10.333897   -4.970135    3.31387    -6.6982446]\n",
      "[-6.660806  -3.0561426  2.0787952 -4.2035117]\n",
      "[-4.574676  -2.1292777  1.5146059 -2.9925857]\n",
      "[-4.974003  -2.279621   1.4583454 -3.2311711]\n",
      "[-7.901234  -3.548573   2.3698587 -5.1439033]\n",
      "[-7.051203  -3.2367852  2.1151996 -4.5868754]\n",
      "[-7.980979  -3.7633061  2.4050055 -5.239598 ]\n",
      "[-7.4927897 -3.3359802  2.3704312 -4.584992 ]\n",
      "[-3.133718   -1.4406778   0.94455034 -2.004287  ]\n",
      "[-3.5425017 -1.4902347  1.2791418 -2.1340342]\n",
      "[-9.697205  -4.436742   2.9552763 -6.146087 ]\n",
      "[-6.371262  -2.9308767  1.8813795 -4.128598 ]\n",
      "[-7.470568  -3.5366244  2.278756  -4.880134 ]\n",
      "[-4.525338  -2.057578   1.3417524 -2.878269 ]\n",
      "[-10.001475   -4.586223    3.401687   -6.2326393]\n",
      "Time since start: 0.35 min\n",
      "Trained from step 4000 to 4500 in 317.86 steps / sec\n",
      "Average discriminator output on Real: 3929.69  Fake: -0.17\n",
      "[-5.2669806 -2.0986533  2.305848  -3.3661892]\n",
      "[-7.3048267 -2.9499087  3.1230607 -4.828429 ]\n",
      "[-1.9291791  -0.78676903  0.88810915 -1.2949181 ]\n",
      "[-4.272414  -1.7162758  1.8710508 -2.782876 ]\n",
      "[-5.1277294 -2.2518182  2.2920983 -3.636411 ]\n",
      "[-4.5565557 -1.9371216  1.9532707 -3.2112978]\n",
      "[-2.7278304 -1.1281586  1.2452427 -1.8641189]\n",
      "[-4.0578947 -1.7231994  1.7464625 -2.7954762]\n",
      "[-6.0306387 -2.5701807  2.5266666 -4.0881553]\n",
      "[-4.2924137 -1.7135105  1.9664005 -2.8202996]\n",
      "[-3.917124  -1.6206199  1.7311482 -2.7421632]\n",
      "[-6.7267876 -2.8601155  2.8978713 -4.619489 ]\n",
      "[-2.533822  -1.0627223  1.134266  -1.7560959]\n",
      "[-3.7659028 -1.5947223  1.6284053 -2.5887408]\n",
      "[-5.1533227 -2.1342652  2.1709254 -3.6133788]\n",
      "[-3.8747375 -1.687      1.7415165 -2.7105007]\n",
      "[-2.9993005 -1.243109   1.3412772 -2.0740519]\n",
      "[-3.0859373 -1.2826749  1.3762589 -2.163062 ]\n",
      "[-3.093992  -1.3181753  1.2974561 -2.1325681]\n",
      "[-2.9556215 -1.2805804  1.293416  -2.1020863]\n",
      "Time since start: 0.39 min\n",
      "Trained from step 4500 to 5000 in 294.29 steps / sec\n",
      "Average discriminator output on Real: 4442.57  Fake: -0.03\n",
      "[-5.556852  -2.152223   4.7973866 -4.7766047]\n",
      "[-3.2495692 -1.2628471  3.0267425 -2.8501968]\n",
      "[-6.268061  -2.3411992  5.893431  -5.211192 ]\n",
      "[-3.1001303 -1.1437356  2.7701719 -2.6041026]\n",
      "[-2.2869573 -0.9510236  2.1784832 -2.1189203]\n",
      "[-5.517196  -2.3740957  4.994054  -5.0518227]\n",
      "[-1.6573073 -0.6220287  1.533173  -1.4483472]\n",
      "[-3.448213  -1.2529117  3.1684196 -2.8178356]\n",
      "[-2.6000748 -1.0407612  2.4056175 -2.329038 ]\n",
      "[-3.8580666 -1.6995997  3.7096624 -3.663583 ]\n",
      "[-3.7617903 -1.5603504  3.1523418 -3.3253767]\n",
      "[-2.4468884 -1.0400981  2.1285353 -2.2415526]\n",
      "[-6.2541738 -2.4953632  5.547242  -5.4957833]\n",
      "[-4.762384  -1.8081684  4.1813774 -4.1521254]\n",
      "[-3.3097126 -1.3625737  2.8502078 -2.9924529]\n",
      "[-3.706204  -1.5234998  3.2228196 -3.2985244]\n",
      "[-5.889751  -2.0310276  5.496395  -4.80851  ]\n",
      "[-4.4712644 -1.8309882  3.9053962 -3.9989104]\n",
      "[-4.205849  -1.6335495  3.8255377 -3.7282326]\n",
      "[-3.0344398 -1.2160983  2.7104993 -2.74159  ]\n"
     ]
    }
   ],
   "source": [
    "# Disable noisy output.\n",
    "tf.autograph.set_verbosity(0, False)\n",
    "\n",
    "import time\n",
    "steps_per_eval = 500 #@param\n",
    "max_train_steps = 5000 #@param\n",
    "batches_for_eval_metrics = 100 #@param\n",
    "\n",
    "# Used to track metrics.\n",
    "steps = []\n",
    "real_logits, fake_logits = [], []\n",
    "real_mnist_scores, mnist_scores, frechet_distances = [], [], []\n",
    "\n",
    "cur_step = 0\n",
    "start_time = time.time()\n",
    "while cur_step < max_train_steps:\n",
    "  \n",
    "    \n",
    "    \n",
    "  next_step = min(cur_step + steps_per_eval, max_train_steps)\n",
    "\n",
    "  start = time.time()\n",
    "  gan_estimator.train(input_fn, max_steps=next_step)\n",
    "  steps_taken = next_step - cur_step\n",
    "  time_taken = time.time() - start\n",
    "  print('Time since start: %.2f min' % ((time.time() - start_time) / 60.0))\n",
    "  print('Trained from step %i to %i in %.2f steps / sec' % (\n",
    "      cur_step, next_step, steps_taken / time_taken))\n",
    "  cur_step = next_step\n",
    "  \n",
    "  # Calculate some metrics.\n",
    "  metrics = gan_estimator.evaluate(input_fn, steps=batches_for_eval_metrics)\n",
    "  steps.append(cur_step)\n",
    "  real_logits.append(metrics['real_data_logits'])\n",
    "  fake_logits.append(metrics['gen_data_logits'])\n",
    "  print('Average discriminator output on Real: %.2f  Fake: %.2f' % (\n",
    "      real_logits[-1], fake_logits[-1]))\n",
    "  \n",
    "  # Print current predictions\n",
    "  iterator = gan_estimator.predict(\n",
    "      input_fn, hooks=[tf.train.StopAtStepHook(num_steps=21)])\n",
    "  try:\n",
    "    daily_prices = np.array([next(iterator) for _ in range(20)])\n",
    "  except StopIteration:\n",
    "    pass\n",
    "  for p in daily_prices:\n",
    "    print(p)\n",
    " \n",
    "  \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
